2025-04-15 16:35:45,383 - INFO - Loading environment variables...
2025-04-15 16:35:45,735 - INFO - Start Processing file: theory_evaluation\llm_handler.py
2025-04-15 16:35:57,299 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-15 16:36:08,206 - INFO - 

2025-04-15 16:36:08,206 - INFO - TEST CASE 1 Retry 0
2025-04-15 16:36:08,206 - INFO - ---------------
2025-04-15 16:36:08,207 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest


@pytest.mark.asyncio
async def test_openai_llm_initialization():
    with patch('theory_evaluation.llm_handler.AzureOpenAI') as mock_azure_openai, \
         patch('theory_evaluation.llm_handler.OpenAI') as mock_openai, \
         patch('os.getenv', side_effect=lambda key: f"{key}_value"):

2025-04-15 16:36:08,208 - INFO - ---------------
2025-04-15 16:36:09,337 - INFO - Test Result 1- False
2025-04-15 16:36:09,337 - INFO - Test Error 1 - C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\python.py:493: in importtestmodule
    mod = import_path(
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\pathlib.py:587: in import_path
    importlib.import_module(module_name)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1387: in _gcd_import
    ???
<frozen importlib._bootstrap>:1360: in _find_and_load
    ???
<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:935: in _load_unlocked
    ???
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\assertion\rewrite.py:176: in exec_module
    source_stat, co = _rewrite_test(fn, self.config)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\assertion\rewrite.py:356: in _rewrite_test
    tree = ast.parse(source, filename=strfn)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\ast.py:54: in parse
    return compile(source, filename, mode, flags,
E     File "C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py", line 14
E       patch('os.getenv', side_effect=lambda key: f"{key}_value"):
E                                                                  ^
E   IndentationError: expected an indented block after 'with' statement on line 12
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 0.24s
2025-04-15 16:36:10,843 - INFO - TEST CASE 1 Retry 1
2025-04-15 16:36:10,844 - INFO - ---------------
2025-04-15 16:36:10,844 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest

from unittest.mock import patch
import pytest

@pytest.mark.asyncio
async def test_openai_llm_initialization():
    with patch('theory_evaluation.llm_handler.AzureOpenAI') as mock_azure_openai, \
         patch('theory_evaluation.llm_handler.OpenAI') as mock_openai, \
         patch('os.getenv', side_effect=lambda key: f"{key}_value"):
        # Add your test logic here
        pass

2025-04-15 16:36:10,844 - INFO - ---------------
2025-04-15 16:36:13,287 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-15 16:36:13,288 - INFO - New import Statements 2- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest
from unittest.mock import patch
2025-04-15 16:36:13,288 - INFO - Test Result 2- True
2025-04-15 16:36:13,288 - INFO - Test Error 2 - 
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
.                                                                        [100%]
1 passed in 0.94s
2025-04-15 16:36:13,288 - INFO - 

2025-04-15 16:36:13,288 - INFO - TEST CASE 2 Retry 0
2025-04-15 16:36:13,288 - INFO - ---------------
2025-04-15 16:36:13,289 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest
from unittest.mock import patch


@pytest.mark.asyncio
async def test_openai_json_completion():
    mock_response = MagicMock()
    mock_response.choices = [MagicMock()]
    mock_response.choices[0].message.content = json.dumps({"key": "value"})

2025-04-15 16:36:13,289 - INFO - ---------------
2025-04-15 16:36:15,365 - INFO - Test Result 1- False
2025-04-15 16:36:15,366 - INFO - Test Error 1 - C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
_________________________ test_openai_json_completion _________________________
temp\temp.py:13: in test_openai_json_completion
    mock_response = MagicMock()
E   NameError: name 'MagicMock' is not defined
=========================== short test summary info ===========================
FAILED temp/temp.py::test_openai_json_completion - NameError: name 'MagicMock...
1 failed in 1.14s
2025-04-15 16:36:17,059 - INFO - TEST CASE 2 Retry 1
2025-04-15 16:36:17,059 - INFO - ---------------
2025-04-15 16:36:17,060 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest
from unittest.mock import patch

from unittest.mock import MagicMock
import json
import pytest

@pytest.mark.asyncio
async def test_openai_json_completion():
    mock_response = MagicMock()
    mock_response.choices = [MagicMock()]
    mock_response.choices[0].message.content = json.dumps({"key": "value"})

2025-04-15 16:36:17,060 - INFO - ---------------
2025-04-15 16:36:19,829 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-15 16:36:19,829 - INFO - New import Statements 2- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest
from unittest.mock import patch
from unittest.mock import MagicMock
import json
import pytest
2025-04-15 16:36:19,830 - INFO - Test Result 2- True
2025-04-15 16:36:19,830 - INFO - Test Error 2 - 
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
.                                                                        [100%]
1 passed in 1.21s
2025-04-15 16:36:19,830 - INFO - 

2025-04-15 16:36:19,830 - INFO - TEST CASE 3 Retry 0
2025-04-15 16:36:19,831 - INFO - ---------------
2025-04-15 16:36:19,831 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest
from unittest.mock import patch
from unittest.mock import MagicMock
import json
import pytest


@pytest.mark.asyncio
async def test_openai_streaming():
    mock_chunk = MagicMock()
    mock_chunk.choices = [MagicMock()]
    mock_chunk.choices[0].delta.content = "streamed content"

2025-04-15 16:36:19,831 - INFO - ---------------
2025-04-15 16:36:21,729 - INFO - Test Result 1- True
2025-04-15 16:36:21,729 - INFO - Test Error 1 - C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
.                                                                        [100%]
1 passed in 1.01s
2025-04-15 16:36:21,729 - INFO - 

2025-04-15 16:36:21,729 - INFO - TEST CASE 4 Retry 0
2025-04-15 16:36:21,729 - INFO - ---------------
2025-04-15 16:36:21,729 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest
from unittest.mock import patch
from unittest.mock import MagicMock
import json
import pytest


@pytest.mark.asyncio
async def test_openai_chat_completion():
    mock_response = MagicMock()
    mock_response.choices = [MagicMock()]
    mock_response.choices[0].message.content = "chat completion content"

2025-04-15 16:36:21,729 - INFO - ---------------
2025-04-15 16:36:23,720 - INFO - Test Result 1- True
2025-04-15 16:36:23,720 - INFO - Test Error 1 - C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
.                                                                        [100%]
1 passed in 1.05s
2025-04-15 16:36:23,720 - INFO - 

2025-04-15 16:36:23,720 - INFO - TEST CASE 5 Retry 0
2025-04-15 16:36:23,720 - INFO - ---------------
2025-04-15 16:36:23,720 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest
from unittest.mock import patch
from unittest.mock import MagicMock
import json
import pytest


@pytest.mark.asyncio
async def test_execute_text_generation():
    with patch.object(OpenAI_llm, '_run', return_value=AsyncMock(return_value=["response"])), \
         patch.object(OpenAI_llm, '__init__', return_value=None):
        llm = OpenAI_llm()
        llm.mode = "text_generation"
        llm.message = "Test message"
        responses = [response async for response in llm.execute()]
        assert responses == ["response"]

2025-04-15 16:36:23,720 - INFO - ---------------
2025-04-15 16:36:25,718 - INFO - Test Result 1- False
2025-04-15 16:36:25,718 - INFO - Test Error 1 - C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
________________________ test_execute_text_generation _________________________
temp\temp.py:16: in test_execute_text_generation
    with patch.object(OpenAI_llm, '_run', return_value=AsyncMock(return_value=["response"])), \
E   NameError: name 'AsyncMock' is not defined
=========================== short test summary info ===========================
FAILED temp/temp.py::test_execute_text_generation - NameError: name 'AsyncMoc...
1 failed in 1.13s
2025-04-15 16:36:28,195 - INFO - TEST CASE 5 Retry 1
2025-04-15 16:36:28,196 - INFO - ---------------
2025-04-15 16:36:28,196 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest
from unittest.mock import patch
from unittest.mock import MagicMock
import json
import pytest

from unittest.mock import patch, AsyncMock

@pytest.mark.asyncio
async def test_execute_text_generation():
    with patch.object(OpenAI_llm, '_run', return_value=AsyncMock(return_value=["response"])), \
         patch.object(OpenAI_llm, '__init__', return_value=None):
        llm = OpenAI_llm()
        llm.mode = "text_generation"
        llm.message = "Test message"
        responses = [response async for response in llm.execute()]
        assert responses == ["response"]

2025-04-15 16:36:28,196 - INFO - ---------------
2025-04-15 16:36:30,199 - INFO - Test Result 2- False
2025-04-15 16:36:30,199 - INFO - Test Error 2 - 
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
________________________ test_execute_text_generation _________________________
temp\temp.py:23: in test_execute_text_generation
    assert responses == ["response"]
E   assert ["Error: 'Ope...te 'verbose'"] == ['response']
E     
E     At index 0 diff: "Error: 'OpenAI_llm' object has no attribute 'verbose'" != 'response'
E     Use -v to get more diff
=========================== short test summary info ===========================
FAILED temp/temp.py::test_execute_text_generation - assert ["Error: 'Ope...te...
1 failed in 1.10s
2025-04-15 16:36:31,947 - INFO - TEST CASE 5 Retry 2
2025-04-15 16:36:31,948 - INFO - ---------------
2025-04-15 16:36:31,948 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest
from unittest.mock import patch
from unittest.mock import MagicMock
import json
import pytest

from unittest.mock import patch, AsyncMock
import pytest

@pytest.mark.asyncio
async def test_execute_text_generation():
    with patch.object(OpenAI_llm, '_run', return_value=AsyncMock(return_value=["response"])), \
         patch.object(OpenAI_llm, '__init__', return_value=None):
        llm = OpenAI_llm()
        llm.mode = "text_generation"
        llm.message = "Test message"
        llm.verbose = False  # Ensure verbose attribute is set
        responses = [response async for response in llm.execute()]
        assert responses == ["response"]

2025-04-15 16:36:31,948 - INFO - ---------------
2025-04-15 16:36:33,701 - INFO - Test Result 3- False
2025-04-15 16:36:33,701 - INFO - Test Error 3 - 
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
________________________ test_execute_text_generation _________________________
temp\temp.py:25: in test_execute_text_generation
    assert responses == ["response"]
E   assert ["Error: 'Ope...'model_name'"] == ['response']
E     
E     At index 0 diff: "Error: 'OpenAI_llm' object has no attribute 'model_name'" != 'response'
E     Use -v to get more diff
=========================== short test summary info ===========================
FAILED temp/temp.py::test_execute_text_generation - assert ["Error: 'Ope...'m...
1 failed in 0.99s
2025-04-15 16:36:33,702 - INFO - Failed after all retries for test case 5
2025-04-15 16:36:33,702 - INFO - 

2025-04-15 16:36:33,702 - INFO - TEST CASE 6 Retry 0
2025-04-15 16:36:33,702 - INFO - ---------------
2025-04-15 16:36:33,702 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest
from unittest.mock import patch
from unittest.mock import MagicMock
import json
import pytest


@pytest.mark.asyncio
async def test_execute_vision():
    with patch.object(OpenAI_llm, '_run', return_value=AsyncMock(return_value=["response"])), \
         patch.object(OpenAI_llm, '__init__', return_value=None):
        llm = OpenAI_llm()
        llm.mode = "vision"
        llm.message = "Test message"
        llm.image_input = "image_data"
        responses = [response async for response in llm.execute()]
        assert responses == ["response"]

2025-04-15 16:36:33,702 - INFO - ---------------
2025-04-15 16:36:35,546 - INFO - Test Result 1- False
2025-04-15 16:36:35,546 - INFO - Test Error 1 - C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
_____________________________ test_execute_vision _____________________________
temp\temp.py:16: in test_execute_vision
    with patch.object(OpenAI_llm, '_run', return_value=AsyncMock(return_value=["response"])), \
E   NameError: name 'AsyncMock' is not defined
=========================== short test summary info ===========================
FAILED temp/temp.py::test_execute_vision - NameError: name 'AsyncMock' is not...
1 failed in 1.00s
2025-04-15 16:36:37,891 - INFO - TEST CASE 6 Retry 1
2025-04-15 16:36:37,891 - INFO - ---------------
2025-04-15 16:36:37,891 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest
from unittest.mock import patch
from unittest.mock import MagicMock
import json
import pytest

from unittest.mock import patch, AsyncMock

@pytest.mark.asyncio
async def test_execute_vision():
    with patch.object(OpenAI_llm, '_run', return_value=AsyncMock(return_value=["response"])), \
         patch.object(OpenAI_llm, '__init__', return_value=None):
        llm = OpenAI_llm()
        llm.mode = "vision"
        llm.message = "Test message"
        llm.image_input = "image_data"
        responses = [response async for response in llm.execute()]
        assert responses == ["response"]

2025-04-15 16:36:37,891 - INFO - ---------------
2025-04-15 16:36:40,417 - INFO - Test Result 2- False
2025-04-15 16:36:40,417 - INFO - Test Error 2 - 
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
_____________________________ test_execute_vision _____________________________
temp\temp.py:24: in test_execute_vision
    assert responses == ["response"]
E   assert ["Error: 'Ope...te 'verbose'"] == ['response']
E     
E     At index 0 diff: "Error: 'OpenAI_llm' object has no attribute 'verbose'" != 'response'
E     Use -v to get more diff
=========================== short test summary info ===========================
FAILED temp/temp.py::test_execute_vision - assert ["Error: 'Ope...te 'verbose...
1 failed in 1.42s
2025-04-15 16:36:42,241 - INFO - TEST CASE 6 Retry 2
2025-04-15 16:36:42,242 - INFO - ---------------
2025-04-15 16:36:42,242 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest
from unittest.mock import patch
from unittest.mock import MagicMock
import json
import pytest

import pytest
from unittest.mock import patch, AsyncMock

@pytest.mark.asyncio
async def test_execute_vision():
    with patch.object(OpenAI_llm, '_run', return_value=AsyncMock(return_value=["response"])), \
         patch.object(OpenAI_llm, '__init__', return_value=None):
        llm = OpenAI_llm()
        llm.mode = "vision"
        llm.message = "Test message"
        llm.image_input = "image_data"
        llm.verbose = False
        responses = [response async for response in llm.execute()]
        assert responses == ["response"]

2025-04-15 16:36:42,243 - INFO - ---------------
2025-04-15 16:36:44,602 - INFO - Test Result 3- False
2025-04-15 16:36:44,602 - INFO - Test Error 3 - 
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
_____________________________ test_execute_vision _____________________________
temp\temp.py:26: in test_execute_vision
    assert responses == ["response"]
E   assert ["Error: 'Ope...'model_name'"] == ['response']
E     
E     At index 0 diff: "Error: 'OpenAI_llm' object has no attribute 'model_name'" != 'response'
E     Use -v to get more diff
=========================== short test summary info ===========================
FAILED temp/temp.py::test_execute_vision - assert ["Error: 'Ope...'model_name...
1 failed in 1.32s
2025-04-15 16:36:44,603 - INFO - Failed after all retries for test case 6
2025-04-15 16:36:44,605 - INFO - End Processing file: theory_evaluation\llm_handler.py

2025-04-15 16:36:44,606 - INFO - Start Processing file: theory_evaluation\llm_utils.py
2025-04-15 16:36:51,093 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-15 16:37:01,588 - INFO - End Processing file: theory_evaluation\llm_utils.py

2025-04-15 16:37:01,588 - INFO - Start Processing file: theory_evaluation\__init__.py
2025-04-15 16:37:01,589 - WARNING - No public functions found in theory_evaluation\__init__.py. Skipping test generation.

