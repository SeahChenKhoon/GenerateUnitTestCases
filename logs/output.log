2025-04-17 11:24:49,167 - INFO - Loading environment variables start
2025-04-17 11:24:49,170 - INFO - Loading environment variables completes
2025-04-17 11:24:49,170 - INFO - Initialising of LLM start
2025-04-17 11:24:49,483 - INFO - Initialising of LLM completes
2025-04-17 11:24:49,483 - INFO - Getting python file starts
2025-04-17 11:24:49,483 - INFO - Getting python file completes
2025-04-17 11:24:49,484 - INFO - 
Start Processing file: theory_evaluation\circle_utils.py
2025-04-17 11:24:49,484 - INFO - Extraction of function and class start
2025-04-17 11:24:49,484 - INFO - extraction of function and class complete
2025-04-17 11:24:49,484 - INFO - Generate Unit Test Case starts
2025-04-17 11:24:49,484 - INFO - Extract unique import start
2025-04-17 11:24:51,148 - INFO - Extract unique import complete
2025-04-17 11:24:51,148 - INFO - Update relative import start
2025-04-17 11:24:51,149 - INFO - Update relative import complete
2025-04-17 11:24:54,846 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-17 11:24:54,847 - INFO - Generate Unit Test Case complete
2025-04-17 11:24:54,851 - INFO - run_each_pytest_function_individually start
2025-04-17 11:24:58,062 - INFO - Number of test case to process - 6
2025-04-17 11:24:58,063 - INFO - 
TEST CASE 1 Retry 0
---------------
import math
from theory_evaluation.circle_utils import circle_area, circle_circumference
import pytest



def test_circle_area_positive_radius():
    radius = 5
    expected_area = math.pi * radius ** 2
    assert circle_area(radius) == pytest.approx(expected_area)

---------------
2025-04-17 11:24:58,860 - INFO - TEST CASE 1 Retry 0 - Result - Passed
2025-04-17 11:24:58,861 - INFO - 
TEST CASE 2 Retry 0
---------------
import math
from theory_evaluation.circle_utils import circle_area, circle_circumference
import pytest



def test_circle_area_zero_radius():
    radius = 0
    expected_area = 0
    assert circle_area(radius) == pytest.approx(expected_area)

---------------
2025-04-17 11:24:59,749 - INFO - TEST CASE 2 Retry 0 - Result - Passed
2025-04-17 11:24:59,750 - INFO - 
TEST CASE 3 Retry 0
---------------
import math
from theory_evaluation.circle_utils import circle_area, circle_circumference
import pytest



def test_circle_area_negative_radius():
    with pytest.raises(ValueError, match="Radius cannot be negative."):
        circle_area(-1)

---------------
2025-04-17 11:25:00,388 - INFO - TEST CASE 3 Retry 0 - Result - Passed
2025-04-17 11:25:00,389 - INFO - 
TEST CASE 4 Retry 0
---------------
import math
from theory_evaluation.circle_utils import circle_area, circle_circumference
import pytest



def test_circle_circumference_positive_radius():
    radius = 5
    expected_circumference = 2 * math.pi * radius
    assert circle_circumference(radius) == pytest.approx(expected_circumference)

---------------
2025-04-17 11:25:01,064 - INFO - TEST CASE 4 Retry 0 - Result - Passed
2025-04-17 11:25:01,064 - INFO - 
TEST CASE 5 Retry 0
---------------
import math
from theory_evaluation.circle_utils import circle_area, circle_circumference
import pytest



def test_circle_circumference_zero_radius():
    radius = 0
    expected_circumference = 0
    assert circle_circumference(radius) == pytest.approx(expected_circumference)

---------------
2025-04-17 11:25:01,728 - INFO - TEST CASE 5 Retry 0 - Result - Passed
2025-04-17 11:25:01,728 - INFO - 
TEST CASE 6 Retry 0
---------------
import math
from theory_evaluation.circle_utils import circle_area, circle_circumference
import pytest



def test_circle_circumference_negative_radius():
    with pytest.raises(ValueError, match="Radius cannot be negative."):
        circle_circumference(-1)

---------------
2025-04-17 11:25:02,344 - INFO - TEST CASE 6 Retry 0 - Result - Passed
2025-04-17 11:25:02,344 - INFO - Before Improvement
import math
from theory_evaluation.circle_utils import circle_area, circle_circumference
import pytest


import math
from theory_evaluation.circle_utils import circle_area, circle_circumference
import pytest


def test_circle_area_positive_radius():
    radius = 5
    expected_area = math.pi * radius ** 2
    assert circle_area(radius) == pytest.approx(expected_area)

def test_circle_area_zero_radius():
    radius = 0
    expected_area = 0
    assert circle_area(radius) == pytest.approx(expected_area)

def test_circle_area_negative_radius():
    with pytest.raises(ValueError, match="Radius cannot be negative."):
        circle_area(-1)

def test_circle_circumference_positive_radius():
    radius = 5
    expected_circumference = 2 * math.pi * radius
    assert circle_circumference(radius) == pytest.approx(expected_circumference)

def test_circle_circumference_zero_radius():
    radius = 0
    expected_circumference = 0
    assert circle_circumference(radius) == pytest.approx(expected_circumference)

def test_circle_circumference_negative_radius():
    with pytest.raises(ValueError, match="Radius cannot be negative."):
        circle_circumference(-1)

2025-04-17 11:25:05,439 - INFO - After Improvement
import math
from theory_evaluation.circle_utils import circle_area, circle_circumference
import pytest

def test_circle_area_positive_radius():
    radius = 5
    expected_area = math.pi * radius ** 2
    assert circle_area(radius) == pytest.approx(expected_area)

def test_circle_area_zero_radius():
    radius = 0
    expected_area = 0
    assert circle_area(radius) == pytest.approx(expected_area)

def test_circle_area_negative_radius():
    with pytest.raises(ValueError, match="Radius cannot be negative."):
        circle_area(-1)

def test_circle_circumference_positive_radius():
    radius = 5
    expected_circumference = 2 * math.pi * radius
    assert circle_circumference(radius) == pytest.approx(expected_circumference)

def test_circle_circumference_zero_radius():
    radius = 0
    expected_circumference = 0
    assert circle_circumference(radius) == pytest.approx(expected_circumference)

def test_circle_circumference_negative_radius():
    with pytest.raises(ValueError, match="Radius cannot be negative."):
        circle_circumference(-1)
2025-04-17 11:25:06,212 - INFO - Improvement of test cases processed successfully
2025-04-17 11:25:06,213 - INFO - run_each_pytest_function_individually complete
2025-04-17 11:25:06,213 - INFO - Statistic theory_evaluation\circle_utils.py: 
Total test case - 6
Total test case passed - 6
Percentage Passed - 100.0%

2025-04-17 11:25:06,215 - INFO - End Processing file: theory_evaluation\circle_utils.py

2025-04-17 11:25:06,215 - INFO - 
Start Processing file: theory_evaluation\llm_utils.py
2025-04-17 11:25:06,215 - INFO - Extraction of function and class start
2025-04-17 11:25:06,215 - INFO - extraction of function and class complete
2025-04-17 11:25:06,215 - INFO - Generate Unit Test Case starts
2025-04-17 11:25:06,215 - INFO - Extract unique import start
2025-04-17 11:25:06,793 - INFO - Extract unique import complete
2025-04-17 11:25:06,793 - INFO - Update relative import start
2025-04-17 11:25:06,793 - INFO - Update relative import complete
2025-04-17 11:25:10,687 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-17 11:25:10,688 - INFO - Generate Unit Test Case complete
2025-04-17 11:25:10,692 - INFO - run_each_pytest_function_individually start
2025-04-17 11:25:15,895 - INFO - Number of test case to process - 4
2025-04-17 11:25:15,896 - INFO - 
TEST CASE 1 Retry 0
---------------
import os
import re
import yaml
from theory_evaluation.llm_utils import initialise_prompt, initialise_settings
import pytest



def test_initialise_prompt_success():
    agent = "test_agent"
    config_yaml = "key: value"
    prompt_txt = "This is a {$key} prompt."
    expected_prompt = "This is a value prompt."

---------------
2025-04-17 11:25:16,628 - INFO - TEST CASE 1 Retry 0 - Result - Passed
2025-04-17 11:25:16,628 - INFO - 
TEST CASE 2 Retry 0
---------------
import os
import re
import yaml
from theory_evaluation.llm_utils import initialise_prompt, initialise_settings
import pytest



def test_initialise_prompt_no_config_path():
    with patch("theory_evaluation.llm_utils.open", side_effect=FileNotFoundError):
        result = initialise_prompt("non_existent_agent")
        assert result is None

---------------
2025-04-17 11:25:17,185 - INFO - TEST CASE 2 Retry 0 - Result - Failed
2025-04-17 11:25:17,185 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
____________________ test_initialise_prompt_no_config_path ____________________
temp\temp.py:10: in test_initialise_prompt_no_config_path
    with patch("theory_evaluation.llm_utils.open", side_effect=FileNotFoundError):
E   NameError: name 'patch' is not defined
=========================== short test summary info ===========================
FAILED temp/temp.py::test_initialise_prompt_no_config_path - NameError: name ...
1 failed in 0.08s
2025-04-17 11:25:18,262 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-17 11:25:18,262 - INFO - 
TEST CASE 2 Retry 1
---------------
import os
import re
import yaml
from theory_evaluation.llm_utils import initialise_prompt, initialise_settings
import pytest



from unittest.mock import patch

def test_initialise_prompt_no_config_path():
    with patch("theory_evaluation.llm_utils.open", side_effect=FileNotFoundError):
        result = initialise_prompt("non_existent_agent")
        assert result is None

---------------
2025-04-17 11:25:19,033 - INFO - TEST CASE 2 Retry 1 - Result - Passed
2025-04-17 11:25:19,034 - INFO - 
TEST CASE 3 Retry 0
---------------
import os
import re
import yaml
from theory_evaluation.llm_utils import initialise_prompt, initialise_settings
import pytest



def test_initialise_settings_success():
    agent = "test_agent"
    settings_yaml = "key: value"
    expected_settings = {"key": "value"}

---------------
2025-04-17 11:25:19,736 - INFO - TEST CASE 3 Retry 0 - Result - Passed
2025-04-17 11:25:19,736 - INFO - 
TEST CASE 4 Retry 0
---------------
import os
import re
import yaml
from theory_evaluation.llm_utils import initialise_prompt, initialise_settings
import pytest



def test_initialise_settings_no_config_path():
    with patch("theory_evaluation.llm_utils.open", side_effect=FileNotFoundError):
        result = initialise_settings("non_existent_agent")
        assert result is None

---------------
2025-04-17 11:25:20,431 - INFO - TEST CASE 4 Retry 0 - Result - Failed
2025-04-17 11:25:20,431 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
___________________ test_initialise_settings_no_config_path ___________________
temp\temp.py:10: in test_initialise_settings_no_config_path
    with patch("theory_evaluation.llm_utils.open", side_effect=FileNotFoundError):
E   NameError: name 'patch' is not defined
=========================== short test summary info ===========================
FAILED temp/temp.py::test_initialise_settings_no_config_path - NameError: nam...
1 failed in 0.08s
2025-04-17 11:25:21,509 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-17 11:25:21,509 - INFO - 
TEST CASE 4 Retry 1
---------------
import os
import re
import yaml
from theory_evaluation.llm_utils import initialise_prompt, initialise_settings
import pytest



from unittest.mock import patch

def test_initialise_settings_no_config_path():
    with patch("theory_evaluation.llm_utils.open", side_effect=FileNotFoundError):
        result = initialise_settings("non_existent_agent")
        assert result is None

---------------
2025-04-17 11:25:22,212 - INFO - TEST CASE 4 Retry 1 - Result - Passed
2025-04-17 11:25:22,212 - INFO - Before Improvement
import os
import re
import yaml
from theory_evaluation.llm_utils import initialise_prompt, initialise_settings
import pytest


import os
import re
import yaml
from theory_evaluation.llm_utils import initialise_prompt, initialise_settings
import pytest


def test_initialise_prompt_success():
    agent = "test_agent"
    config_yaml = "key: value"
    prompt_txt = "This is a {$key} prompt."
    expected_prompt = "This is a value prompt."

from unittest.mock import patch

def test_initialise_prompt_no_config_path():
    with patch("theory_evaluation.llm_utils.open", side_effect=FileNotFoundError):
        result = initialise_prompt("non_existent_agent")
        assert result is None

def test_initialise_settings_success():
    agent = "test_agent"
    settings_yaml = "key: value"
    expected_settings = {"key": "value"}

from unittest.mock import patch

def test_initialise_settings_no_config_path():
    with patch("theory_evaluation.llm_utils.open", side_effect=FileNotFoundError):
        result = initialise_settings("non_existent_agent")
        assert result is None

2025-04-17 11:25:26,443 - INFO - After Improvement
import yaml
from theory_evaluation.llm_utils import initialise_prompt, initialise_settings
import pytest
from unittest.mock import patch


def test_initialise_prompt_success():
    agent = "test_agent"
    config_yaml = "key: value"
    prompt_txt = "This is a {$key} prompt."
    expected_prompt = "This is a value prompt."


def test_initialise_prompt_no_config_path():
    with patch("theory_evaluation.llm_utils.open", side_effect=FileNotFoundError):
        result = initialise_prompt("non_existent_agent")
        assert result is None


def test_initialise_settings_success():
    agent = "test_agent"
    settings_yaml = "key: value"
    expected_settings = {"key": "value"}


def test_initialise_settings_no_config_path():
    with patch("theory_evaluation.llm_utils.open", side_effect=FileNotFoundError):
        result = initialise_settings("non_existent_agent")
        assert result is None
2025-04-17 11:25:27,344 - INFO - Improvement of test cases processed successfully
2025-04-17 11:25:27,345 - INFO - run_each_pytest_function_individually complete
2025-04-17 11:25:27,345 - INFO - Statistic theory_evaluation\llm_utils.py: 
Total test case - 4
Total test case passed - 4
Percentage Passed - 100.0%

2025-04-17 11:25:27,346 - INFO - End Processing file: theory_evaluation\llm_utils.py

2025-04-17 11:25:27,346 - INFO - 
Start Processing file: theory_evaluation\main.py
2025-04-17 11:25:27,346 - INFO - Extraction of function and class start
2025-04-17 11:25:27,346 - INFO - extraction of function and class complete
2025-04-17 11:25:27,346 - INFO - Generate Unit Test Case starts
2025-04-17 11:25:27,346 - INFO - Extract unique import start
2025-04-17 11:25:28,130 - INFO - Extract unique import complete
2025-04-17 11:25:28,131 - INFO - Update relative import start
2025-04-17 11:25:28,131 - INFO - Update relative import complete
2025-04-17 11:25:32,446 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-17 11:25:32,446 - INFO - Generate Unit Test Case complete
2025-04-17 11:25:32,450 - INFO - run_each_pytest_function_individually start
2025-04-17 11:25:35,209 - INFO - Number of test case to process - 3
2025-04-17 11:25:35,209 - INFO - 
TEST CASE 1 Retry 0
---------------
from theory_evaluation import config
from theory_evaluation.evaluator import general_qa
import fastapi
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import logging
from theory_evaluation.main import health_check, shutdown_event, startup_event
import pytest



def test_health_check():
    response = client.get("/health")
    assert response.status_code == 200
    assert response.json() == {"status": "healthy"}

---------------
2025-04-17 11:25:36,118 - INFO - TEST CASE 1 Retry 0 - Result - Failed
2025-04-17 11:25:36,118 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:1: in <module>
    from theory_evaluation import config
E   ImportError: cannot import name 'config' from 'theory_evaluation' (unknown location)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 0.24s
2025-04-17 11:25:37,300 - INFO - 
TEST CASE 1 Retry 1
---------------
from theory_evaluation import config
from theory_evaluation.evaluator import general_qa
import fastapi
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import logging
from theory_evaluation.main import health_check, shutdown_event, startup_event
import pytest



from fastapi.testclient import TestClient
from temp import APP

client = TestClient(APP)

def test_health_check():
    response = client.get("/health")
    assert response.status_code == 200
    assert response.json() == {"status": "healthy"}

---------------
2025-04-17 11:25:38,155 - INFO - TEST CASE 1 Retry 1 - Result - Failed
2025-04-17 11:25:38,155 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:1: in <module>
    from theory_evaluation import config
E   ImportError: cannot import name 'config' from 'theory_evaluation' (unknown location)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 0.12s
2025-04-17 11:25:39,168 - INFO - 
TEST CASE 1 Retry 2
---------------
from theory_evaluation import config
from theory_evaluation.evaluator import general_qa
import fastapi
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import logging
from theory_evaluation.main import health_check, shutdown_event, startup_event
import pytest



from fastapi.testclient import TestClient
from temp import APP

client = TestClient(APP)

def test_health_check():
    response = client.get("/health")
    assert response.status_code == 200
    assert response.json() == {"status": "healthy"}

---------------
2025-04-17 11:25:39,868 - INFO - TEST CASE 1 Retry 2 - Result - Failed
2025-04-17 11:25:39,868 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:1: in <module>
    from theory_evaluation import config
E   ImportError: cannot import name 'config' from 'theory_evaluation' (unknown location)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 0.12s
2025-04-17 11:25:40,900 - INFO - Failed after all retries for test case 1
2025-04-17 11:25:40,901 - INFO - 
TEST CASE 2 Retry 0
---------------
from theory_evaluation import config
from theory_evaluation.evaluator import general_qa
import fastapi
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import logging
from theory_evaluation.main import health_check, shutdown_event, startup_event
import pytest



@pytest.mark.asyncio
async def test_startup_event():
    with patch.object(logger, 'info') as mock_info:
        await APP.router.startup()
        assert mock_info.called
        assert mock_info.call_args_list[0][0][0] == "Starting up the FastAPI application"

---------------
2025-04-17 11:25:41,659 - INFO - TEST CASE 2 Retry 0 - Result - Failed
2025-04-17 11:25:41,659 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:1: in <module>
    from theory_evaluation import config
E   ImportError: cannot import name 'config' from 'theory_evaluation' (unknown location)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 0.13s
2025-04-17 11:25:43,283 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-17 11:25:43,284 - INFO - 
TEST CASE 2 Retry 1
---------------
from theory_evaluation import config
from theory_evaluation.evaluator import general_qa
import fastapi
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import logging
from theory_evaluation.main import health_check, shutdown_event, startup_event
import pytest



import pytest
from unittest.mock import patch
from fastapi.testclient import TestClient
from your_module_name import APP, logger  # Replace 'your_module_name' with the actual module name

@pytest.mark.asyncio
async def test_startup_event():
    with patch.object(logger, 'info') as mock_info:
        with TestClient(APP) as client:
            await APP.router.startup()
            assert mock_info.called
            assert mock_info.call_args_list[0][0][0] == "Starting up the FastAPI application"

---------------
2025-04-17 11:25:44,046 - INFO - TEST CASE 2 Retry 1 - Result - Failed
2025-04-17 11:25:44,046 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:1: in <module>
    from theory_evaluation import config
E   ImportError: cannot import name 'config' from 'theory_evaluation' (unknown location)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 0.12s
2025-04-17 11:25:46,170 - INFO - 
TEST CASE 2 Retry 2
---------------
from theory_evaluation import config
from theory_evaluation.evaluator import general_qa
import fastapi
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import logging
from theory_evaluation.main import health_check, shutdown_event, startup_event
import pytest



import pytest
from unittest.mock import patch
from fastapi.testclient import TestClient
from your_module_name import APP, logger  # Replace 'your_module_name' with the actual module name

@pytest.mark.asyncio
async def test_startup_event():
    with patch.object(logger, 'info') as mock_info:
        with TestClient(APP) as client:
            await APP.router.startup()
            assert mock_info.called
            assert mock_info.call_args_list[0][0][0] == "Starting up the FastAPI application"

---------------
2025-04-17 11:25:47,098 - INFO - TEST CASE 2 Retry 2 - Result - Failed
2025-04-17 11:25:47,098 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:1: in <module>
    from theory_evaluation import config
E   ImportError: cannot import name 'config' from 'theory_evaluation' (unknown location)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 0.21s
2025-04-17 11:25:48,752 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-17 11:25:48,752 - INFO - Failed after all retries for test case 2
2025-04-17 11:25:48,752 - INFO - 
TEST CASE 3 Retry 0
---------------
from theory_evaluation import config
from theory_evaluation.evaluator import general_qa
import fastapi
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import logging
from theory_evaluation.main import health_check, shutdown_event, startup_event
import pytest



@pytest.mark.asyncio
async def test_shutdown_event():
    with patch.object(logger, 'info') as mock_info:
        await APP.router.shutdown()
        assert mock_info.called
        assert mock_info.call_args_list[0][0][0] == "Shutting down the FastAPI application"

---------------
2025-04-17 11:25:49,602 - INFO - TEST CASE 3 Retry 0 - Result - Failed
2025-04-17 11:25:49,603 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:1: in <module>
    from theory_evaluation import config
E   ImportError: cannot import name 'config' from 'theory_evaluation' (unknown location)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 0.16s
2025-04-17 11:25:51,048 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-17 11:25:51,049 - INFO - 
TEST CASE 3 Retry 1
---------------
from theory_evaluation import config
from theory_evaluation.evaluator import general_qa
import fastapi
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import logging
from theory_evaluation.main import health_check, shutdown_event, startup_event
import pytest



import pytest
from unittest.mock import patch
from fastapi.testclient import TestClient
from temp import APP  # Adjust the import based on your actual module structure

@pytest.mark.asyncio
async def test_shutdown_event():
    with patch.object(logger, 'info') as mock_info:
        await APP.router.shutdown()
        assert mock_info.called
        assert mock_info.call_args_list[0][0][0] == "Shutting down the FastAPI application"

---------------
2025-04-17 11:25:51,783 - INFO - TEST CASE 3 Retry 1 - Result - Failed
2025-04-17 11:25:51,783 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:1: in <module>
    from theory_evaluation import config
E   ImportError: cannot import name 'config' from 'theory_evaluation' (unknown location)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 0.13s
2025-04-17 11:25:53,048 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-17 11:25:53,048 - INFO - 
TEST CASE 3 Retry 2
---------------
from theory_evaluation import config
from theory_evaluation.evaluator import general_qa
import fastapi
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import logging
from theory_evaluation.main import health_check, shutdown_event, startup_event
import pytest



import pytest
from unittest.mock import patch
from fastapi.testclient import TestClient
from theory_evaluation import APP  # Adjust the import based on your actual module structure

@pytest.mark.asyncio
async def test_shutdown_event():
    with patch.object(logger, 'info') as mock_info:
        await APP.router.shutdown()
        assert mock_info.called
        assert mock_info.call_args_list[0][0][0] == "Shutting down the FastAPI application"

---------------
2025-04-17 11:25:53,785 - INFO - TEST CASE 3 Retry 2 - Result - Failed
2025-04-17 11:25:53,785 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:1: in <module>
    from theory_evaluation import config
E   ImportError: cannot import name 'config' from 'theory_evaluation' (unknown location)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 0.14s
2025-04-17 11:25:55,115 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-17 11:25:55,115 - INFO - Failed after all retries for test case 3
2025-04-17 11:25:55,116 - INFO - Before Improvement
from theory_evaluation import config
from theory_evaluation.evaluator import general_qa
import fastapi
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import logging
from theory_evaluation.main import health_check, shutdown_event, startup_event
import pytest


from theory_evaluation import config
from theory_evaluation.evaluator import general_qa
import fastapi
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import logging
from theory_evaluation.main import health_check, shutdown_event, startup_event
import pytest


2025-04-17 11:25:56,205 - INFO - After Improvement
from theory_evaluation import config
from theory_evaluation.evaluator import general_qa
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import logging
from theory_evaluation.main import health_check, shutdown_event, startup_event
import pytest
2025-04-17 11:25:56,937 - INFO - Error in generating improved test cases
Test case:
from theory_evaluation import config
from theory_evaluation.evaluator import general_qa
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import logging
from theory_evaluation.main import health_check, shutdown_event, startup_event
import pytest
Test error:
c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:1: in <module>
    from theory_evaluation import config
E   ImportError: cannot import name 'config' from 'theory_evaluation' (unknown location)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 0.14s
2025-04-17 11:25:56,937 - INFO - run_each_pytest_function_individually complete
2025-04-17 11:25:56,938 - INFO - Statistic theory_evaluation\main.py: 
Total test case - 3
Total test case passed - 0
Percentage Passed - 0.0%

2025-04-17 11:25:56,938 - ERROR - Failed processing theory_evaluation\main.py: 'str' object has no attribute 'relative_to'
2025-04-17 11:25:56,938 - INFO - End Processing file: theory_evaluation\main.py

