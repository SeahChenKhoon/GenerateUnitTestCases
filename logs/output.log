2025-04-15 16:09:16,186 - INFO - Loading environment variables...
2025-04-15 16:09:16,559 - INFO - Start Processing file: theory_evaluation\llm_handler.py
2025-04-15 16:09:18,449 - INFO - function_names - ['OpenAI_llm']
2025-04-15 16:09:18,450 - INFO - source_code_path - theory_evaluation\llm_handler.py
2025-04-15 16:09:28,297 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-15 16:09:39,193 - INFO - 

2025-04-15 16:09:39,194 - INFO - TEST CASE 1 Retry 0
2025-04-15 16:09:39,194 - INFO - ---------------
2025-04-15 16:09:39,194 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest


@pytest.mark.asyncio
async def test_openai_llm_initialization():
    with patch("theory_evaluation.llm_handler.AzureOpenAI") as mock_azure_openai, \
         patch("theory_evaluation.llm_handler.OpenAI") as mock_openai, \
         patch("theory_evaluation.llm_handler.os.getenv", return_value="test_value"):
        
        llm = OpenAI_llm(useAzureOpenAI=True, message="Test message", output="json")
        assert llm.message == "Test message"
        assert llm.output == "json"
        assert llm.client == mock_azure_openai.return_value

2025-04-15 16:09:39,197 - INFO - ---------------
2025-04-15 16:09:41,053 - INFO - Test Result 1- False
2025-04-15 16:09:41,053 - INFO - Test Error 1 - C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
_______________________ test_openai_llm_initialization ________________________
temp\temp.py:12: in test_openai_llm_initialization
    with patch("theory_evaluation.llm_handler.AzureOpenAI") as mock_azure_openai, \
E   NameError: name 'patch' is not defined
=========================== short test summary info ===========================
FAILED temp/temp.py::test_openai_llm_initialization - NameError: name 'patch'...
1 failed in 1.03s
2025-04-15 16:09:43,490 - INFO - TEST CASE 1 Retry 1
2025-04-15 16:09:43,490 - INFO - ---------------
2025-04-15 16:09:43,490 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest

from unittest.mock import patch

@pytest.mark.asyncio
async def test_openai_llm_initialization():
    with patch("theory_evaluation.llm_handler.AzureOpenAI") as mock_azure_openai, \
         patch("theory_evaluation.llm_handler.OpenAI") as mock_openai, \
         patch("theory_evaluation.llm_handler.os.getenv", return_value="test_value"):
        
        llm = OpenAI_llm(useAzureOpenAI=True, message="Test message", output="json")
        assert llm.message == "Test message"
        assert llm.output == "json"
        assert llm.client == mock_azure_openai.return_value

2025-04-15 16:09:43,491 - INFO - ---------------
2025-04-15 16:09:45,797 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-15 16:09:45,797 - INFO - New import Statements 2- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest
from unittest.mock import patch
import pytest
2025-04-15 16:09:45,798 - INFO - Test Result 2- True
2025-04-15 16:09:45,798 - INFO - Test Error 2 - 
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
.                                                                        [100%]
1 passed in 0.91s
2025-04-15 16:09:45,798 - INFO - 

2025-04-15 16:09:45,798 - INFO - TEST CASE 2 Retry 0
2025-04-15 16:09:45,798 - INFO - ---------------
2025-04-15 16:09:45,799 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest
from unittest.mock import patch
import pytest


@pytest.mark.asyncio
async def test_openai_json_completion():
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client") as mock_client:
        mock_response = MagicMock()
        mock_response.choices[0].message.content = json.dumps({"answer": "42", "explanation": "The answer to life"})
        mock_client.chat.completions.create.return_value = mock_response

2025-04-15 16:09:45,799 - INFO - ---------------
2025-04-15 16:09:48,398 - INFO - Test Result 1- False
2025-04-15 16:09:48,398 - INFO - Test Error 1 - C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
_________________________ test_openai_json_completion _________________________
temp\temp.py:14: in test_openai_json_completion
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client") as mock_client:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py:1495: in __enter__
    original, local = self.get_original()
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py:1465: in get_original
    raise AttributeError(
E   AttributeError: <class 'theory_evaluation.llm_handler.OpenAI_llm'> does not have the attribute 'client'
=========================== short test summary info ===========================
FAILED temp/temp.py::test_openai_json_completion - AttributeError: <class 'th...
1 failed in 1.61s
2025-04-15 16:09:50,447 - INFO - TEST CASE 2 Retry 1
2025-04-15 16:09:50,448 - INFO - ---------------
2025-04-15 16:09:50,448 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest
from unittest.mock import patch
import pytest

from unittest.mock import patch, MagicMock
import pytest
import json
from theory_evaluation.llm_handler import OpenAI_llm

@pytest.mark.asyncio
async def test_openai_json_completion():
    with patch.object(OpenAI_llm, 'client', create=True) as mock_client:
        mock_response = MagicMock()
        mock_response.choices[0].message.content = json.dumps({"answer": "42", "explanation": "The answer to life"})
        mock_client.chat.completions.create.return_value = mock_response

        llm = OpenAI_llm()
        result = await llm._OpenAI_JSON_Completion()
        assert result == {"answer": "42", "explanation": "The answer to life"}

2025-04-15 16:09:50,449 - INFO - ---------------
2025-04-15 16:09:52,980 - INFO - Test Result 2- False
2025-04-15 16:09:52,980 - INFO - Test Error 2 - 
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
_________________________ test_openai_json_completion _________________________
temp\temp.py:25: in test_openai_json_completion
    assert result == {"answer": "42", "explanation": "The answer to life"}
E   AssertionError: assert None == {'answer': '42', 'explanation': 'The answer to life'}
---------------------------- Captured stdout call -----------------------------
Failed in _OpenAI_JSON_Completion: Missing required arguments; Expected either ('messages' and 'model') or ('messages', 'model' and 'stream') arguments to be given
=========================== short test summary info ===========================
FAILED temp/temp.py::test_openai_json_completion - AssertionError: assert Non...
1 failed in 1.45s
2025-04-15 16:09:55,538 - INFO - TEST CASE 2 Retry 2
2025-04-15 16:09:55,539 - INFO - ---------------
2025-04-15 16:09:55,539 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest
from unittest.mock import patch
import pytest

import pytest
import json
from unittest.mock import patch, MagicMock
from theory_evaluation.llm_handler import OpenAI_llm

@pytest.mark.asyncio
async def test_openai_json_completion():
    with patch.object(OpenAI_llm, 'client', create=True) as mock_client:
        mock_response = MagicMock()
        mock_response.choices = [MagicMock()]
        mock_response.choices[0].message.content = json.dumps({"answer": "42", "explanation": "The answer to life"})
        mock_client.chat.completions.create.return_value = mock_response

        llm = OpenAI_llm()
        result = await llm._OpenAI_JSON_Completion(messages=[{"role": "system", "content": llm.message}], model=llm.model_name)
        assert result == {"answer": "42", "explanation": "The answer to life"}

2025-04-15 16:09:55,539 - INFO - ---------------
2025-04-15 16:09:58,632 - INFO - Test Result 3- False
2025-04-15 16:09:58,632 - INFO - Test Error 3 - 
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
_________________________ test_openai_json_completion _________________________
temp\temp.py:26: in test_openai_json_completion
    assert result == {"answer": "42", "explanation": "The answer to life"}
E   AssertionError: assert None == {'answer': '42', 'explanation': 'The answer to life'}
---------------------------- Captured stdout call -----------------------------
Failed in _OpenAI_JSON_Completion: Error code: 400 - {'error': {'message': 'you must provide a model parameter', 'type': 'invalid_request_error', 'param': None, 'code': None}}
=========================== short test summary info ===========================
FAILED temp/temp.py::test_openai_json_completion - AssertionError: assert Non...
1 failed in 2.24s
2025-04-15 16:09:58,632 - INFO - Failed after all retries for test case 2
2025-04-15 16:09:58,632 - INFO - 

2025-04-15 16:09:58,632 - INFO - TEST CASE 3 Retry 0
2025-04-15 16:09:58,633 - INFO - ---------------
2025-04-15 16:09:58,633 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest
from unittest.mock import patch
import pytest


@pytest.mark.asyncio
async def test_openai_streaming():
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client") as mock_client:
        mock_stream = [MagicMock(), MagicMock()]
        mock_stream[0].choices[0].delta.content = "Hello"
        mock_stream[1].choices[0].delta.content = "World"
        mock_client.chat.completions.create.return_value = mock_stream

2025-04-15 16:09:58,633 - INFO - ---------------
2025-04-15 16:10:01,422 - INFO - Test Result 1- False
2025-04-15 16:10:01,422 - INFO - Test Error 1 - C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
____________________________ test_openai_streaming ____________________________
temp\temp.py:14: in test_openai_streaming
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client") as mock_client:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py:1495: in __enter__
    original, local = self.get_original()
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py:1465: in get_original
    raise AttributeError(
E   AttributeError: <class 'theory_evaluation.llm_handler.OpenAI_llm'> does not have the attribute 'client'
=========================== short test summary info ===========================
FAILED temp/temp.py::test_openai_streaming - AttributeError: <class 'theory_e...
1 failed in 1.73s
2025-04-15 16:10:03,794 - INFO - TEST CASE 3 Retry 1
2025-04-15 16:10:03,794 - INFO - ---------------
2025-04-15 16:10:03,795 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest
from unittest.mock import patch
import pytest

from unittest.mock import patch, MagicMock
from theory_evaluation.llm_handler import OpenAI_llm

@pytest.mark.asyncio
async def test_openai_streaming():
    with patch.object(OpenAI_llm, 'client') as mock_client:
        mock_stream = [MagicMock(), MagicMock()]
        mock_stream[0].choices[0].delta.content = "Hello"
        mock_stream[1].choices[0].delta.content = "World"
        mock_client.chat.completions.create.return_value = mock_stream

2025-04-15 16:10:03,795 - INFO - ---------------
2025-04-15 16:10:06,366 - INFO - Test Result 2- False
2025-04-15 16:10:06,366 - INFO - Test Error 2 - 
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
____________________________ test_openai_streaming ____________________________
temp\temp.py:16: in test_openai_streaming
    with patch.object(OpenAI_llm, 'client') as mock_client:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py:1495: in __enter__
    original, local = self.get_original()
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py:1465: in get_original
    raise AttributeError(
E   AttributeError: <class 'theory_evaluation.llm_handler.OpenAI_llm'> does not have the attribute 'client'
=========================== short test summary info ===========================
FAILED temp/temp.py::test_openai_streaming - AttributeError: <class 'theory_e...
1 failed in 1.51s
2025-04-15 16:10:08,264 - INFO - TEST CASE 3 Retry 2
2025-04-15 16:10:08,264 - INFO - ---------------
2025-04-15 16:10:08,264 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest
from unittest.mock import patch
import pytest

from unittest.mock import patch, MagicMock
from theory_evaluation.llm_handler import OpenAI_llm
import pytest

@pytest.mark.asyncio
async def test_openai_streaming():
    with patch.object(OpenAI_llm, 'client', create=True) as mock_client:
        mock_stream = [MagicMock(), MagicMock()]
        mock_stream[0].choices[0].delta.content = "Hello"
        mock_stream[1].choices[0].delta.content = "World"
        mock_client.chat.completions.create.return_value = mock_stream

2025-04-15 16:10:08,265 - INFO - ---------------
2025-04-15 16:10:11,121 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-15 16:10:11,121 - INFO - New import Statements 3- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest
from unittest.mock import patch
import pytest
from unittest.mock import patch, MagicMock
from theory_evaluation.llm_handler import OpenAI_llm
import pytest
2025-04-15 16:10:11,122 - INFO - Test Result 3- True
2025-04-15 16:10:11,122 - INFO - Test Error 3 - 
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
.                                                                        [100%]
1 passed in 1.26s
2025-04-15 16:10:11,122 - INFO - 

2025-04-15 16:10:11,122 - INFO - TEST CASE 4 Retry 0
2025-04-15 16:10:11,122 - INFO - ---------------
2025-04-15 16:10:11,122 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest
from unittest.mock import patch
import pytest
from unittest.mock import patch, MagicMock
from theory_evaluation.llm_handler import OpenAI_llm
import pytest


@pytest.mark.asyncio
async def test_openai_chat_completion():
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client") as mock_client:
        mock_response = MagicMock()
        mock_response.choices[0].message.content = "Chat response"
        mock_client.chat.completions.create.return_value = mock_response

2025-04-15 16:10:11,123 - INFO - ---------------
2025-04-15 16:10:13,408 - INFO - Test Result 1- False
2025-04-15 16:10:13,408 - INFO - Test Error 1 - C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
_________________________ test_openai_chat_completion _________________________
temp\temp.py:17: in test_openai_chat_completion
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client") as mock_client:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py:1495: in __enter__
    original, local = self.get_original()
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py:1465: in get_original
    raise AttributeError(
E   AttributeError: <class 'theory_evaluation.llm_handler.OpenAI_llm'> does not have the attribute 'client'
=========================== short test summary info ===========================
FAILED temp/temp.py::test_openai_chat_completion - AttributeError: <class 'th...
1 failed in 1.28s
2025-04-15 16:10:15,485 - INFO - TEST CASE 4 Retry 1
2025-04-15 16:10:15,485 - INFO - ---------------
2025-04-15 16:10:15,486 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest
from unittest.mock import patch
import pytest
from unittest.mock import patch, MagicMock
from theory_evaluation.llm_handler import OpenAI_llm
import pytest

from unittest.mock import MagicMock, patch
from theory_evaluation.llm_handler import OpenAI_llm

@pytest.mark.asyncio
async def test_openai_chat_completion():
    with patch.object(OpenAI_llm, 'client', create=True) as mock_client:
        mock_response = MagicMock()
        mock_response.choices[0].message.content = "Chat response"
        mock_client.chat.completions.create.return_value = mock_response

        llm = OpenAI_llm()
        response = await llm._OpenAI_Chat_Completion(messages=[{"role": "system", "content": "Test message"}], model="test-model")
        assert response == "Chat response"

2025-04-15 16:10:15,486 - INFO - ---------------
2025-04-15 16:10:18,798 - INFO - Test Result 2- False
2025-04-15 16:10:18,798 - INFO - Test Error 2 - 
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
_________________________ test_openai_chat_completion _________________________
temp\temp.py:26: in test_openai_chat_completion
    assert response == "Chat response"
E   AssertionError: assert None == 'Chat response'
---------------------------- Captured stdout call -----------------------------
Failed in _OpenAI_Chat_Completion: Error code: 404 - {'error': {'message': 'The model `test-model` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
=========================== short test summary info ===========================
FAILED temp/temp.py::test_openai_chat_completion - AssertionError: assert Non...
1 failed in 2.28s
2025-04-15 16:10:21,194 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-15 16:10:21,194 - INFO - TEST CASE 4 Retry 2
2025-04-15 16:10:21,195 - INFO - ---------------
2025-04-15 16:10:21,195 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest
from unittest.mock import patch
import pytest
from unittest.mock import patch, MagicMock
from theory_evaluation.llm_handler import OpenAI_llm
import pytest

import pytest
from unittest.mock import MagicMock, patch
from theory_evaluation.llm_handler import OpenAI_llm

@pytest.mark.asyncio
async def test_openai_chat_completion():
    with patch.object(OpenAI_llm, 'client', create=True) as mock_client:
        mock_response = MagicMock()
        mock_response.choices = [MagicMock()]
        mock_response.choices[0].message.content = "Chat response"
        mock_client.chat.completions.create.return_value = mock_response

        llm = OpenAI_llm(model_name="test-model")
        response = await llm._OpenAI_Chat_Completion(messages=[{"role": "system", "content": "Test message"}], model="test-model")
        assert response == "Chat response"

2025-04-15 16:10:21,195 - INFO - ---------------
2025-04-15 16:10:24,588 - INFO - Test Result 3- False
2025-04-15 16:10:24,588 - INFO - Test Error 3 - 
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
_________________________ test_openai_chat_completion _________________________
temp\temp.py:28: in test_openai_chat_completion
    assert response == "Chat response"
E   AssertionError: assert None == 'Chat response'
---------------------------- Captured stdout call -----------------------------
Failed in _OpenAI_Chat_Completion: Error code: 404 - {'error': {'message': 'The model `test-model` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
=========================== short test summary info ===========================
FAILED temp/temp.py::test_openai_chat_completion - AssertionError: assert Non...
1 failed in 2.28s
2025-04-15 16:10:24,588 - INFO - Failed after all retries for test case 4
2025-04-15 16:10:24,588 - INFO - 

2025-04-15 16:10:24,588 - INFO - TEST CASE 5 Retry 0
2025-04-15 16:10:24,588 - INFO - ---------------
2025-04-15 16:10:24,588 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest
from unittest.mock import patch
import pytest
from unittest.mock import patch, MagicMock
from theory_evaluation.llm_handler import OpenAI_llm
import pytest


@pytest.mark.asyncio
async def test_execute_text_generation():
    with patch("theory_evaluation.llm_handler.OpenAI_llm._run") as mock_run:
        mock_run.return_value.__aiter__.return_value = ["response1", "response2"]

2025-04-15 16:10:24,588 - INFO - ---------------
2025-04-15 16:10:26,354 - INFO - Test Result 1- True
2025-04-15 16:10:26,355 - INFO - Test Error 1 - C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
.                                                                        [100%]
1 passed in 1.00s
2025-04-15 16:10:26,355 - INFO - 

2025-04-15 16:10:26,355 - INFO - TEST CASE 6 Retry 0
2025-04-15 16:10:26,355 - INFO - ---------------
2025-04-15 16:10:26,355 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest
from unittest.mock import patch
import pytest
from unittest.mock import patch, MagicMock
from theory_evaluation.llm_handler import OpenAI_llm
import pytest


@pytest.mark.asyncio
async def test_execute_vision():
    with patch("theory_evaluation.llm_handler.OpenAI_llm._run") as mock_run:
        mock_run.return_value.__aiter__.return_value = ["response1", "response2"]

2025-04-15 16:10:26,355 - INFO - ---------------
2025-04-15 16:10:28,373 - INFO - Test Result 1- True
2025-04-15 16:10:28,373 - INFO - Test Error 1 - C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
.                                                                        [100%]
1 passed in 1.09s
2025-04-15 16:10:28,374 - INFO - End Processing file: theory_evaluation\llm_handler.py

2025-04-15 16:10:28,374 - INFO - Start Processing file: theory_evaluation\llm_utils.py
2025-04-15 16:10:29,720 - INFO - function_names - ['initialise_prompt', 'initialise_settings']
2025-04-15 16:10:29,720 - INFO - source_code_path - theory_evaluation\llm_utils.py
2025-04-15 16:10:36,401 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-15 16:10:43,262 - INFO - End Processing file: theory_evaluation\llm_utils.py

2025-04-15 16:10:43,263 - INFO - Start Processing file: theory_evaluation\__init__.py
2025-04-15 16:10:43,264 - WARNING - No public functions found in theory_evaluation\__init__.py. Skipping test generation.

