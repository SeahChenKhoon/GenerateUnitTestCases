2025-04-15 16:21:45,711 - INFO - Loading environment variables...
2025-04-15 16:21:46,105 - INFO - Start Processing file: theory_evaluation\llm_handler.py
2025-04-15 16:22:11,861 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-15 16:22:20,389 - INFO - 

2025-04-15 16:22:20,390 - INFO - TEST CASE 1 Retry 0
2025-04-15 16:22:20,390 - INFO - ---------------
2025-04-15 16:22:20,390 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm


@pytest.mark.asyncio
async def test_openai_llm_initialization():
    with patch("os.getenv", side_effect=lambda key: f"mock_{key}"):
        llm = OpenAI_llm(
            useAzureOpenAI=True,
            message="Test message",
            output="json",
            mode="text_generation",
            verbose=True
        )
        assert llm.message == "Test message"
        assert llm.output == "json"
        assert llm.mode == "text_generation"
        assert llm.verbose is True
        assert hasattr(llm, "client")

2025-04-15 16:22:20,393 - INFO - ---------------
2025-04-15 16:22:23,472 - INFO - Test Result 1- False
2025-04-15 16:22:23,472 - INFO - Test Error 1 - C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
temp\temp.py:9: in <module>
    @pytest.mark.asyncio
E   NameError: name 'pytest' is not defined
=========================== short test summary info ===========================
ERROR temp/temp.py - NameError: name 'pytest' is not defined
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 2.06s
2025-04-15 16:22:25,415 - INFO - TEST CASE 1 Retry 1
2025-04-15 16:22:25,416 - INFO - ---------------
2025-04-15 16:22:25,416 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm

import pytest
from unittest.mock import patch
from llm_handler import OpenAI_llm

@pytest.mark.asyncio
async def test_openai_llm_initialization():
    with patch("os.getenv", side_effect=lambda key: f"mock_{key}"):
        llm = OpenAI_llm(
            useAzureOpenAI=True,
            message="Test message",
            output="json",
            mode="text_generation",
            verbose=True
        )
        assert llm.message == "Test message"
        assert llm.output == "json"
        assert llm.mode == "text_generation"
        assert llm.verbose is True
        assert hasattr(llm, "client")

2025-04-15 16:22:25,416 - INFO - ---------------
2025-04-15 16:22:27,367 - INFO - Test Result 2- False
2025-04-15 16:22:27,367 - INFO - Test Error 2 - 
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:10: in <module>
    from llm_handler import OpenAI_llm
E   ModuleNotFoundError: No module named 'llm_handler'
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 1.00s
2025-04-15 16:22:29,362 - INFO - TEST CASE 1 Retry 2
2025-04-15 16:22:29,362 - INFO - ---------------
2025-04-15 16:22:29,363 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm

import pytest
from unittest.mock import patch
from temp.llm_handler import OpenAI_llm

@pytest.mark.asyncio
async def test_openai_llm_initialization():
    with patch("os.getenv", side_effect=lambda key: f"mock_{key}"):
        llm = OpenAI_llm(
            useAzureOpenAI=True,
            message="Test message",
            output="json",
            mode="text_generation",
            verbose=True
        )
        assert llm.message == "Test message"
        assert llm.output == "json"
        assert llm.mode == "text_generation"
        assert llm.verbose is True
        assert hasattr(llm, "client")

2025-04-15 16:22:29,363 - INFO - ---------------
2025-04-15 16:22:31,369 - INFO - Test Result 3- False
2025-04-15 16:22:31,369 - INFO - Test Error 3 - 
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:10: in <module>
    from temp.llm_handler import OpenAI_llm
E   ModuleNotFoundError: No module named 'temp.llm_handler'; 'temp' is not a package
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 1.17s
2025-04-15 16:22:31,369 - INFO - Failed after all retries for test case 1
2025-04-15 16:22:31,370 - INFO - 

2025-04-15 16:22:31,370 - INFO - TEST CASE 2 Retry 0
2025-04-15 16:22:31,370 - INFO - ---------------
2025-04-15 16:22:31,370 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm


@pytest.mark.asyncio
async def test_openai_llm_execute_text_generation():
    with patch("os.getenv", side_effect=lambda key: f"mock_{key}"), \
         patch("theory_evaluation.llm_handler.OpenAI_llm._run", return_value=asyncio.coroutine(lambda **kwargs: iter(["mock_response"]))) as mock_run:
        llm = OpenAI_llm(
            useAzureOpenAI=True,
            message="Test message",
            output="json",
            mode="text_generation",
            verbose=True
        )
        responses = []
        async for response in llm.execute():
            responses.append(response)
        assert responses == ["mock_response"]
        mock_run.assert_called_once()

2025-04-15 16:22:31,370 - INFO - ---------------
2025-04-15 16:22:33,175 - INFO - Test Result 1- False
2025-04-15 16:22:33,176 - INFO - Test Error 1 - C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
temp\temp.py:9: in <module>
    @pytest.mark.asyncio
E   NameError: name 'pytest' is not defined
=========================== short test summary info ===========================
ERROR temp/temp.py - NameError: name 'pytest' is not defined
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 1.12s
2025-04-15 16:22:35,143 - INFO - TEST CASE 2 Retry 1
2025-04-15 16:22:35,143 - INFO - ---------------
2025-04-15 16:22:35,143 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm

import pytest
import asyncio
from unittest.mock import patch

@pytest.mark.asyncio
async def test_openai_llm_execute_text_generation():
    with patch("os.getenv", side_effect=lambda key: f"mock_{key}"), \
         patch("theory_evaluation.llm_handler.OpenAI_llm._run", return_value=asyncio.coroutine(lambda **kwargs: iter(["mock_response"]))) as mock_run:
        llm = OpenAI_llm(
            useAzureOpenAI=True,
            message="Test message",
            output="json",
            mode="text_generation",
            verbose=True
        )
        responses = []
        async for response in llm.execute():
            responses.append(response)
        assert responses == ["mock_response"]
        mock_run.assert_called_once()

2025-04-15 16:22:35,143 - INFO - ---------------
2025-04-15 16:22:37,523 - INFO - Test Result 2- False
2025-04-15 16:22:37,524 - INFO - Test Error 2 - 
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
___________________ test_openai_llm_execute_text_generation ___________________
temp\temp.py:15: in test_openai_llm_execute_text_generation
    patch("theory_evaluation.llm_handler.OpenAI_llm._run", return_value=asyncio.coroutine(lambda **kwargs: iter(["mock_response"]))) as mock_run:
E   AttributeError: module 'asyncio' has no attribute 'coroutine'. Did you mean: 'coroutines'?
=========================== short test summary info ===========================
FAILED temp/temp.py::test_openai_llm_execute_text_generation - AttributeError...
1 failed in 1.38s
2025-04-15 16:22:40,576 - INFO - TEST CASE 2 Retry 2
2025-04-15 16:22:40,577 - INFO - ---------------
2025-04-15 16:22:40,577 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm

import pytest
from unittest.mock import patch, AsyncMock

@pytest.mark.asyncio
async def test_openai_llm_execute_text_generation():
    with patch("os.getenv", side_effect=lambda key: f"mock_{key}"), \
         patch("theory_evaluation.llm_handler.OpenAI_llm._run", return_value=AsyncMock(return_value=iter(["mock_response"]))) as mock_run:
        llm = OpenAI_llm(
            useAzureOpenAI=True,
            message="Test message",
            output="json",
            mode="text_generation",
            verbose=True
        )
        responses = []
        async for response in llm.execute():
            responses.append(response)
        assert responses == ["mock_response"]
        mock_run.assert_called_once()

2025-04-15 16:22:40,577 - INFO - ---------------
2025-04-15 16:22:43,721 - INFO - Test Result 3- False
2025-04-15 16:22:43,722 - INFO - Test Error 3 - 
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
___________________ test_openai_llm_execute_text_generation ___________________
temp\temp.py:25: in test_openai_llm_execute_text_generation
    assert responses == ["mock_response"]
E   AssertionError: assert [] == ['mock_response']
E     
E     Right contains one more item: 'mock_response'
E     Use -v to get more diff
---------------------------- Captured stdout call -----------------------------
{
    "role": "system",
    "content": "Test message"
}
=========================== short test summary info ===========================
FAILED temp/temp.py::test_openai_llm_execute_text_generation - AssertionError...
1 failed in 1.97s
2025-04-15 16:22:43,722 - INFO - Failed after all retries for test case 2
2025-04-15 16:22:43,722 - INFO - 

2025-04-15 16:22:43,722 - INFO - TEST CASE 3 Retry 0
2025-04-15 16:22:43,722 - INFO - ---------------
2025-04-15 16:22:43,723 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm


@pytest.mark.asyncio
async def test_openai_llm_execute_vision():
    with patch("os.getenv", side_effect=lambda key: f"mock_{key}"), \
         patch("theory_evaluation.llm_handler.OpenAI_llm._run", return_value=asyncio.coroutine(lambda **kwargs: iter(["mock_response"]))) as mock_run:
        llm = OpenAI_llm(
            useAzureOpenAI=True,
            message="Test message",
            image_input="mock_image_input",
            output="json",
            mode="vision",
            verbose=True
        )
        responses = []
        async for response in llm.execute():
            responses.append(response)
        assert responses == ["mock_response"]
        mock_run.assert_called_once()

2025-04-15 16:22:43,723 - INFO - ---------------
2025-04-15 16:22:45,585 - INFO - Test Result 1- False
2025-04-15 16:22:45,586 - INFO - Test Error 1 - C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
temp\temp.py:9: in <module>
    @pytest.mark.asyncio
E   NameError: name 'pytest' is not defined
=========================== short test summary info ===========================
ERROR temp/temp.py - NameError: name 'pytest' is not defined
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 1.10s
2025-04-15 16:22:48,955 - INFO - TEST CASE 3 Retry 1
2025-04-15 16:22:48,956 - INFO - ---------------
2025-04-15 16:22:48,956 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm

import pytest
import asyncio
from unittest.mock import patch

@pytest.mark.asyncio
async def test_openai_llm_execute_vision():
    with patch("os.getenv", side_effect=lambda key: f"mock_{key}"), \
         patch("theory_evaluation.llm_handler.OpenAI_llm._run", return_value=asyncio.coroutine(lambda **kwargs: iter(["mock_response"]))) as mock_run:
        llm = OpenAI_llm(
            useAzureOpenAI=True,
            message="Test message",
            image_input="mock_image_input",
            output="json",
            mode="vision",
            verbose=True
        )
        responses = []
        async for response in llm.execute():
            responses.append(response)
        assert responses == ["mock_response"]
        mock_run.assert_called_once()

2025-04-15 16:22:48,957 - INFO - ---------------
2025-04-15 16:22:50,872 - INFO - Test Result 2- False
2025-04-15 16:22:50,872 - INFO - Test Error 2 - 
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
_______________________ test_openai_llm_execute_vision ________________________
temp\temp.py:15: in test_openai_llm_execute_vision
    patch("theory_evaluation.llm_handler.OpenAI_llm._run", return_value=asyncio.coroutine(lambda **kwargs: iter(["mock_response"]))) as mock_run:
E   AttributeError: module 'asyncio' has no attribute 'coroutine'. Did you mean: 'coroutines'?
=========================== short test summary info ===========================
FAILED temp/temp.py::test_openai_llm_execute_vision - AttributeError: module ...
1 failed in 1.05s
2025-04-15 16:22:52,918 - INFO - TEST CASE 3 Retry 2
2025-04-15 16:22:52,919 - INFO - ---------------
2025-04-15 16:22:52,919 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm

import pytest
import asyncio
from unittest.mock import patch, AsyncMock

@pytest.mark.asyncio
async def test_openai_llm_execute_vision():
    with patch("os.getenv", side_effect=lambda key: f"mock_{key}"), \
         patch("theory_evaluation.llm_handler.OpenAI_llm._run", return_value=AsyncMock(return_value=iter(["mock_response"]))) as mock_run:
        llm = OpenAI_llm(
            useAzureOpenAI=True,
            message="Test message",
            image_input="mock_image_input",
            output="json",
            mode="vision",
            verbose=True
        )
        responses = []
        async for response in llm.execute():
            responses.append(response)
        assert responses == ["mock_response"]
        mock_run.assert_called_once()

2025-04-15 16:22:52,919 - INFO - ---------------
2025-04-15 16:22:55,161 - INFO - Test Result 3- False
2025-04-15 16:22:55,162 - INFO - Test Error 3 - 
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
_______________________ test_openai_llm_execute_vision ________________________
temp\temp.py:27: in test_openai_llm_execute_vision
    assert responses == ["mock_response"]
E   AssertionError: assert [] == ['mock_response']
E     
E     Right contains one more item: 'mock_response'
E     Use -v to get more diff
---------------------------- Captured stdout call -----------------------------
{
    "role": "system",
    "content": "Test message"
}
=========================== short test summary info ===========================
FAILED temp/temp.py::test_openai_llm_execute_vision - AssertionError: assert ...
1 failed in 1.36s
2025-04-15 16:22:55,162 - INFO - Failed after all retries for test case 3
2025-04-15 16:22:55,162 - INFO - 

2025-04-15 16:22:55,162 - INFO - TEST CASE 4 Retry 0
2025-04-15 16:22:55,162 - INFO - ---------------
2025-04-15 16:22:55,163 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm


@pytest.mark.asyncio
async def test_openai_llm_openai_json_completion():
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client.chat.completions.create", return_value=MagicMock(choices=[MagicMock(message=MagicMock(content=json.dumps({"key": "value"})))])):
        llm = OpenAI_llm(message="Test message")
        content = await llm._OpenAI_JSON_Completion()
        assert content == {"key": "value"}

2025-04-15 16:22:55,163 - INFO - ---------------
2025-04-15 16:22:57,810 - INFO - Test Result 1- False
2025-04-15 16:22:57,811 - INFO - Test Error 1 - C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
temp\temp.py:9: in <module>
    @pytest.mark.asyncio
E   NameError: name 'pytest' is not defined
=========================== short test summary info ===========================
ERROR temp/temp.py - NameError: name 'pytest' is not defined
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 1.84s
2025-04-15 16:22:59,889 - INFO - TEST CASE 4 Retry 1
2025-04-15 16:22:59,889 - INFO - ---------------
2025-04-15 16:22:59,889 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm

from unittest.mock import patch, MagicMock
import json
import pytest

@pytest.mark.asyncio
async def test_openai_llm_openai_json_completion():
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client.chat.completions.create", return_value=MagicMock(choices=[MagicMock(message=MagicMock(content=json.dumps({"key": "value"})))])):
        llm = OpenAI_llm(message="Test message")
        content = await llm._OpenAI_JSON_Completion()
        assert content == {"key": "value"}

2025-04-15 16:22:59,889 - INFO - ---------------
2025-04-15 16:23:03,452 - INFO - Test Result 2- False
2025-04-15 16:23:03,453 - INFO - Test Error 2 - 
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
___________________ test_openai_llm_openai_json_completion ____________________
temp\temp.py:14: in test_openai_llm_openai_json_completion
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client.chat.completions.create", return_value=MagicMock(choices=[MagicMock(message=MagicMock(content=json.dumps({"key": "value"})))])):
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py:1479: in __enter__
    self.target = self.getter()
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\pkgutil.py:528: in resolve_name
    result = getattr(result, p)
E   AttributeError: type object 'OpenAI_llm' has no attribute 'client'
=========================== short test summary info ===========================
FAILED temp/temp.py::test_openai_llm_openai_json_completion - AttributeError:...
1 failed in 2.38s
2025-04-15 16:23:08,586 - INFO - TEST CASE 4 Retry 2
2025-04-15 16:23:08,586 - INFO - ---------------
2025-04-15 16:23:08,586 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm

import unittest
from unittest.mock import patch, MagicMock
import json
import pytest
from llm_handler import OpenAI_llm

@pytest.mark.asyncio
async def test_openai_llm_openai_json_completion():
    with patch("llm_handler.OpenAI_llm.client.chat.completions.create", return_value=MagicMock(choices=[MagicMock(message=MagicMock(content=json.dumps({"key": "value"})))])):
        llm = OpenAI_llm(message="Test message")
        content = await llm._OpenAI_JSON_Completion()
        assert content == {"key": "value"}

2025-04-15 16:23:08,587 - INFO - ---------------
2025-04-15 16:23:10,667 - INFO - Test Result 3- False
2025-04-15 16:23:10,667 - INFO - Test Error 3 - 
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:12: in <module>
    from llm_handler import OpenAI_llm
E   ModuleNotFoundError: No module named 'llm_handler'
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 1.21s
2025-04-15 16:23:10,667 - INFO - Failed after all retries for test case 4
2025-04-15 16:23:10,667 - INFO - 

2025-04-15 16:23:10,667 - INFO - TEST CASE 5 Retry 0
2025-04-15 16:23:10,667 - INFO - ---------------
2025-04-15 16:23:10,667 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm


@pytest.mark.asyncio
async def test_openai_llm_openai_streaming():
    mock_chunk = MagicMock(choices=[MagicMock(delta=MagicMock(content="chunk_content"))])
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client.chat.completions.create", return_value=iter([mock_chunk])):
        llm = OpenAI_llm(message="Test message")
        stream_content = []
        async for chunk in llm._OpenAI_Streaming():
            stream_content.append(chunk)
        assert stream_content == ["chunk_content"]

2025-04-15 16:23:10,667 - INFO - ---------------
2025-04-15 16:23:12,415 - INFO - Test Result 1- False
2025-04-15 16:23:12,416 - INFO - Test Error 1 - C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
temp\temp.py:9: in <module>
    @pytest.mark.asyncio
E   NameError: name 'pytest' is not defined
=========================== short test summary info ===========================
ERROR temp/temp.py - NameError: name 'pytest' is not defined
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 1.08s
2025-04-15 16:23:14,415 - INFO - TEST CASE 5 Retry 1
2025-04-15 16:23:14,415 - INFO - ---------------
2025-04-15 16:23:14,415 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm

import pytest
from unittest.mock import MagicMock, patch

@pytest.mark.asyncio
async def test_openai_llm_openai_streaming():
    mock_chunk = MagicMock(choices=[MagicMock(delta=MagicMock(content="chunk_content"))])
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client.chat.completions.create", return_value=iter([mock_chunk])):
        llm = OpenAI_llm(message="Test message")
        stream_content = []
        async for chunk in llm._OpenAI_Streaming():
            stream_content.append(chunk)
        assert stream_content == ["chunk_content"]

2025-04-15 16:23:14,416 - INFO - ---------------
2025-04-15 16:23:16,846 - INFO - Test Result 2- False
2025-04-15 16:23:16,847 - INFO - Test Error 2 - 
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
______________________ test_openai_llm_openai_streaming _______________________
temp\temp.py:14: in test_openai_llm_openai_streaming
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client.chat.completions.create", return_value=iter([mock_chunk])):
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py:1479: in __enter__
    self.target = self.getter()
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\pkgutil.py:528: in resolve_name
    result = getattr(result, p)
E   AttributeError: type object 'OpenAI_llm' has no attribute 'client'
=========================== short test summary info ===========================
FAILED temp/temp.py::test_openai_llm_openai_streaming - AttributeError: type ...
1 failed in 1.37s
2025-04-15 16:23:19,149 - INFO - TEST CASE 5 Retry 2
2025-04-15 16:23:19,150 - INFO - ---------------
2025-04-15 16:23:19,150 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm

import pytest
from unittest.mock import MagicMock, patch
from theory_evaluation.llm_handler import OpenAI_llm

@pytest.mark.asyncio
async def test_openai_llm_openai_streaming():
    mock_chunk = MagicMock(choices=[MagicMock(delta=MagicMock(content="chunk_content"))])
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client.chat.completions.create", return_value=iter([mock_chunk])):
        llm = OpenAI_llm(message="Test message")
        stream_content = []
        async for chunk in llm._OpenAI_Streaming():
            stream_content.append(chunk)
        assert stream_content == ["chunk_content"]

2025-04-15 16:23:19,150 - INFO - ---------------
2025-04-15 16:23:21,896 - INFO - Test Result 3- False
2025-04-15 16:23:21,897 - INFO - Test Error 3 - 
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
______________________ test_openai_llm_openai_streaming _______________________
temp\temp.py:15: in test_openai_llm_openai_streaming
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client.chat.completions.create", return_value=iter([mock_chunk])):
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py:1479: in __enter__
    self.target = self.getter()
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\pkgutil.py:528: in resolve_name
    result = getattr(result, p)
E   AttributeError: type object 'OpenAI_llm' has no attribute 'client'
=========================== short test summary info ===========================
FAILED temp/temp.py::test_openai_llm_openai_streaming - AttributeError: type ...
1 failed in 1.72s
2025-04-15 16:23:21,897 - INFO - Failed after all retries for test case 5
2025-04-15 16:23:21,897 - INFO - 

2025-04-15 16:23:21,897 - INFO - TEST CASE 6 Retry 0
2025-04-15 16:23:21,897 - INFO - ---------------
2025-04-15 16:23:21,898 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm


@pytest.mark.asyncio
async def test_openai_llm_openai_chat_completion():
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client.chat.completions.create", return_value=MagicMock(choices=[MagicMock(message=MagicMock(content="chat_content"))])):
        llm = OpenAI_llm(message="Test message")
        content = await llm._OpenAI_Chat_Completion()
        assert content == "chat_content"

2025-04-15 16:23:21,898 - INFO - ---------------
2025-04-15 16:23:23,982 - INFO - Test Result 1- False
2025-04-15 16:23:23,983 - INFO - Test Error 1 - C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
temp\temp.py:9: in <module>
    @pytest.mark.asyncio
E   NameError: name 'pytest' is not defined
=========================== short test summary info ===========================
ERROR temp/temp.py - NameError: name 'pytest' is not defined
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 1.25s
2025-04-15 16:23:25,665 - INFO - TEST CASE 6 Retry 1
2025-04-15 16:23:25,665 - INFO - ---------------
2025-04-15 16:23:25,666 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm

from unittest.mock import patch, MagicMock
import pytest

@pytest.mark.asyncio
async def test_openai_llm_openai_chat_completion():
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client.chat.completions.create", return_value=MagicMock(choices=[MagicMock(message=MagicMock(content="chat_content"))])):
        llm = OpenAI_llm(message="Test message")
        content = await llm._OpenAI_Chat_Completion()
        assert content == "chat_content"

2025-04-15 16:23:25,666 - INFO - ---------------
2025-04-15 16:23:27,486 - INFO - Test Result 2- False
2025-04-15 16:23:27,486 - INFO - Test Error 2 - 
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
___________________ test_openai_llm_openai_chat_completion ____________________
temp\temp.py:13: in test_openai_llm_openai_chat_completion
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client.chat.completions.create", return_value=MagicMock(choices=[MagicMock(message=MagicMock(content="chat_content"))])):
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py:1479: in __enter__
    self.target = self.getter()
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\pkgutil.py:528: in resolve_name
    result = getattr(result, p)
E   AttributeError: type object 'OpenAI_llm' has no attribute 'client'
=========================== short test summary info ===========================
FAILED temp/temp.py::test_openai_llm_openai_chat_completion - AttributeError:...
1 failed in 1.00s
2025-04-15 16:23:29,565 - INFO - TEST CASE 6 Retry 2
2025-04-15 16:23:29,565 - INFO - ---------------
2025-04-15 16:23:29,565 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm

from unittest.mock import patch, MagicMock
import pytest
from theory_evaluation.llm_handler import OpenAI_llm

@pytest.mark.asyncio
async def test_openai_llm_openai_chat_completion():
    with patch("openai.OpenAI.chat.completions.create", return_value=MagicMock(choices=[MagicMock(message=MagicMock(content="chat_content"))])):
        llm = OpenAI_llm(message="Test message")
        content = await llm._OpenAI_Chat_Completion()
        assert content == "chat_content"

2025-04-15 16:23:29,566 - INFO - ---------------
2025-04-15 16:23:31,605 - INFO - Test Result 3- False
2025-04-15 16:23:31,605 - INFO - Test Error 3 - 
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
___________________ test_openai_llm_openai_chat_completion ____________________
temp\temp.py:14: in test_openai_llm_openai_chat_completion
    with patch("openai.OpenAI.chat.completions.create", return_value=MagicMock(choices=[MagicMock(message=MagicMock(content="chat_content"))])):
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py:1479: in __enter__
    self.target = self.getter()
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\pkgutil.py:528: in resolve_name
    result = getattr(result, p)
E   AttributeError: type object 'OpenAI' has no attribute 'chat'
=========================== short test summary info ===========================
FAILED temp/temp.py::test_openai_llm_openai_chat_completion - AttributeError:...
1 failed in 1.21s
2025-04-15 16:23:31,606 - INFO - Failed after all retries for test case 6
2025-04-15 16:23:31,608 - INFO - End Processing file: theory_evaluation\llm_handler.py

2025-04-15 16:23:31,609 - INFO - Start Processing file: theory_evaluation\llm_utils.py
2025-04-15 16:23:38,410 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-15 16:23:46,183 - INFO - End Processing file: theory_evaluation\llm_utils.py

2025-04-15 16:23:46,183 - INFO - Start Processing file: theory_evaluation\__init__.py
2025-04-15 16:23:46,184 - WARNING - No public functions found in theory_evaluation\__init__.py. Skipping test generation.

