2025-04-15 14:47:38,460 - INFO - Loading environment variables...
2025-04-15 14:47:38,812 - INFO - [1mStart Processing file: theory_evaluation\llm_handler.py[0m
2025-04-15 14:47:50,201 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-15 14:48:03,042 - INFO - 

2025-04-15 14:48:03,042 - INFO - TEST CASE 1 Retry 0
2025-04-15 14:48:03,043 - INFO - ---------------
2025-04-15 14:48:03,043 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
@pytest.fixture
def mock_openai():
    with patch('theory_evaluation.llm_handler.OpenAI') as mock:
        yield mock

@pytest.fixture
def mock_azure_openai():
    with patch('theory_evaluation.llm_handler.AzureOpenAI') as mock:
        yield mock

@pytest.fixture
def mock_os_environ():
    with patch.dict(os.environ, {
        "AZURE_OPENAI_ENDPOINT_SWEDEN": "https://example.com",
        "AZURE_OPENAI_API_VERSION": "v1",
        "AZURE_OPENAI_API_KEY_SWEDEN": "fake_key",
        "OPENAI_API_KEY": "fake_key",
        "AZURE_OPENAI_DEPLOYMENT_NAME": "azure_model",
        "OPENAI_DEPLOYMENT_NAME": "openai_model"
    }):
        yield

@pytest.mark.asyncio
async def test_openai_llm_initialization_with_azure(mock_azure_openai, mock_os_environ):
    llm = OpenAI_llm(useAzureOpenAI=True)
    assert llm.client is mock_azure_openai.return_value
    assert llm.model_name == "azure_model"

2025-04-15 14:48:03,046 - INFO - ---------------
2025-04-15 14:48:04,775 - INFO - Test Result 1- False
2025-04-15 14:48:04,775 - INFO - Test Error 1 - E                                                                        [100%]
=================================== ERRORS ====================================
_________ ERROR at setup of test_openai_llm_initialization_with_azure _________
temp\temp.py:15: in mock_azure_openai
    with patch('theory_evaluation.llm_handler.AzureOpenAI') as mock:
E   NameError: name 'patch' is not defined
============================== warnings summary ===============================
temp\temp.py:30
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py:30: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ===========================
ERROR temp/temp.py::test_openai_llm_initialization_with_azure - NameError: na...
1 warning, 1 error in 1.03s
2025-04-15 14:48:06,169 - INFO - TEST CASE 1 Retry 1
2025-04-15 14:48:06,170 - INFO - ---------------
2025-04-15 14:48:06,170 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
@pytest.fixture
def mock_openai():
    with patch('theory_evaluation.llm_handler.OpenAI') as mock:
        yield mock

@pytest.fixture
def mock_azure_openai():
    with patch('theory_evaluation.llm_handler.AzureOpenAI') as mock:
        yield mock

@pytest.fixture
def mock_os_environ():
    with patch.dict(os.environ, {
        "AZURE_OPENAI_ENDPOINT_SWEDEN": "https://example.com",
        "AZURE_OPENAI_API_VERSION": "v1",
        "AZURE_OPENAI_API_KEY_SWEDEN": "fake_key",
        "OPENAI_API_KEY": "fake_key",
        "AZURE_OPENAI_DEPLOYMENT_NAME": "azure_model",
        "OPENAI_DEPLOYMENT_NAME": "openai_model"
    }):
        yield
from unittest.mock import patch

@pytest.mark.asyncio
async def test_openai_llm_initialization_with_azure(mock_azure_openai, mock_os_environ):
    with patch('theory_evaluation.llm_handler.AzureOpenAI') as mock:
        llm = OpenAI_llm(useAzureOpenAI=True)
        assert llm.client is mock.return_value
        assert llm.model_name == "azure_model"

2025-04-15 14:48:06,170 - INFO - ---------------
2025-04-15 14:48:07,748 - INFO - New import Statements 2- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
2025-04-15 14:48:07,749 - INFO - Test Result 2- True
2025-04-15 14:48:07,749 - INFO - Test Error 2 - 
s                                                                        [100%]
============================== warnings summary ===============================
temp\temp.py:31
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py:31: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

temp/temp.py::test_openai_llm_initialization_with_azure
  C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\python.py:148: PytestUnhandledCoroutineWarning: async def functions are not natively supported and have been skipped.
  You need to install a suitable plugin for your async framework, for example:
    - anyio
    - pytest-asyncio
    - pytest-tornasync
    - pytest-trio
    - pytest-twisted
    warnings.warn(PytestUnhandledCoroutineWarning(msg.format(nodeid)))

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
1 skipped, 2 warnings in 0.92s
2025-04-15 14:48:07,751 - ERROR - Exception occurred while processing test case 1: cannot access local variable 'success_test_cases' where it is not associated with a value
Traceback (most recent call last):
  File "C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\generate_tests.py", line 600, in run_each_pytest_function_individually
    success_test_cases += "\n" + test_case + "\n"
    ^^^^^^^^^^^^^^^^^^
UnboundLocalError: cannot access local variable 'success_test_cases' where it is not associated with a value
2025-04-15 14:48:07,752 - INFO - 

2025-04-15 14:48:07,752 - INFO - TEST CASE 2 Retry 0
2025-04-15 14:48:07,752 - INFO - ---------------
2025-04-15 14:48:07,752 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
@pytest.fixture
def mock_openai():
    with patch('theory_evaluation.llm_handler.OpenAI') as mock:
        yield mock

@pytest.fixture
def mock_azure_openai():
    with patch('theory_evaluation.llm_handler.AzureOpenAI') as mock:
        yield mock

@pytest.fixture
def mock_os_environ():
    with patch.dict(os.environ, {
        "AZURE_OPENAI_ENDPOINT_SWEDEN": "https://example.com",
        "AZURE_OPENAI_API_VERSION": "v1",
        "AZURE_OPENAI_API_KEY_SWEDEN": "fake_key",
        "OPENAI_API_KEY": "fake_key",
        "AZURE_OPENAI_DEPLOYMENT_NAME": "azure_model",
        "OPENAI_DEPLOYMENT_NAME": "openai_model"
    }):
        yield

@pytest.mark.asyncio
async def test_openai_llm_initialization_without_azure(mock_openai, mock_os_environ):
    llm = OpenAI_llm(useAzureOpenAI=False)
    assert llm.client is mock_openai.return_value
    assert llm.model_name == "openai_model"

2025-04-15 14:48:07,753 - INFO - ---------------
2025-04-15 14:48:09,954 - INFO - Test Result 1- False
2025-04-15 14:48:09,955 - INFO - Test Error 1 - E                                                                        [100%]
=================================== ERRORS ====================================
_______ ERROR at setup of test_openai_llm_initialization_without_azure ________
temp\temp.py:10: in mock_openai
    with patch('theory_evaluation.llm_handler.OpenAI') as mock:
E   NameError: name 'patch' is not defined
============================== warnings summary ===============================
temp\temp.py:30
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py:30: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ===========================
ERROR temp/temp.py::test_openai_llm_initialization_without_azure - NameError:...
1 warning, 1 error in 1.38s
2025-04-15 14:48:11,120 - INFO - TEST CASE 2 Retry 1
2025-04-15 14:48:11,121 - INFO - ---------------
2025-04-15 14:48:11,121 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
@pytest.fixture
def mock_openai():
    with patch('theory_evaluation.llm_handler.OpenAI') as mock:
        yield mock

@pytest.fixture
def mock_azure_openai():
    with patch('theory_evaluation.llm_handler.AzureOpenAI') as mock:
        yield mock

@pytest.fixture
def mock_os_environ():
    with patch.dict(os.environ, {
        "AZURE_OPENAI_ENDPOINT_SWEDEN": "https://example.com",
        "AZURE_OPENAI_API_VERSION": "v1",
        "AZURE_OPENAI_API_KEY_SWEDEN": "fake_key",
        "OPENAI_API_KEY": "fake_key",
        "AZURE_OPENAI_DEPLOYMENT_NAME": "azure_model",
        "OPENAI_DEPLOYMENT_NAME": "openai_model"
    }):
        yield
from unittest.mock import patch

@pytest.mark.asyncio
async def test_openai_llm_initialization_without_azure():
    with patch('theory_evaluation.llm_handler.OpenAI') as mock_openai:
        llm = OpenAI_llm(useAzureOpenAI=False)
        assert llm.client is mock_openai.return_value
        assert llm.model_name == "openai_model"

2025-04-15 14:48:11,121 - INFO - ---------------
2025-04-15 14:48:13,864 - INFO - New import Statements 2- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
2025-04-15 14:48:13,864 - INFO - Test Result 2- True
2025-04-15 14:48:13,864 - INFO - Test Error 2 - 
s                                                                        [100%]
============================== warnings summary ===============================
temp\temp.py:31
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py:31: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

temp/temp.py::test_openai_llm_initialization_without_azure
  C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\python.py:148: PytestUnhandledCoroutineWarning: async def functions are not natively supported and have been skipped.
  You need to install a suitable plugin for your async framework, for example:
    - anyio
    - pytest-asyncio
    - pytest-tornasync
    - pytest-trio
    - pytest-twisted
    warnings.warn(PytestUnhandledCoroutineWarning(msg.format(nodeid)))

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
1 skipped, 2 warnings in 1.66s
2025-04-15 14:48:13,864 - ERROR - Exception occurred while processing test case 2: cannot access local variable 'success_test_cases' where it is not associated with a value
Traceback (most recent call last):
  File "C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\generate_tests.py", line 600, in run_each_pytest_function_individually
    success_test_cases += "\n" + test_case + "\n"
    ^^^^^^^^^^^^^^^^^^
UnboundLocalError: cannot access local variable 'success_test_cases' where it is not associated with a value
2025-04-15 14:48:13,865 - INFO - 

2025-04-15 14:48:13,865 - INFO - TEST CASE 3 Retry 0
2025-04-15 14:48:13,865 - INFO - ---------------
2025-04-15 14:48:13,865 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
@pytest.fixture
def mock_openai():
    with patch('theory_evaluation.llm_handler.OpenAI') as mock:
        yield mock

@pytest.fixture
def mock_azure_openai():
    with patch('theory_evaluation.llm_handler.AzureOpenAI') as mock:
        yield mock

@pytest.fixture
def mock_os_environ():
    with patch.dict(os.environ, {
        "AZURE_OPENAI_ENDPOINT_SWEDEN": "https://example.com",
        "AZURE_OPENAI_API_VERSION": "v1",
        "AZURE_OPENAI_API_KEY_SWEDEN": "fake_key",
        "OPENAI_API_KEY": "fake_key",
        "AZURE_OPENAI_DEPLOYMENT_NAME": "azure_model",
        "OPENAI_DEPLOYMENT_NAME": "openai_model"
    }):
        yield

@pytest.mark.asyncio
async def test_openai_json_completion(mock_openai):
    mock_response = MagicMock()
    mock_response.choices[0].message.content = json.dumps({"answer": "42", "explanation": "The answer to everything."})
    mock_openai.return_value.chat.completions.create.return_value = mock_response

2025-04-15 14:48:13,865 - INFO - ---------------
2025-04-15 14:48:15,643 - INFO - Test Result 1- False
2025-04-15 14:48:15,643 - INFO - Test Error 1 - E                                                                        [100%]
=================================== ERRORS ====================================
________________ ERROR at setup of test_openai_json_completion ________________
temp\temp.py:10: in mock_openai
    with patch('theory_evaluation.llm_handler.OpenAI') as mock:
E   NameError: name 'patch' is not defined
============================== warnings summary ===============================
temp\temp.py:30
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py:30: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ===========================
ERROR temp/temp.py::test_openai_json_completion - NameError: name 'patch' is ...
1 warning, 1 error in 1.05s
2025-04-15 14:48:18,451 - INFO - TEST CASE 3 Retry 1
2025-04-15 14:48:18,451 - INFO - ---------------
2025-04-15 14:48:18,452 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
@pytest.fixture
def mock_openai():
    with patch('theory_evaluation.llm_handler.OpenAI') as mock:
        yield mock

@pytest.fixture
def mock_azure_openai():
    with patch('theory_evaluation.llm_handler.AzureOpenAI') as mock:
        yield mock

@pytest.fixture
def mock_os_environ():
    with patch.dict(os.environ, {
        "AZURE_OPENAI_ENDPOINT_SWEDEN": "https://example.com",
        "AZURE_OPENAI_API_VERSION": "v1",
        "AZURE_OPENAI_API_KEY_SWEDEN": "fake_key",
        "OPENAI_API_KEY": "fake_key",
        "AZURE_OPENAI_DEPLOYMENT_NAME": "azure_model",
        "OPENAI_DEPLOYMENT_NAME": "openai_model"
    }):
        yield
from unittest.mock import patch, MagicMock
import json
import pytest

@pytest.fixture
def mock_openai():
    with patch('theory_evaluation.llm_handler.OpenAI') as mock:
        yield mock

@pytest.mark.asyncio
async def test_openai_json_completion(mock_openai):
    mock_response = MagicMock()
    mock_response.choices[0].message.content = json.dumps({"answer": "42", "explanation": "The answer to everything."})
    mock_openai.return_value.chat.completions.create.return_value = mock_response

    # Assuming you have an instance of OpenAI_llm to test
    llm = OpenAI_llm(message="Test message", output="json")
    response = await llm._OpenAI_JSON_Completion()

    assert response == {"answer": "42", "explanation": "The answer to everything."}

2025-04-15 14:48:18,452 - INFO - ---------------
2025-04-15 14:48:20,201 - INFO - New import Statements 2- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
2025-04-15 14:48:20,201 - INFO - Test Result 2- True
2025-04-15 14:48:20,201 - INFO - Test Error 2 - 
s                                                                        [100%]
============================== warnings summary ===============================
temp\temp.py:38
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py:38: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

temp/temp.py::test_openai_json_completion
  C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\python.py:148: PytestUnhandledCoroutineWarning: async def functions are not natively supported and have been skipped.
  You need to install a suitable plugin for your async framework, for example:
    - anyio
    - pytest-asyncio
    - pytest-tornasync
    - pytest-trio
    - pytest-twisted
    warnings.warn(PytestUnhandledCoroutineWarning(msg.format(nodeid)))

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
1 skipped, 2 warnings in 0.91s
2025-04-15 14:48:20,202 - ERROR - Exception occurred while processing test case 3: cannot access local variable 'success_test_cases' where it is not associated with a value
Traceback (most recent call last):
  File "C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\generate_tests.py", line 600, in run_each_pytest_function_individually
    success_test_cases += "\n" + test_case + "\n"
    ^^^^^^^^^^^^^^^^^^
UnboundLocalError: cannot access local variable 'success_test_cases' where it is not associated with a value
2025-04-15 14:48:20,203 - INFO - 

2025-04-15 14:48:20,203 - INFO - TEST CASE 4 Retry 0
2025-04-15 14:48:20,203 - INFO - ---------------
2025-04-15 14:48:20,203 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
@pytest.fixture
def mock_openai():
    with patch('theory_evaluation.llm_handler.OpenAI') as mock:
        yield mock

@pytest.fixture
def mock_azure_openai():
    with patch('theory_evaluation.llm_handler.AzureOpenAI') as mock:
        yield mock

@pytest.fixture
def mock_os_environ():
    with patch.dict(os.environ, {
        "AZURE_OPENAI_ENDPOINT_SWEDEN": "https://example.com",
        "AZURE_OPENAI_API_VERSION": "v1",
        "AZURE_OPENAI_API_KEY_SWEDEN": "fake_key",
        "OPENAI_API_KEY": "fake_key",
        "AZURE_OPENAI_DEPLOYMENT_NAME": "azure_model",
        "OPENAI_DEPLOYMENT_NAME": "openai_model"
    }):
        yield

@pytest.mark.asyncio
async def test_openai_streaming(mock_openai):
    mock_chunk = MagicMock()
    mock_chunk.choices[0].delta.content = "streaming content"
    mock_openai.return_value.chat.completions.create.return_value = [mock_chunk]

2025-04-15 14:48:20,203 - INFO - ---------------
2025-04-15 14:48:22,082 - INFO - Test Result 1- False
2025-04-15 14:48:22,083 - INFO - Test Error 1 - E                                                                        [100%]
=================================== ERRORS ====================================
___________________ ERROR at setup of test_openai_streaming ___________________
temp\temp.py:10: in mock_openai
    with patch('theory_evaluation.llm_handler.OpenAI') as mock:
E   NameError: name 'patch' is not defined
============================== warnings summary ===============================
temp\temp.py:30
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py:30: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ===========================
ERROR temp/temp.py::test_openai_streaming - NameError: name 'patch' is not de...
1 warning, 1 error in 1.10s
2025-04-15 14:48:23,652 - INFO - TEST CASE 4 Retry 1
2025-04-15 14:48:23,653 - INFO - ---------------
2025-04-15 14:48:23,653 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
@pytest.fixture
def mock_openai():
    with patch('theory_evaluation.llm_handler.OpenAI') as mock:
        yield mock

@pytest.fixture
def mock_azure_openai():
    with patch('theory_evaluation.llm_handler.AzureOpenAI') as mock:
        yield mock

@pytest.fixture
def mock_os_environ():
    with patch.dict(os.environ, {
        "AZURE_OPENAI_ENDPOINT_SWEDEN": "https://example.com",
        "AZURE_OPENAI_API_VERSION": "v1",
        "AZURE_OPENAI_API_KEY_SWEDEN": "fake_key",
        "OPENAI_API_KEY": "fake_key",
        "AZURE_OPENAI_DEPLOYMENT_NAME": "azure_model",
        "OPENAI_DEPLOYMENT_NAME": "openai_model"
    }):
        yield
from unittest.mock import patch, MagicMock
import pytest

@pytest.mark.asyncio
async def test_openai_streaming():
    with patch('theory_evaluation.llm_handler.OpenAI') as mock_openai:
        mock_chunk = MagicMock()
        mock_chunk.choices[0].delta.content = "streaming content"
        mock_openai.return_value.chat.completions.create.return_value = [mock_chunk]
        # Add your test logic here to call the function and assert the expected behavior

2025-04-15 14:48:23,653 - INFO - ---------------
2025-04-15 14:48:25,471 - INFO - New import Statements 2- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
2025-04-15 14:48:25,471 - INFO - Test Result 2- True
2025-04-15 14:48:25,471 - INFO - Test Error 2 - 
s                                                                        [100%]
============================== warnings summary ===============================
temp\temp.py:32
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py:32: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

temp/temp.py::test_openai_streaming
  C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\python.py:148: PytestUnhandledCoroutineWarning: async def functions are not natively supported and have been skipped.
  You need to install a suitable plugin for your async framework, for example:
    - anyio
    - pytest-asyncio
    - pytest-tornasync
    - pytest-trio
    - pytest-twisted
    warnings.warn(PytestUnhandledCoroutineWarning(msg.format(nodeid)))

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
1 skipped, 2 warnings in 1.02s
2025-04-15 14:48:25,471 - ERROR - Exception occurred while processing test case 4: cannot access local variable 'success_test_cases' where it is not associated with a value
Traceback (most recent call last):
  File "C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\generate_tests.py", line 600, in run_each_pytest_function_individually
    success_test_cases += "\n" + test_case + "\n"
    ^^^^^^^^^^^^^^^^^^
UnboundLocalError: cannot access local variable 'success_test_cases' where it is not associated with a value
2025-04-15 14:48:25,472 - INFO - 

2025-04-15 14:48:25,472 - INFO - TEST CASE 5 Retry 0
2025-04-15 14:48:25,472 - INFO - ---------------
2025-04-15 14:48:25,472 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
@pytest.fixture
def mock_openai():
    with patch('theory_evaluation.llm_handler.OpenAI') as mock:
        yield mock

@pytest.fixture
def mock_azure_openai():
    with patch('theory_evaluation.llm_handler.AzureOpenAI') as mock:
        yield mock

@pytest.fixture
def mock_os_environ():
    with patch.dict(os.environ, {
        "AZURE_OPENAI_ENDPOINT_SWEDEN": "https://example.com",
        "AZURE_OPENAI_API_VERSION": "v1",
        "AZURE_OPENAI_API_KEY_SWEDEN": "fake_key",
        "OPENAI_API_KEY": "fake_key",
        "AZURE_OPENAI_DEPLOYMENT_NAME": "azure_model",
        "OPENAI_DEPLOYMENT_NAME": "openai_model"
    }):
        yield

@pytest.mark.asyncio
async def test_openai_chat_completion(mock_openai):
    mock_response = MagicMock()
    mock_response.choices[0].message.content = "Chat completion content"
    mock_openai.return_value.chat.completions.create.return_value = mock_response

2025-04-15 14:48:25,472 - INFO - ---------------
2025-04-15 14:48:27,505 - INFO - Test Result 1- False
2025-04-15 14:48:27,505 - INFO - Test Error 1 - E                                                                        [100%]
=================================== ERRORS ====================================
________________ ERROR at setup of test_openai_chat_completion ________________
temp\temp.py:10: in mock_openai
    with patch('theory_evaluation.llm_handler.OpenAI') as mock:
E   NameError: name 'patch' is not defined
============================== warnings summary ===============================
temp\temp.py:30
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py:30: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ===========================
ERROR temp/temp.py::test_openai_chat_completion - NameError: name 'patch' is ...
1 warning, 1 error in 1.25s
2025-04-15 14:48:31,720 - INFO - TEST CASE 5 Retry 1
2025-04-15 14:48:31,720 - INFO - ---------------
2025-04-15 14:48:31,721 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
@pytest.fixture
def mock_openai():
    with patch('theory_evaluation.llm_handler.OpenAI') as mock:
        yield mock

@pytest.fixture
def mock_azure_openai():
    with patch('theory_evaluation.llm_handler.AzureOpenAI') as mock:
        yield mock

@pytest.fixture
def mock_os_environ():
    with patch.dict(os.environ, {
        "AZURE_OPENAI_ENDPOINT_SWEDEN": "https://example.com",
        "AZURE_OPENAI_API_VERSION": "v1",
        "AZURE_OPENAI_API_KEY_SWEDEN": "fake_key",
        "OPENAI_API_KEY": "fake_key",
        "AZURE_OPENAI_DEPLOYMENT_NAME": "azure_model",
        "OPENAI_DEPLOYMENT_NAME": "openai_model"
    }):
        yield
from unittest.mock import patch, MagicMock
import pytest

@pytest.mark.asyncio
async def test_openai_chat_completion():
    with patch('theory_evaluation.llm_handler.OpenAI') as mock_openai:
        mock_response = MagicMock()
        mock_response.choices[0].message.content = "Chat completion content"
        mock_openai.return_value.chat.completions.create.return_value = mock_response

        # Assuming you have an instance of OpenAI_llm to test
        llm = OpenAI_llm()
        response = await llm._OpenAI_Chat_Completion()

        assert response == "Chat completion content"

2025-04-15 14:48:31,722 - INFO - ---------------
2025-04-15 14:48:33,730 - INFO - New import Statements 2- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
2025-04-15 14:48:33,730 - INFO - Test Result 2- True
2025-04-15 14:48:33,730 - INFO - Test Error 2 - 
s                                                                        [100%]
============================== warnings summary ===============================
temp\temp.py:32
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py:32: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

temp/temp.py::test_openai_chat_completion
  C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\python.py:148: PytestUnhandledCoroutineWarning: async def functions are not natively supported and have been skipped.
  You need to install a suitable plugin for your async framework, for example:
    - anyio
    - pytest-asyncio
    - pytest-tornasync
    - pytest-trio
    - pytest-twisted
    warnings.warn(PytestUnhandledCoroutineWarning(msg.format(nodeid)))

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
1 skipped, 2 warnings in 0.98s
2025-04-15 14:48:33,730 - ERROR - Exception occurred while processing test case 5: cannot access local variable 'success_test_cases' where it is not associated with a value
Traceback (most recent call last):
  File "C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\generate_tests.py", line 600, in run_each_pytest_function_individually
    success_test_cases += "\n" + test_case + "\n"
    ^^^^^^^^^^^^^^^^^^
UnboundLocalError: cannot access local variable 'success_test_cases' where it is not associated with a value
2025-04-15 14:48:33,732 - INFO - 

2025-04-15 14:48:33,732 - INFO - TEST CASE 6 Retry 0
2025-04-15 14:48:33,732 - INFO - ---------------
2025-04-15 14:48:33,732 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
@pytest.fixture
def mock_openai():
    with patch('theory_evaluation.llm_handler.OpenAI') as mock:
        yield mock

@pytest.fixture
def mock_azure_openai():
    with patch('theory_evaluation.llm_handler.AzureOpenAI') as mock:
        yield mock

@pytest.fixture
def mock_os_environ():
    with patch.dict(os.environ, {
        "AZURE_OPENAI_ENDPOINT_SWEDEN": "https://example.com",
        "AZURE_OPENAI_API_VERSION": "v1",
        "AZURE_OPENAI_API_KEY_SWEDEN": "fake_key",
        "OPENAI_API_KEY": "fake_key",
        "AZURE_OPENAI_DEPLOYMENT_NAME": "azure_model",
        "OPENAI_DEPLOYMENT_NAME": "openai_model"
    }):
        yield

@pytest.mark.asyncio
async def test_execute_text_generation(mock_openai):
    mock_response = MagicMock()
    mock_response.choices[0].message.content = "Generated text"
    mock_openai.return_value.chat.completions.create.return_value = mock_response

2025-04-15 14:48:33,732 - INFO - ---------------
2025-04-15 14:48:35,482 - INFO - Test Result 1- False
2025-04-15 14:48:35,482 - INFO - Test Error 1 - E                                                                        [100%]
=================================== ERRORS ====================================
_______________ ERROR at setup of test_execute_text_generation ________________
temp\temp.py:10: in mock_openai
    with patch('theory_evaluation.llm_handler.OpenAI') as mock:
E   NameError: name 'patch' is not defined
============================== warnings summary ===============================
temp\temp.py:30
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py:30: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ===========================
ERROR temp/temp.py::test_execute_text_generation - NameError: name 'patch' is...
1 warning, 1 error in 1.05s
2025-04-15 14:48:37,210 - INFO - TEST CASE 6 Retry 1
2025-04-15 14:48:37,210 - INFO - ---------------
2025-04-15 14:48:37,210 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
@pytest.fixture
def mock_openai():
    with patch('theory_evaluation.llm_handler.OpenAI') as mock:
        yield mock

@pytest.fixture
def mock_azure_openai():
    with patch('theory_evaluation.llm_handler.AzureOpenAI') as mock:
        yield mock

@pytest.fixture
def mock_os_environ():
    with patch.dict(os.environ, {
        "AZURE_OPENAI_ENDPOINT_SWEDEN": "https://example.com",
        "AZURE_OPENAI_API_VERSION": "v1",
        "AZURE_OPENAI_API_KEY_SWEDEN": "fake_key",
        "OPENAI_API_KEY": "fake_key",
        "AZURE_OPENAI_DEPLOYMENT_NAME": "azure_model",
        "OPENAI_DEPLOYMENT_NAME": "openai_model"
    }):
        yield
from unittest.mock import patch, MagicMock
import pytest

@pytest.mark.asyncio
async def test_execute_text_generation():
    with patch('theory_evaluation.llm_handler.OpenAI') as mock_openai:
        mock_response = MagicMock()
        mock_response.choices[0].message.content = "Generated text"
        mock_openai.return_value.chat.completions.create.return_value = mock_response

        # Add the rest of your test logic here, such as creating an instance of OpenAI_llm and calling the execute method.

2025-04-15 14:48:37,210 - INFO - ---------------
2025-04-15 14:48:38,819 - INFO - New import Statements 2- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
2025-04-15 14:48:38,819 - INFO - Test Result 2- True
2025-04-15 14:48:38,819 - INFO - Test Error 2 - 
s                                                                        [100%]
============================== warnings summary ===============================
temp\temp.py:32
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py:32: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

temp/temp.py::test_execute_text_generation
  C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\python.py:148: PytestUnhandledCoroutineWarning: async def functions are not natively supported and have been skipped.
  You need to install a suitable plugin for your async framework, for example:
    - anyio
    - pytest-asyncio
    - pytest-tornasync
    - pytest-trio
    - pytest-twisted
    warnings.warn(PytestUnhandledCoroutineWarning(msg.format(nodeid)))

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
1 skipped, 2 warnings in 1.00s
2025-04-15 14:48:38,819 - ERROR - Exception occurred while processing test case 6: cannot access local variable 'success_test_cases' where it is not associated with a value
Traceback (most recent call last):
  File "C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\generate_tests.py", line 600, in run_each_pytest_function_individually
    success_test_cases += "\n" + test_case + "\n"
    ^^^^^^^^^^^^^^^^^^
UnboundLocalError: cannot access local variable 'success_test_cases' where it is not associated with a value
2025-04-15 14:48:38,820 - INFO - 

2025-04-15 14:48:38,820 - INFO - TEST CASE 7 Retry 0
2025-04-15 14:48:38,820 - INFO - ---------------
2025-04-15 14:48:38,820 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
@pytest.fixture
def mock_openai():
    with patch('theory_evaluation.llm_handler.OpenAI') as mock:
        yield mock

@pytest.fixture
def mock_azure_openai():
    with patch('theory_evaluation.llm_handler.AzureOpenAI') as mock:
        yield mock

@pytest.fixture
def mock_os_environ():
    with patch.dict(os.environ, {
        "AZURE_OPENAI_ENDPOINT_SWEDEN": "https://example.com",
        "AZURE_OPENAI_API_VERSION": "v1",
        "AZURE_OPENAI_API_KEY_SWEDEN": "fake_key",
        "OPENAI_API_KEY": "fake_key",
        "AZURE_OPENAI_DEPLOYMENT_NAME": "azure_model",
        "OPENAI_DEPLOYMENT_NAME": "openai_model"
    }):
        yield

@pytest.mark.asyncio
async def test_execute_vision(mock_openai):
    mock_response = MagicMock()
    mock_response.choices[0].message.content = "Vision response"
    mock_openai.return_value.chat.completions.create.return_value = mock_response

2025-04-15 14:48:38,820 - INFO - ---------------
2025-04-15 14:48:40,564 - INFO - Test Result 1- False
2025-04-15 14:48:40,565 - INFO - Test Error 1 - E                                                                        [100%]
=================================== ERRORS ====================================
____________________ ERROR at setup of test_execute_vision ____________________
temp\temp.py:10: in mock_openai
    with patch('theory_evaluation.llm_handler.OpenAI') as mock:
E   NameError: name 'patch' is not defined
============================== warnings summary ===============================
temp\temp.py:30
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py:30: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ===========================
ERROR temp/temp.py::test_execute_vision - NameError: name 'patch' is not defined
1 warning, 1 error in 1.08s
2025-04-15 14:48:42,686 - INFO - TEST CASE 7 Retry 1
2025-04-15 14:48:42,686 - INFO - ---------------
2025-04-15 14:48:42,687 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
@pytest.fixture
def mock_openai():
    with patch('theory_evaluation.llm_handler.OpenAI') as mock:
        yield mock

@pytest.fixture
def mock_azure_openai():
    with patch('theory_evaluation.llm_handler.AzureOpenAI') as mock:
        yield mock

@pytest.fixture
def mock_os_environ():
    with patch.dict(os.environ, {
        "AZURE_OPENAI_ENDPOINT_SWEDEN": "https://example.com",
        "AZURE_OPENAI_API_VERSION": "v1",
        "AZURE_OPENAI_API_KEY_SWEDEN": "fake_key",
        "OPENAI_API_KEY": "fake_key",
        "AZURE_OPENAI_DEPLOYMENT_NAME": "azure_model",
        "OPENAI_DEPLOYMENT_NAME": "openai_model"
    }):
        yield
from unittest.mock import patch, MagicMock

@pytest.mark.asyncio
async def test_execute_vision():
    with patch('theory_evaluation.llm_handler.OpenAI') as mock_openai:
        mock_response = MagicMock()
        mock_response.choices[0].message.content = "Vision response"
        mock_openai.return_value.chat.completions.create.return_value = mock_response

        llm = OpenAI_llm(
            message="Test message",
            mode="vision",
            image_input="test_image_data",
            model_name="test_model",
            output=None
        )

        async for response in llm.execute():
            assert response == "Vision response"

2025-04-15 14:48:42,687 - INFO - ---------------
2025-04-15 14:48:44,382 - INFO - New import Statements 2- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
2025-04-15 14:48:44,382 - INFO - Test Result 2- True
2025-04-15 14:48:44,382 - INFO - Test Error 2 - 
s                                                                        [100%]
============================== warnings summary ===============================
temp\temp.py:31
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py:31: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

temp/temp.py::test_execute_vision
  C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\python.py:148: PytestUnhandledCoroutineWarning: async def functions are not natively supported and have been skipped.
  You need to install a suitable plugin for your async framework, for example:
    - anyio
    - pytest-asyncio
    - pytest-tornasync
    - pytest-trio
    - pytest-twisted
    warnings.warn(PytestUnhandledCoroutineWarning(msg.format(nodeid)))

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
1 skipped, 2 warnings in 0.92s
2025-04-15 14:48:44,383 - ERROR - Exception occurred while processing test case 7: cannot access local variable 'success_test_cases' where it is not associated with a value
Traceback (most recent call last):
  File "C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\generate_tests.py", line 600, in run_each_pytest_function_individually
    success_test_cases += "\n" + test_case + "\n"
    ^^^^^^^^^^^^^^^^^^
UnboundLocalError: cannot access local variable 'success_test_cases' where it is not associated with a value
2025-04-15 14:48:44,384 - ERROR - Failed processing theory_evaluation\llm_handler.py: cannot access local variable 'success_test_cases' where it is not associated with a value
2025-04-15 14:48:44,384 - INFO - [1mEnd Processing file: theory_evaluation\llm_handler.py[0m

2025-04-15 14:48:44,384 - INFO - [1mStart Processing file: theory_evaluation\llm_utils.py[0m
2025-04-15 14:48:51,627 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-15 14:48:55,685 - ERROR - Failed processing theory_evaluation\llm_utils.py: cannot access local variable 'success_test_cases' where it is not associated with a value
2025-04-15 14:48:55,686 - INFO - [1mEnd Processing file: theory_evaluation\llm_utils.py[0m

2025-04-15 14:48:55,686 - INFO - [1mStart Processing file: theory_evaluation\__init__.py[0m
2025-04-15 14:48:55,687 - WARNING - No public functions found in theory_evaluation\__init__.py. Skipping test generation.

