2025-04-17 14:22:54,334 - INFO - Loading environment variables start
2025-04-17 14:22:54,338 - INFO - Loading environment variables completes
2025-04-17 14:22:54,338 - INFO - Initialising of LLM start
2025-04-17 14:22:54,777 - INFO - Initialising of LLM completes
2025-04-17 14:22:54,777 - INFO - Getting python file starts
2025-04-17 14:22:54,778 - INFO - Getting python file completes
2025-04-17 14:22:54,778 - INFO - 
Start Processing file: theory_evaluation\circle_utils.py
2025-04-17 14:22:54,778 - INFO - Extraction of function and class start
2025-04-17 14:22:54,779 - INFO - extraction of function and class complete
2025-04-17 14:22:54,779 - INFO - Generate Unit Test Case starts
2025-04-17 14:22:54,779 - INFO - Extract unique import start
2025-04-17 14:22:56,970 - INFO - Extract unique import complete
2025-04-17 14:22:56,971 - INFO - Update relative import start
2025-04-17 14:22:56,973 - INFO - Update relative import complete
2025-04-17 14:23:01,797 - INFO - Generate Unit Test Case complete
2025-04-17 14:23:01,799 - INFO - run_each_pytest_function_individually start
2025-04-17 14:23:06,693 - INFO - Number of test case to process - 6
2025-04-17 14:23:06,694 - INFO - 
TEST CASE 1 Retry 0
---------------
import math
from theory_evaluation.circle_utils import circle_area, circle_circumference
import pytest



def test_circle_area_returns_correct_value_for_positive_radius():
    # Arrange
    radius = 3.0
    expected_area = math.pi * radius ** 2

---------------
2025-04-17 14:23:07,782 - INFO - TEST CASE 1 Retry 0 - Result - Passed
2025-04-17 14:23:07,783 - INFO - 
TEST CASE 2 Retry 0
---------------
import math
from theory_evaluation.circle_utils import circle_area, circle_circumference
import pytest



def test_circle_area_raises_value_error_for_negative_radius():
    # Arrange
    radius = -1.0

---------------
2025-04-17 14:23:08,849 - INFO - TEST CASE 2 Retry 0 - Result - Passed
2025-04-17 14:23:08,849 - INFO - 
TEST CASE 3 Retry 0
---------------
import math
from theory_evaluation.circle_utils import circle_area, circle_circumference
import pytest



def test_circle_area_returns_zero_for_zero_radius():
    # Arrange
    radius = 0.0
    expected_area = 0.0

---------------
2025-04-17 14:23:09,830 - INFO - TEST CASE 3 Retry 0 - Result - Passed
2025-04-17 14:23:09,830 - INFO - 
TEST CASE 4 Retry 0
---------------
import math
from theory_evaluation.circle_utils import circle_area, circle_circumference
import pytest



def test_circle_circumference_returns_correct_value_for_positive_radius():
    # Arrange
    radius = 3.0
    expected_circumference = 2 * math.pi * radius

---------------
2025-04-17 14:23:10,659 - INFO - TEST CASE 4 Retry 0 - Result - Passed
2025-04-17 14:23:10,659 - INFO - 
TEST CASE 5 Retry 0
---------------
import math
from theory_evaluation.circle_utils import circle_area, circle_circumference
import pytest



def test_circle_circumference_raises_value_error_for_negative_radius():
    # Arrange
    radius = -1.0

---------------
2025-04-17 14:23:11,777 - INFO - TEST CASE 5 Retry 0 - Result - Passed
2025-04-17 14:23:11,777 - INFO - 
TEST CASE 6 Retry 0
---------------
import math
from theory_evaluation.circle_utils import circle_area, circle_circumference
import pytest



def test_circle_circumference_returns_zero_for_zero_radius():
    # Arrange
    radius = 0.0
    expected_circumference = 0.0

---------------
2025-04-17 14:23:12,956 - INFO - TEST CASE 6 Retry 0 - Result - Passed
2025-04-17 14:23:12,957 - INFO - Before Improvement
import math
from theory_evaluation.circle_utils import circle_area, circle_circumference
import pytest


import math
from theory_evaluation.circle_utils import circle_area, circle_circumference
import pytest


def test_circle_area_returns_correct_value_for_positive_radius():
    # Arrange
    radius = 3.0
    expected_area = math.pi * radius ** 2

def test_circle_area_raises_value_error_for_negative_radius():
    # Arrange
    radius = -1.0

def test_circle_area_returns_zero_for_zero_radius():
    # Arrange
    radius = 0.0
    expected_area = 0.0

def test_circle_circumference_returns_correct_value_for_positive_radius():
    # Arrange
    radius = 3.0
    expected_circumference = 2 * math.pi * radius

def test_circle_circumference_raises_value_error_for_negative_radius():
    # Arrange
    radius = -1.0

def test_circle_circumference_returns_zero_for_zero_radius():
    # Arrange
    radius = 0.0
    expected_circumference = 0.0

2025-04-17 14:23:16,728 - INFO - After Improvement
import math
from theory_evaluation.circle_utils import circle_area, circle_circumference
import pytest

def test_circle_area_returns_correct_value_for_positive_radius():
    # Arrange
    radius = 3.0
    expected_area = math.pi * radius ** 2

def test_circle_area_raises_value_error_for_negative_radius():
    # Arrange
    radius = -1.0

def test_circle_area_returns_zero_for_zero_radius():
    # Arrange
    radius = 0.0
    expected_area = 0.0

def test_circle_circumference_returns_correct_value_for_positive_radius():
    # Arrange
    radius = 3.0
    expected_circumference = 2 * math.pi * radius

def test_circle_circumference_raises_value_error_for_negative_radius():
    # Arrange
    radius = -1.0

def test_circle_circumference_returns_zero_for_zero_radius():
    # Arrange
    radius = 0.0
    expected_circumference = 0.0
2025-04-17 14:23:17,769 - INFO - Improvement of test cases processed successfully
2025-04-17 14:23:17,769 - INFO - run_each_pytest_function_individually complete
2025-04-17 14:23:17,769 - INFO - End Processing file: theory_evaluation\circle_utils.py

2025-04-17 14:23:17,769 - INFO - 
Start Processing file: theory_evaluation\llm_utils.py
2025-04-17 14:23:17,770 - INFO - Extraction of function and class start
2025-04-17 14:23:17,770 - INFO - extraction of function and class complete
2025-04-17 14:23:17,770 - INFO - Generate Unit Test Case starts
2025-04-17 14:23:17,770 - INFO - Extract unique import start
2025-04-17 14:23:18,467 - INFO - Extract unique import complete
2025-04-17 14:23:18,468 - INFO - Update relative import start
2025-04-17 14:23:18,468 - INFO - Update relative import complete
2025-04-17 14:23:25,737 - INFO - Generate Unit Test Case complete
2025-04-17 14:23:25,740 - INFO - run_each_pytest_function_individually start
2025-04-17 14:23:33,930 - INFO - Number of test case to process - 5
2025-04-17 14:23:33,931 - INFO - 
TEST CASE 1 Retry 0
---------------
import os
import re
import yaml
from theory_evaluation.llm_utils import initialise_prompt, initialise_settings
import pytest



def test_initialise_prompt_returns_correct_prompt_structure():
    agent = "test_agent"
    config_path = "./theory_evaluation/evaluator/prompts"
    config_data = {'name': 'TestAgent', 'version': '1.0'}
    prompt_data = "Hello, {$name}! Version: {$version}."
    expected_prompt = "Hello, TestAgent! Version: 1.0."

---------------
2025-04-17 14:23:35,103 - INFO - TEST CASE 1 Retry 0 - Result - Passed
2025-04-17 14:23:35,104 - INFO - 
TEST CASE 2 Retry 0
---------------
import os
import re
import yaml
from theory_evaluation.llm_utils import initialise_prompt, initialise_settings
import pytest



def test_initialise_prompt_handles_missing_placeholder():
    agent = "test_agent"
    config_path = "./theory_evaluation/evaluator/prompts"
    config_data = {'name': 'TestAgent'}
    prompt_data = "Hello, {$name}! Version: {$version}."
    expected_prompt = "Hello, TestAgent! Version: {$version}."

---------------
2025-04-17 14:23:36,384 - INFO - TEST CASE 2 Retry 0 - Result - Passed
2025-04-17 14:23:36,385 - INFO - 
TEST CASE 3 Retry 0
---------------
import os
import re
import yaml
from theory_evaluation.llm_utils import initialise_prompt, initialise_settings
import pytest



def test_initialise_prompt_raises_exception_on_file_not_found():
    agent = "non_existent_agent"
    config_path = "./theory_evaluation/evaluator/prompts"

---------------
2025-04-17 14:23:37,325 - INFO - TEST CASE 3 Retry 0 - Result - Passed
2025-04-17 14:23:37,326 - INFO - 
TEST CASE 4 Retry 0
---------------
import os
import re
import yaml
from theory_evaluation.llm_utils import initialise_prompt, initialise_settings
import pytest



def test_initialise_settings_returns_correct_settings():
    agent = "test_agent"
    config_path = "./theory_evaluation/evaluator/prompts"
    settings_data = {'setting1': 'value1', 'setting2': 'value2'}

---------------
2025-04-17 14:23:38,217 - INFO - TEST CASE 4 Retry 0 - Result - Passed
2025-04-17 14:23:38,217 - INFO - 
TEST CASE 5 Retry 0
---------------
import os
import re
import yaml
from theory_evaluation.llm_utils import initialise_prompt, initialise_settings
import pytest



def test_initialise_settings_raises_exception_on_file_not_found():
    agent = "non_existent_agent"
    config_path = "./theory_evaluation/evaluator/prompts"

---------------
2025-04-17 14:23:39,337 - INFO - TEST CASE 5 Retry 0 - Result - Passed
2025-04-17 14:23:39,337 - INFO - Before Improvement
import os
import re
import yaml
from theory_evaluation.llm_utils import initialise_prompt, initialise_settings
import pytest


import os
import re
import yaml
from theory_evaluation.llm_utils import initialise_prompt, initialise_settings
import pytest


def test_initialise_prompt_returns_correct_prompt_structure():
    agent = "test_agent"
    config_path = "./theory_evaluation/evaluator/prompts"
    config_data = {'name': 'TestAgent', 'version': '1.0'}
    prompt_data = "Hello, {$name}! Version: {$version}."
    expected_prompt = "Hello, TestAgent! Version: 1.0."

def test_initialise_prompt_handles_missing_placeholder():
    agent = "test_agent"
    config_path = "./theory_evaluation/evaluator/prompts"
    config_data = {'name': 'TestAgent'}
    prompt_data = "Hello, {$name}! Version: {$version}."
    expected_prompt = "Hello, TestAgent! Version: {$version}."

def test_initialise_prompt_raises_exception_on_file_not_found():
    agent = "non_existent_agent"
    config_path = "./theory_evaluation/evaluator/prompts"

def test_initialise_settings_returns_correct_settings():
    agent = "test_agent"
    config_path = "./theory_evaluation/evaluator/prompts"
    settings_data = {'setting1': 'value1', 'setting2': 'value2'}

def test_initialise_settings_raises_exception_on_file_not_found():
    agent = "non_existent_agent"
    config_path = "./theory_evaluation/evaluator/prompts"

2025-04-17 14:23:44,717 - INFO - After Improvement
import yaml
from theory_evaluation.llm_utils import initialise_prompt, initialise_settings
import pytest


def test_initialise_prompt_returns_correct_prompt_structure():
    agent = "test_agent"
    config_path = "./theory_evaluation/evaluator/prompts"
    config_data = {'name': 'TestAgent', 'version': '1.0'}
    prompt_data = "Hello, {$name}! Version: {$version}."
    expected_prompt = "Hello, TestAgent! Version: 1.0."

def test_initialise_prompt_handles_missing_placeholder():
    agent = "test_agent"
    config_path = "./theory_evaluation/evaluator/prompts"
    config_data = {'name': 'TestAgent'}
    prompt_data = "Hello, {$name}! Version: {$version}."
    expected_prompt = "Hello, TestAgent! Version: {$version}."

def test_initialise_prompt_raises_exception_on_file_not_found():
    agent = "non_existent_agent"
    config_path = "./theory_evaluation/evaluator/prompts"

def test_initialise_settings_returns_correct_settings():
    agent = "test_agent"
    config_path = "./theory_evaluation/evaluator/prompts"
    settings_data = {'setting1': 'value1', 'setting2': 'value2'}

def test_initialise_settings_raises_exception_on_file_not_found():
    agent = "non_existent_agent"
    config_path = "./theory_evaluation/evaluator/prompts"
2025-04-17 14:23:45,918 - INFO - Improvement of test cases processed successfully
2025-04-17 14:23:45,918 - INFO - run_each_pytest_function_individually complete
2025-04-17 14:23:45,918 - INFO - End Processing file: theory_evaluation\llm_utils.py

2025-04-17 14:23:45,919 - INFO -                             filename  ...  percentage_passed (%)
1  theory_evaluation\circle_utils.py  ...                  100.0
2     theory_evaluation\llm_utils.py  ...                  100.0

[2 rows x 4 columns]
2025-04-17 14:23:45,947 - INFO - 
+----+-----------------------------------+---------------------------+--------------------+-------------------------+
|    | filename                          |   total_test_cases_passed |   total_test_cases |   percentage_passed (%) |
+====+===================================+===========================+====================+=========================+
|  1 | theory_evaluation\circle_utils.py |                         6 |                  6 |                     100 |
+----+-----------------------------------+---------------------------+--------------------+-------------------------+
|  2 | theory_evaluation\llm_utils.py    |                         5 |                  5 |                     100 |
+----+-----------------------------------+---------------------------+--------------------+-------------------------+
