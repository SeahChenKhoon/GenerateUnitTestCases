2025-04-14 17:11:17,851 - INFO - Loading environment variables...
2025-04-14 17:11:18,238 - INFO - [1mStart Processing file: theory_evaluation\llm_handler.py[0m
2025-04-14 17:11:29,768 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-14 17:11:29,776 - INFO - 

2025-04-14 17:11:29,776 - INFO - TEST CASE 1 Retry 1
2025-04-14 17:11:29,776 - INFO - ---------------
2025-04-14 17:11:29,776 - INFO - def test_openai_llm_initialization_with_azure(mock_azure_openai, mock_env_vars):
    llm = OpenAI_llm(useAzureOpenAI=True)
    assert llm.client == mock_azure_openai.return_value
    assert llm.model_name == "azure_model"
2025-04-14 17:11:29,777 - INFO - ---------------
2025-04-14 17:11:31,957 - INFO - passed 1- False
2025-04-14 17:11:31,959 - INFO - test_case_error 1 - =================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:6: in <module>
    from theory_evaluation.llm_handler import _OpenAI_Chat_Completion, _OpenAI_JSON_Completion, _OpenAI_Streaming, __init__, _run, execute, main
E   ImportError: cannot import name '_OpenAI_Chat_Completion' from 'theory_evaluation.llm_handler' (C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\llm_handler.py)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 1.30s
2025-04-14 17:11:31,960 - INFO - TEST CASE 1 Retry 2
2025-04-14 17:11:31,960 - INFO - ---------------
2025-04-14 17:11:31,960 - INFO - def test_openai_llm_initialization_with_azure(mock_azure_openai, mock_env_vars):
    llm = OpenAI_llm(useAzureOpenAI=True)
    assert llm.client == mock_azure_openai.return_value
    assert llm.model_name == "azure_model"
2025-04-14 17:11:31,960 - INFO - ---------------
2025-04-14 17:11:32,589 - INFO - missing_import_statement 2- from theory_evaluation.llm_handler import _OpenAI_Chat_Completion
2025-04-14 17:11:32,589 - INFO - new import statement 2- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import _OpenAI_Chat_Completion, _OpenAI_JSON_Completion, _OpenAI_Streaming, __init__, _run, execute, main
from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

2025-04-14 17:11:34,813 - INFO - TEST CASE 1 Retry 3
2025-04-14 17:11:34,813 - INFO - ---------------
2025-04-14 17:11:34,813 - INFO - def test_openai_llm_initialization_with_azure(mock_azure_openai, mock_env_vars):
    llm = OpenAI_llm(useAzureOpenAI=True)
    assert llm.client == mock_azure_openai.return_value
    assert llm.model_name == "azure_model"
2025-04-14 17:11:34,813 - INFO - ---------------
2025-04-14 17:11:35,350 - INFO - missing_import_statement 3- from theory_evaluation.llm_handler import _OpenAI_Chat_Completion
2025-04-14 17:11:35,351 - INFO - new import statement 3- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import _OpenAI_Chat_Completion, _OpenAI_JSON_Completion, _OpenAI_Streaming, __init__, _run, execute, main
from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

2025-04-14 17:11:37,671 - INFO - Failed after all retries for test case 1
2025-04-14 17:11:37,671 - INFO - 

2025-04-14 17:11:37,671 - INFO - TEST CASE 2 Retry 1
2025-04-14 17:11:37,671 - INFO - ---------------
2025-04-14 17:11:37,671 - INFO - def test_openai_llm_initialization_without_azure(mock_openai, mock_env_vars):
    llm = OpenAI_llm(useAzureOpenAI=False)
    assert llm.client == mock_openai.return_value
    assert llm.model_name == "openai_model"
2025-04-14 17:11:37,671 - INFO - ---------------
2025-04-14 17:11:39,776 - INFO - passed 1- False
2025-04-14 17:11:39,776 - INFO - test_case_error 1 - =================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:6: in <module>
    from theory_evaluation.llm_handler import _OpenAI_Chat_Completion, _OpenAI_JSON_Completion, _OpenAI_Streaming, __init__, _run, execute, main
E   ImportError: cannot import name '_OpenAI_Chat_Completion' from 'theory_evaluation.llm_handler' (C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\llm_handler.py)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 1.31s
2025-04-14 17:11:39,777 - INFO - TEST CASE 2 Retry 2
2025-04-14 17:11:39,777 - INFO - ---------------
2025-04-14 17:11:39,777 - INFO - def test_openai_llm_initialization_without_azure(mock_openai, mock_env_vars):
    llm = OpenAI_llm(useAzureOpenAI=False)
    assert llm.client == mock_openai.return_value
    assert llm.model_name == "openai_model"
2025-04-14 17:11:39,777 - INFO - ---------------
2025-04-14 17:11:40,344 - INFO - missing_import_statement 2- from theory_evaluation.llm_handler import _OpenAI_Chat_Completion
2025-04-14 17:11:40,345 - INFO - new import statement 2- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import _OpenAI_Chat_Completion, _OpenAI_JSON_Completion, _OpenAI_Streaming, __init__, _run, execute, main
from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

2025-04-14 17:11:42,397 - INFO - TEST CASE 2 Retry 3
2025-04-14 17:11:42,398 - INFO - ---------------
2025-04-14 17:11:42,398 - INFO - def test_openai_llm_initialization_without_azure(mock_openai, mock_env_vars):
    llm = OpenAI_llm(useAzureOpenAI=False)
    assert llm.client == mock_openai.return_value
    assert llm.model_name == "openai_model"
2025-04-14 17:11:42,398 - INFO - ---------------
2025-04-14 17:11:43,078 - INFO - missing_import_statement 3- from theory_evaluation.llm_handler import _OpenAI_Chat_Completion
2025-04-14 17:11:43,078 - INFO - new import statement 3- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import _OpenAI_Chat_Completion, _OpenAI_JSON_Completion, _OpenAI_Streaming, __init__, _run, execute, main
from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

2025-04-14 17:11:45,863 - INFO - Failed after all retries for test case 2
2025-04-14 17:11:45,863 - INFO - 

2025-04-14 17:11:45,863 - INFO - TEST CASE 3 Retry 1
2025-04-14 17:11:45,863 - INFO - ---------------
2025-04-14 17:11:45,863 - INFO - def test_openai_json_completion(mock_openai):
    mock_response = MagicMock()
    mock_response.choices[0].message.content = json.dumps({"key": "value"})
    mock_openai.return_value.chat.completions.create = AsyncMock(return_value=mock_response)
2025-04-14 17:11:45,863 - INFO - ---------------
2025-04-14 17:11:49,391 - INFO - passed 1- False
2025-04-14 17:11:49,391 - INFO - test_case_error 1 - =================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:6: in <module>
    from theory_evaluation.llm_handler import _OpenAI_Chat_Completion, _OpenAI_JSON_Completion, _OpenAI_Streaming, __init__, _run, execute, main
E   ImportError: cannot import name '_OpenAI_Chat_Completion' from 'theory_evaluation.llm_handler' (C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\llm_handler.py)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 2.20s
2025-04-14 17:11:49,392 - INFO - TEST CASE 3 Retry 2
2025-04-14 17:11:49,392 - INFO - ---------------
2025-04-14 17:11:49,392 - INFO - def test_openai_json_completion(mock_openai):
    mock_response = MagicMock()
    mock_response.choices[0].message.content = json.dumps({"key": "value"})
    mock_openai.return_value.chat.completions.create = AsyncMock(return_value=mock_response)
2025-04-14 17:11:49,392 - INFO - ---------------
2025-04-14 17:11:50,646 - INFO - missing_import_statement 2- ''
2025-04-14 17:11:50,647 - INFO - new import statement 2- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import _OpenAI_Chat_Completion, _OpenAI_JSON_Completion, _OpenAI_Streaming, __init__, _run, execute, main
from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

''

2025-04-14 17:11:52,741 - INFO - TEST CASE 3 Retry 3
2025-04-14 17:11:52,741 - INFO - ---------------
2025-04-14 17:11:52,741 - INFO - def test_openai_json_completion(mock_openai):
    mock_response = MagicMock()
    mock_response.choices[0].message.content = json.dumps({"key": "value"})
    mock_openai.return_value.chat.completions.create = AsyncMock(return_value=mock_response)
2025-04-14 17:11:52,741 - INFO - ---------------
2025-04-14 17:11:55,027 - INFO - missing_import_statement 3- from theory_evaluation.llm_handler import _OpenAI_JSON_Completion
2025-04-14 17:11:55,028 - INFO - new import statement 3- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import _OpenAI_Chat_Completion, _OpenAI_JSON_Completion, _OpenAI_Streaming, __init__, _run, execute, main
from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

''

from theory_evaluation.llm_handler import _OpenAI_JSON_Completion

2025-04-14 17:11:57,062 - INFO - Failed after all retries for test case 3
2025-04-14 17:11:57,062 - INFO - 

2025-04-14 17:11:57,062 - INFO - TEST CASE 4 Retry 1
2025-04-14 17:11:57,062 - INFO - ---------------
2025-04-14 17:11:57,062 - INFO - def test_openai_streaming(mock_openai):
    mock_chunk = MagicMock()
    mock_chunk.choices[0].delta.content = "streamed content"
    mock_openai.return_value.chat.completions.create = AsyncMock(return_value=[mock_chunk])
2025-04-14 17:11:57,062 - INFO - ---------------
2025-04-14 17:11:59,047 - INFO - passed 1- False
2025-04-14 17:11:59,047 - INFO - test_case_error 1 - =================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:6: in <module>
    from theory_evaluation.llm_handler import _OpenAI_Chat_Completion, _OpenAI_JSON_Completion, _OpenAI_Streaming, __init__, _run, execute, main
E   ImportError: cannot import name '_OpenAI_Chat_Completion' from 'theory_evaluation.llm_handler' (C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\llm_handler.py)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 1.33s
2025-04-14 17:11:59,047 - INFO - TEST CASE 4 Retry 2
2025-04-14 17:11:59,048 - INFO - ---------------
2025-04-14 17:11:59,048 - INFO - def test_openai_streaming(mock_openai):
    mock_chunk = MagicMock()
    mock_chunk.choices[0].delta.content = "streamed content"
    mock_openai.return_value.chat.completions.create = AsyncMock(return_value=[mock_chunk])
2025-04-14 17:11:59,048 - INFO - ---------------
2025-04-14 17:11:59,549 - INFO - missing_import_statement 2- from theory_evaluation.llm_handler import _OpenAI_Chat_Completion
2025-04-14 17:11:59,549 - INFO - new import statement 2- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import _OpenAI_Chat_Completion, _OpenAI_JSON_Completion, _OpenAI_Streaming, __init__, _run, execute, main
from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

''

from theory_evaluation.llm_handler import _OpenAI_JSON_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

2025-04-14 17:12:01,406 - INFO - TEST CASE 4 Retry 3
2025-04-14 17:12:01,406 - INFO - ---------------
2025-04-14 17:12:01,406 - INFO - def test_openai_streaming(mock_openai):
    mock_chunk = MagicMock()
    mock_chunk.choices[0].delta.content = "streamed content"
    mock_openai.return_value.chat.completions.create = AsyncMock(return_value=[mock_chunk])
2025-04-14 17:12:01,406 - INFO - ---------------
2025-04-14 17:12:02,585 - INFO - missing_import_statement 3- from theory_evaluation.llm_handler import _OpenAI_Chat_Completion
2025-04-14 17:12:02,585 - INFO - new import statement 3- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import _OpenAI_Chat_Completion, _OpenAI_JSON_Completion, _OpenAI_Streaming, __init__, _run, execute, main
from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

''

from theory_evaluation.llm_handler import _OpenAI_JSON_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

2025-04-14 17:12:05,125 - INFO - Failed after all retries for test case 4
2025-04-14 17:12:05,125 - INFO - 

2025-04-14 17:12:05,125 - INFO - TEST CASE 5 Retry 1
2025-04-14 17:12:05,125 - INFO - ---------------
2025-04-14 17:12:05,125 - INFO - def test_openai_chat_completion(mock_openai):
    mock_response = MagicMock()
    mock_response.choices[0].message.content = "chat content"
    mock_openai.return_value.chat.completions.create = AsyncMock(return_value=mock_response)
2025-04-14 17:12:05,125 - INFO - ---------------
2025-04-14 17:12:07,839 - INFO - passed 1- False
2025-04-14 17:12:07,839 - INFO - test_case_error 1 - =================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:6: in <module>
    from theory_evaluation.llm_handler import _OpenAI_Chat_Completion, _OpenAI_JSON_Completion, _OpenAI_Streaming, __init__, _run, execute, main
E   ImportError: cannot import name '_OpenAI_Chat_Completion' from 'theory_evaluation.llm_handler' (C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\llm_handler.py)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 1.46s
2025-04-14 17:12:07,839 - INFO - TEST CASE 5 Retry 2
2025-04-14 17:12:07,839 - INFO - ---------------
2025-04-14 17:12:07,840 - INFO - def test_openai_chat_completion(mock_openai):
    mock_response = MagicMock()
    mock_response.choices[0].message.content = "chat content"
    mock_openai.return_value.chat.completions.create = AsyncMock(return_value=mock_response)
2025-04-14 17:12:07,840 - INFO - ---------------
2025-04-14 17:12:09,285 - INFO - missing_import_statement 2- from theory_evaluation.llm_handler import _OpenAI_Chat_Completion
2025-04-14 17:12:09,286 - INFO - new import statement 2- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import _OpenAI_Chat_Completion, _OpenAI_JSON_Completion, _OpenAI_Streaming, __init__, _run, execute, main
from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

''

from theory_evaluation.llm_handler import _OpenAI_JSON_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

2025-04-14 17:12:11,406 - INFO - TEST CASE 5 Retry 3
2025-04-14 17:12:11,407 - INFO - ---------------
2025-04-14 17:12:11,407 - INFO - def test_openai_chat_completion(mock_openai):
    mock_response = MagicMock()
    mock_response.choices[0].message.content = "chat content"
    mock_openai.return_value.chat.completions.create = AsyncMock(return_value=mock_response)
2025-04-14 17:12:11,407 - INFO - ---------------
2025-04-14 17:12:11,919 - INFO - missing_import_statement 3- from theory_evaluation.llm_handler import _OpenAI_Chat_Completion
2025-04-14 17:12:11,920 - INFO - new import statement 3- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import _OpenAI_Chat_Completion, _OpenAI_JSON_Completion, _OpenAI_Streaming, __init__, _run, execute, main
from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

''

from theory_evaluation.llm_handler import _OpenAI_JSON_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

2025-04-14 17:12:14,083 - INFO - Failed after all retries for test case 5
2025-04-14 17:12:14,084 - INFO - 

2025-04-14 17:12:14,084 - INFO - TEST CASE 6 Retry 1
2025-04-14 17:12:14,084 - INFO - ---------------
2025-04-14 17:12:14,084 - INFO - def test_execute_text_generation(mock_openai):
    mock_response = MagicMock()
    mock_response.choices[0].message.content = "response content"
    mock_openai.return_value.chat.completions.create = AsyncMock(return_value=mock_response)
2025-04-14 17:12:14,084 - INFO - ---------------
2025-04-14 17:12:16,562 - INFO - passed 1- False
2025-04-14 17:12:16,562 - INFO - test_case_error 1 - =================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:6: in <module>
    from theory_evaluation.llm_handler import _OpenAI_Chat_Completion, _OpenAI_JSON_Completion, _OpenAI_Streaming, __init__, _run, execute, main
E   ImportError: cannot import name '_OpenAI_Chat_Completion' from 'theory_evaluation.llm_handler' (C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\llm_handler.py)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 1.37s
2025-04-14 17:12:16,562 - INFO - TEST CASE 6 Retry 2
2025-04-14 17:12:16,562 - INFO - ---------------
2025-04-14 17:12:16,563 - INFO - def test_execute_text_generation(mock_openai):
    mock_response = MagicMock()
    mock_response.choices[0].message.content = "response content"
    mock_openai.return_value.chat.completions.create = AsyncMock(return_value=mock_response)
2025-04-14 17:12:16,563 - INFO - ---------------
2025-04-14 17:12:18,933 - INFO - missing_import_statement 2- from theory_evaluation.llm_handler import _OpenAI_Chat_Completion
2025-04-14 17:12:18,933 - INFO - new import statement 2- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import _OpenAI_Chat_Completion, _OpenAI_JSON_Completion, _OpenAI_Streaming, __init__, _run, execute, main
from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

''

from theory_evaluation.llm_handler import _OpenAI_JSON_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

2025-04-14 17:12:21,015 - INFO - TEST CASE 6 Retry 3
2025-04-14 17:12:21,016 - INFO - ---------------
2025-04-14 17:12:21,016 - INFO - def test_execute_text_generation(mock_openai):
    mock_response = MagicMock()
    mock_response.choices[0].message.content = "response content"
    mock_openai.return_value.chat.completions.create = AsyncMock(return_value=mock_response)
2025-04-14 17:12:21,016 - INFO - ---------------
2025-04-14 17:12:21,791 - INFO - missing_import_statement 3- from theory_evaluation.llm_handler import _OpenAI_Chat_Completion
2025-04-14 17:12:21,791 - INFO - new import statement 3- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import _OpenAI_Chat_Completion, _OpenAI_JSON_Completion, _OpenAI_Streaming, __init__, _run, execute, main
from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

''

from theory_evaluation.llm_handler import _OpenAI_JSON_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

2025-04-14 17:12:24,255 - INFO - Failed after all retries for test case 6
2025-04-14 17:12:24,256 - INFO - 

2025-04-14 17:12:24,256 - INFO - TEST CASE 7 Retry 1
2025-04-14 17:12:24,256 - INFO - ---------------
2025-04-14 17:12:24,256 - INFO - def test_execute_vision(mock_openai):
    mock_response = MagicMock()
    mock_response.choices[0].message.content = "response content"
    mock_openai.return_value.chat.completions.create = AsyncMock(return_value=mock_response)
2025-04-14 17:12:24,256 - INFO - ---------------
2025-04-14 17:12:27,050 - INFO - passed 1- False
2025-04-14 17:12:27,050 - INFO - test_case_error 1 - =================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:6: in <module>
    from theory_evaluation.llm_handler import _OpenAI_Chat_Completion, _OpenAI_JSON_Completion, _OpenAI_Streaming, __init__, _run, execute, main
E   ImportError: cannot import name '_OpenAI_Chat_Completion' from 'theory_evaluation.llm_handler' (C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\llm_handler.py)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 1.79s
2025-04-14 17:12:27,051 - INFO - TEST CASE 7 Retry 2
2025-04-14 17:12:27,051 - INFO - ---------------
2025-04-14 17:12:27,051 - INFO - def test_execute_vision(mock_openai):
    mock_response = MagicMock()
    mock_response.choices[0].message.content = "response content"
    mock_openai.return_value.chat.completions.create = AsyncMock(return_value=mock_response)
2025-04-14 17:12:27,051 - INFO - ---------------
2025-04-14 17:12:28,548 - INFO - missing_import_statement 2- from theory_evaluation.llm_handler import _OpenAI_Chat_Completion
2025-04-14 17:12:28,548 - INFO - new import statement 2- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import _OpenAI_Chat_Completion, _OpenAI_JSON_Completion, _OpenAI_Streaming, __init__, _run, execute, main
from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

''

from theory_evaluation.llm_handler import _OpenAI_JSON_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

2025-04-14 17:12:31,549 - INFO - TEST CASE 7 Retry 3
2025-04-14 17:12:31,550 - INFO - ---------------
2025-04-14 17:12:31,550 - INFO - def test_execute_vision(mock_openai):
    mock_response = MagicMock()
    mock_response.choices[0].message.content = "response content"
    mock_openai.return_value.chat.completions.create = AsyncMock(return_value=mock_response)
2025-04-14 17:12:31,550 - INFO - ---------------
2025-04-14 17:12:32,084 - INFO - missing_import_statement 3- from theory_evaluation.llm_handler import _OpenAI_Chat_Completion
2025-04-14 17:12:32,085 - INFO - new import statement 3- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import _OpenAI_Chat_Completion, _OpenAI_JSON_Completion, _OpenAI_Streaming, __init__, _run, execute, main
from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

''

from theory_evaluation.llm_handler import _OpenAI_JSON_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

from theory_evaluation.llm_handler import _OpenAI_Chat_Completion

2025-04-14 17:12:34,246 - INFO - Failed after all retries for test case 7
2025-04-14 17:12:34,247 - INFO - [1mEnd Processing file: theory_evaluation\llm_handler.py[0m

2025-04-14 17:12:34,247 - INFO - [1mStart Processing file: theory_evaluation\llm_utils.py[0m
2025-04-14 17:12:41,539 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-14 17:12:41,545 - INFO - 

2025-04-14 17:12:41,546 - INFO - TEST CASE 1 Retry 1
2025-04-14 17:12:41,546 - INFO - ---------------
2025-04-14 17:12:41,546 - INFO - def test_initialise_prompt_success():
    agent = "test_agent"
    config_values = {'key1': 'value1', 'key2': 'value2'}
    prompt_structure = "This is a {$key1} and {$key2} test."
2025-04-14 17:12:41,546 - INFO - ---------------
2025-04-14 17:12:42,170 - INFO - passed 1- True
2025-04-14 17:12:42,170 - INFO - test_case_error 1 - .                                                                        [100%]
1 passed in 0.03s
2025-04-14 17:12:42,170 - INFO - 

2025-04-14 17:12:42,170 - INFO - TEST CASE 2 Retry 1
2025-04-14 17:12:42,170 - INFO - ---------------
2025-04-14 17:12:42,170 - INFO - def test_initialise_prompt_file_not_found():
    agent = "test_agent"
    with patch('theory_evaluation.llm_utils.open', side_effect=FileNotFoundError):
        result = initialise_prompt(agent)
        assert result is None
2025-04-14 17:12:42,170 - INFO - ---------------
2025-04-14 17:12:42,896 - INFO - passed 1- False
2025-04-14 17:12:42,896 - INFO - test_case_error 1 - F                                                                        [100%]
================================== FAILURES ===================================
____________________ test_initialise_prompt_file_not_found ____________________
temp\temp.py:8: in test_initialise_prompt_file_not_found
    with patch('theory_evaluation.llm_utils.open', side_effect=FileNotFoundError):
E   NameError: name 'patch' is not defined
=========================== short test summary info ===========================
FAILED temp/temp.py::test_initialise_prompt_file_not_found - NameError: name ...
1 failed in 0.22s
2025-04-14 17:12:42,896 - INFO - TEST CASE 2 Retry 2
2025-04-14 17:12:42,897 - INFO - ---------------
2025-04-14 17:12:42,897 - INFO - def test_initialise_prompt_file_not_found():
    agent = "test_agent"
    with patch('theory_evaluation.llm_utils.open', side_effect=FileNotFoundError):
        result = initialise_prompt(agent)
        assert result is None
2025-04-14 17:12:42,897 - INFO - ---------------
2025-04-14 17:12:43,343 - INFO - missing_import_statement 2- from unittest.mock import patch
2025-04-14 17:12:43,343 - INFO - new import statement 2- import os
import re
import yaml
from theory_evaluation.llm_utils import initialise_prompt, initialise_settings
from unittest.mock import patch

2025-04-14 17:12:44,492 - INFO - passed 2- True
2025-04-14 17:12:44,492 - INFO - test_case_error 2 - .                                                                        [100%]
1 passed in 0.25s
2025-04-14 17:12:44,492 - INFO - 

2025-04-14 17:12:44,492 - INFO - TEST CASE 3 Retry 1
2025-04-14 17:12:44,492 - INFO - ---------------
2025-04-14 17:12:44,492 - INFO - def test_initialise_settings_success():
    agent = "test_agent"
    settings_data = {'setting1': 'value1', 'setting2': 'value2'}
2025-04-14 17:12:44,492 - INFO - ---------------
2025-04-14 17:12:45,323 - INFO - passed 1- True
2025-04-14 17:12:45,323 - INFO - test_case_error 1 - .                                                                        [100%]
1 passed in 0.17s
2025-04-14 17:12:45,323 - INFO - 

2025-04-14 17:12:45,323 - INFO - TEST CASE 4 Retry 1
2025-04-14 17:12:45,323 - INFO - ---------------
2025-04-14 17:12:45,323 - INFO - def test_initialise_settings_file_not_found():
    agent = "test_agent"
    with patch('theory_evaluation.llm_utils.open', side_effect=FileNotFoundError):
        result = initialise_settings(agent)
        assert result is None
2025-04-14 17:12:45,323 - INFO - ---------------
2025-04-14 17:12:46,406 - INFO - passed 1- True
2025-04-14 17:12:46,406 - INFO - test_case_error 1 - .                                                                        [100%]
1 passed in 0.31s
2025-04-14 17:12:46,407 - INFO - [1mEnd Processing file: theory_evaluation\llm_utils.py[0m

2025-04-14 17:12:46,407 - INFO - [1mStart Processing file: theory_evaluation\__init__.py[0m
2025-04-14 17:12:46,407 - WARNING - No public functions found in theory_evaluation\__init__.py. Skipping test generation.

