2025-04-15 15:07:29,243 - INFO - Loading environment variables...
2025-04-15 15:07:29,552 - INFO - Start Processing file: theory_evaluation\llm_handler.py
2025-04-15 15:07:40,990 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-15 15:07:50,041 - INFO - 

2025-04-15 15:07:50,041 - INFO - TEST CASE 1 Retry 0
2025-04-15 15:07:50,042 - INFO - ---------------
2025-04-15 15:07:50,042 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
@pytest.fixture
def mock_openai():
    with patch('theory_evaluation.llm_handler.OpenAI') as mock:
        yield mock

@pytest.fixture
def mock_azure_openai():
    with patch('theory_evaluation.llm_handler.AzureOpenAI') as mock:
        yield mock

@pytest.fixture
def mock_os_environ():
    with patch.dict(os.environ, {
        "AZURE_OPENAI_ENDPOINT_SWEDEN": "test_endpoint",
        "AZURE_OPENAI_API_VERSION": "test_version",
        "AZURE_OPENAI_API_KEY_SWEDEN": "test_key",
        "OPENAI_API_KEY": "test_openai_key",
        "AZURE_OPENAI_DEPLOYMENT_NAME": "test_deployment",
        "OPENAI_DEPLOYMENT_NAME": "test_openai_deployment"
    }):
        yield

@pytest.mark.asyncio
async def test_openai_llm_initialization_with_azure(mock_azure_openai, mock_os_environ):
    llm = OpenAI_llm(useAzureOpenAI=True)
    assert llm.client is mock_azure_openai.return_value
    assert llm.azure_endpoint == "test_endpoint"
    assert llm.api_version == "test_version"
    assert llm.model_name == "test_deployment"

2025-04-15 15:07:50,046 - INFO - ---------------
2025-04-15 15:07:51,956 - INFO - Test Result 1- False
2025-04-15 15:07:51,956 - INFO - Test Error 1 - E                                                                        [100%]
=================================== ERRORS ====================================
_________ ERROR at setup of test_openai_llm_initialization_with_azure _________
temp\temp.py:15: in mock_azure_openai
    with patch('theory_evaluation.llm_handler.AzureOpenAI') as mock:
E   NameError: name 'patch' is not defined
============================== warnings summary ===============================
temp\temp.py:30
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py:30: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ===========================
ERROR temp/temp.py::test_openai_llm_initialization_with_azure - NameError: na...
1 warning, 1 error in 1.23s
2025-04-15 15:07:53,819 - INFO - TEST CASE 1 Retry 1
2025-04-15 15:07:53,820 - INFO - ---------------
2025-04-15 15:07:53,821 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
@pytest.fixture
def mock_openai():
    with patch('theory_evaluation.llm_handler.OpenAI') as mock:
        yield mock

@pytest.fixture
def mock_azure_openai():
    with patch('theory_evaluation.llm_handler.AzureOpenAI') as mock:
        yield mock

@pytest.fixture
def mock_os_environ():
    with patch.dict(os.environ, {
        "AZURE_OPENAI_ENDPOINT_SWEDEN": "test_endpoint",
        "AZURE_OPENAI_API_VERSION": "test_version",
        "AZURE_OPENAI_API_KEY_SWEDEN": "test_key",
        "OPENAI_API_KEY": "test_openai_key",
        "AZURE_OPENAI_DEPLOYMENT_NAME": "test_deployment",
        "OPENAI_DEPLOYMENT_NAME": "test_openai_deployment"
    }):
        yield
from unittest.mock import patch
import pytest

@pytest.mark.asyncio
async def test_openai_llm_initialization_with_azure(mock_azure_openai, mock_os_environ):
    with patch('theory_evaluation.llm_handler.AzureOpenAI') as mock:
        llm = OpenAI_llm(useAzureOpenAI=True)
        assert llm.client is mock_azure_openai.return_value
        assert llm.azure_endpoint == "test_endpoint"
        assert llm.api_version == "test_version"
        assert llm.model_name == "test_deployment"

2025-04-15 15:07:53,822 - INFO - ---------------
2025-04-15 15:07:57,032 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-15 15:07:57,032 - INFO - New import Statements 2- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
from unittest.mock import patch
2025-04-15 15:07:57,032 - INFO - Test Result 2- True
2025-04-15 15:07:57,032 - INFO - Test Error 2 - 
s                                                                        [100%]
============================== warnings summary ===============================
temp\temp.py:32
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py:32: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

temp/temp.py::test_openai_llm_initialization_with_azure
  C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\python.py:148: PytestUnhandledCoroutineWarning: async def functions are not natively supported and have been skipped.
  You need to install a suitable plugin for your async framework, for example:
    - anyio
    - pytest-asyncio
    - pytest-tornasync
    - pytest-trio
    - pytest-twisted
    warnings.warn(PytestUnhandledCoroutineWarning(msg.format(nodeid)))

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
1 skipped, 2 warnings in 1.49s
2025-04-15 15:07:57,032 - INFO - 

2025-04-15 15:07:57,032 - INFO - TEST CASE 2 Retry 0
2025-04-15 15:07:57,032 - INFO - ---------------
2025-04-15 15:07:57,033 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
from unittest.mock import patch
@pytest.fixture
def mock_openai():
    with patch('theory_evaluation.llm_handler.OpenAI') as mock:
        yield mock

@pytest.fixture
def mock_azure_openai():
    with patch('theory_evaluation.llm_handler.AzureOpenAI') as mock:
        yield mock

@pytest.fixture
def mock_os_environ():
    with patch.dict(os.environ, {
        "AZURE_OPENAI_ENDPOINT_SWEDEN": "test_endpoint",
        "AZURE_OPENAI_API_VERSION": "test_version",
        "AZURE_OPENAI_API_KEY_SWEDEN": "test_key",
        "OPENAI_API_KEY": "test_openai_key",
        "AZURE_OPENAI_DEPLOYMENT_NAME": "test_deployment",
        "OPENAI_DEPLOYMENT_NAME": "test_openai_deployment"
    }):
        yield

@pytest.mark.asyncio
async def test_openai_llm_initialization_without_azure(mock_openai, mock_os_environ):
    llm = OpenAI_llm(useAzureOpenAI=False)
    assert llm.client is mock_openai.return_value
    assert llm.model_name == "test_openai_deployment"

2025-04-15 15:07:57,033 - INFO - ---------------
2025-04-15 15:07:59,156 - INFO - Test Result 1- True
2025-04-15 15:07:59,156 - INFO - Test Error 1 - s                                                                        [100%]
============================== warnings summary ===============================
temp\temp.py:31
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py:31: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

temp/temp.py::test_openai_llm_initialization_without_azure
  C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\python.py:148: PytestUnhandledCoroutineWarning: async def functions are not natively supported and have been skipped.
  You need to install a suitable plugin for your async framework, for example:
    - anyio
    - pytest-asyncio
    - pytest-tornasync
    - pytest-trio
    - pytest-twisted
    warnings.warn(PytestUnhandledCoroutineWarning(msg.format(nodeid)))

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
1 skipped, 2 warnings in 1.31s
2025-04-15 15:07:59,157 - INFO - 

2025-04-15 15:07:59,157 - INFO - TEST CASE 3 Retry 0
2025-04-15 15:07:59,157 - INFO - ---------------
2025-04-15 15:07:59,157 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
from unittest.mock import patch
@pytest.fixture
def mock_openai():
    with patch('theory_evaluation.llm_handler.OpenAI') as mock:
        yield mock

@pytest.fixture
def mock_azure_openai():
    with patch('theory_evaluation.llm_handler.AzureOpenAI') as mock:
        yield mock

@pytest.fixture
def mock_os_environ():
    with patch.dict(os.environ, {
        "AZURE_OPENAI_ENDPOINT_SWEDEN": "test_endpoint",
        "AZURE_OPENAI_API_VERSION": "test_version",
        "AZURE_OPENAI_API_KEY_SWEDEN": "test_key",
        "OPENAI_API_KEY": "test_openai_key",
        "AZURE_OPENAI_DEPLOYMENT_NAME": "test_deployment",
        "OPENAI_DEPLOYMENT_NAME": "test_openai_deployment"
    }):
        yield

@pytest.mark.asyncio
async def test_openai_json_completion(mock_openai):
    mock_response = MagicMock()
    mock_response.choices[0].message.content = json.dumps({"key": "value"})
    mock_openai.return_value.chat.completions.create.return_value = mock_response

2025-04-15 15:07:59,157 - INFO - ---------------
2025-04-15 15:08:01,180 - INFO - Test Result 1- True
2025-04-15 15:08:01,181 - INFO - Test Error 1 - s                                                                        [100%]
============================== warnings summary ===============================
temp\temp.py:31
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py:31: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

temp/temp.py::test_openai_json_completion
  C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\python.py:148: PytestUnhandledCoroutineWarning: async def functions are not natively supported and have been skipped.
  You need to install a suitable plugin for your async framework, for example:
    - anyio
    - pytest-asyncio
    - pytest-tornasync
    - pytest-trio
    - pytest-twisted
    warnings.warn(PytestUnhandledCoroutineWarning(msg.format(nodeid)))

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
1 skipped, 2 warnings in 1.20s
2025-04-15 15:08:01,181 - INFO - 

2025-04-15 15:08:01,181 - INFO - TEST CASE 4 Retry 0
2025-04-15 15:08:01,181 - INFO - ---------------
2025-04-15 15:08:01,181 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
from unittest.mock import patch
@pytest.fixture
def mock_openai():
    with patch('theory_evaluation.llm_handler.OpenAI') as mock:
        yield mock

@pytest.fixture
def mock_azure_openai():
    with patch('theory_evaluation.llm_handler.AzureOpenAI') as mock:
        yield mock

@pytest.fixture
def mock_os_environ():
    with patch.dict(os.environ, {
        "AZURE_OPENAI_ENDPOINT_SWEDEN": "test_endpoint",
        "AZURE_OPENAI_API_VERSION": "test_version",
        "AZURE_OPENAI_API_KEY_SWEDEN": "test_key",
        "OPENAI_API_KEY": "test_openai_key",
        "AZURE_OPENAI_DEPLOYMENT_NAME": "test_deployment",
        "OPENAI_DEPLOYMENT_NAME": "test_openai_deployment"
    }):
        yield

@pytest.mark.asyncio
async def test_openai_streaming(mock_openai):
    mock_chunk = MagicMock()
    mock_chunk.choices[0].delta.content = "chunk_content"
    mock_openai.return_value.chat.completions.create.return_value = [mock_chunk]

2025-04-15 15:08:01,181 - INFO - ---------------
2025-04-15 15:08:03,092 - INFO - Test Result 1- True
2025-04-15 15:08:03,092 - INFO - Test Error 1 - s                                                                        [100%]
============================== warnings summary ===============================
temp\temp.py:31
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py:31: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

temp/temp.py::test_openai_streaming
  C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\python.py:148: PytestUnhandledCoroutineWarning: async def functions are not natively supported and have been skipped.
  You need to install a suitable plugin for your async framework, for example:
    - anyio
    - pytest-asyncio
    - pytest-tornasync
    - pytest-trio
    - pytest-twisted
    warnings.warn(PytestUnhandledCoroutineWarning(msg.format(nodeid)))

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
1 skipped, 2 warnings in 1.20s
2025-04-15 15:08:03,092 - INFO - 

2025-04-15 15:08:03,092 - INFO - TEST CASE 5 Retry 0
2025-04-15 15:08:03,092 - INFO - ---------------
2025-04-15 15:08:03,092 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
from unittest.mock import patch
@pytest.fixture
def mock_openai():
    with patch('theory_evaluation.llm_handler.OpenAI') as mock:
        yield mock

@pytest.fixture
def mock_azure_openai():
    with patch('theory_evaluation.llm_handler.AzureOpenAI') as mock:
        yield mock

@pytest.fixture
def mock_os_environ():
    with patch.dict(os.environ, {
        "AZURE_OPENAI_ENDPOINT_SWEDEN": "test_endpoint",
        "AZURE_OPENAI_API_VERSION": "test_version",
        "AZURE_OPENAI_API_KEY_SWEDEN": "test_key",
        "OPENAI_API_KEY": "test_openai_key",
        "AZURE_OPENAI_DEPLOYMENT_NAME": "test_deployment",
        "OPENAI_DEPLOYMENT_NAME": "test_openai_deployment"
    }):
        yield

@pytest.mark.asyncio
async def test_openai_chat_completion(mock_openai):
    mock_response = MagicMock()
    mock_response.choices[0].message.content = "chat_content"
    mock_openai.return_value.chat.completions.create.return_value = mock_response

2025-04-15 15:08:03,092 - INFO - ---------------
2025-04-15 15:08:04,740 - INFO - Test Result 1- True
2025-04-15 15:08:04,740 - INFO - Test Error 1 - s                                                                        [100%]
============================== warnings summary ===============================
temp\temp.py:31
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py:31: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

temp/temp.py::test_openai_chat_completion
  C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\python.py:148: PytestUnhandledCoroutineWarning: async def functions are not natively supported and have been skipped.
  You need to install a suitable plugin for your async framework, for example:
    - anyio
    - pytest-asyncio
    - pytest-tornasync
    - pytest-trio
    - pytest-twisted
    warnings.warn(PytestUnhandledCoroutineWarning(msg.format(nodeid)))

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
1 skipped, 2 warnings in 0.97s
2025-04-15 15:08:04,740 - INFO - 

2025-04-15 15:08:04,740 - INFO - TEST CASE 6 Retry 0
2025-04-15 15:08:04,740 - INFO - ---------------
2025-04-15 15:08:04,740 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
from unittest.mock import patch
@pytest.fixture
def mock_openai():
    with patch('theory_evaluation.llm_handler.OpenAI') as mock:
        yield mock

@pytest.fixture
def mock_azure_openai():
    with patch('theory_evaluation.llm_handler.AzureOpenAI') as mock:
        yield mock

@pytest.fixture
def mock_os_environ():
    with patch.dict(os.environ, {
        "AZURE_OPENAI_ENDPOINT_SWEDEN": "test_endpoint",
        "AZURE_OPENAI_API_VERSION": "test_version",
        "AZURE_OPENAI_API_KEY_SWEDEN": "test_key",
        "OPENAI_API_KEY": "test_openai_key",
        "AZURE_OPENAI_DEPLOYMENT_NAME": "test_deployment",
        "OPENAI_DEPLOYMENT_NAME": "test_openai_deployment"
    }):
        yield

@pytest.mark.asyncio
async def test_execute_text_generation(mock_openai):
    mock_response = MagicMock()
    mock_response.choices[0].message.content = "response_content"
    mock_openai.return_value.chat.completions.create.return_value = mock_response

2025-04-15 15:08:04,740 - INFO - ---------------
2025-04-15 15:08:06,476 - INFO - Test Result 1- True
2025-04-15 15:08:06,476 - INFO - Test Error 1 - s                                                                        [100%]
============================== warnings summary ===============================
temp\temp.py:31
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py:31: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

temp/temp.py::test_execute_text_generation
  C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\python.py:148: PytestUnhandledCoroutineWarning: async def functions are not natively supported and have been skipped.
  You need to install a suitable plugin for your async framework, for example:
    - anyio
    - pytest-asyncio
    - pytest-tornasync
    - pytest-trio
    - pytest-twisted
    warnings.warn(PytestUnhandledCoroutineWarning(msg.format(nodeid)))

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
1 skipped, 2 warnings in 0.99s
2025-04-15 15:08:06,476 - INFO - 

2025-04-15 15:08:06,476 - INFO - TEST CASE 7 Retry 0
2025-04-15 15:08:06,476 - INFO - ---------------
2025-04-15 15:08:06,476 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
from unittest.mock import patch
@pytest.fixture
def mock_openai():
    with patch('theory_evaluation.llm_handler.OpenAI') as mock:
        yield mock

@pytest.fixture
def mock_azure_openai():
    with patch('theory_evaluation.llm_handler.AzureOpenAI') as mock:
        yield mock

@pytest.fixture
def mock_os_environ():
    with patch.dict(os.environ, {
        "AZURE_OPENAI_ENDPOINT_SWEDEN": "test_endpoint",
        "AZURE_OPENAI_API_VERSION": "test_version",
        "AZURE_OPENAI_API_KEY_SWEDEN": "test_key",
        "OPENAI_API_KEY": "test_openai_key",
        "AZURE_OPENAI_DEPLOYMENT_NAME": "test_deployment",
        "OPENAI_DEPLOYMENT_NAME": "test_openai_deployment"
    }):
        yield

@pytest.mark.asyncio
async def test_execute_vision(mock_openai):
    mock_response = MagicMock()
    mock_response.choices[0].message.content = "response_content"
    mock_openai.return_value.chat.completions.create.return_value = mock_response

2025-04-15 15:08:06,477 - INFO - ---------------
2025-04-15 15:08:08,287 - INFO - Test Result 1- True
2025-04-15 15:08:08,287 - INFO - Test Error 1 - s                                                                        [100%]
============================== warnings summary ===============================
temp\temp.py:31
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py:31: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

temp/temp.py::test_execute_vision
  C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\python.py:148: PytestUnhandledCoroutineWarning: async def functions are not natively supported and have been skipped.
  You need to install a suitable plugin for your async framework, for example:
    - anyio
    - pytest-asyncio
    - pytest-tornasync
    - pytest-trio
    - pytest-twisted
    warnings.warn(PytestUnhandledCoroutineWarning(msg.format(nodeid)))

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
1 skipped, 2 warnings in 1.07s
2025-04-15 15:08:08,289 - INFO - End Processing file: theory_evaluation\llm_handler.py

2025-04-15 15:08:08,289 - INFO - Start Processing file: theory_evaluation\llm_utils.py
2025-04-15 15:08:14,762 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-15 15:08:21,209 - INFO - End Processing file: theory_evaluation\llm_utils.py

2025-04-15 15:08:21,210 - INFO - Start Processing file: theory_evaluation\__init__.py
2025-04-15 15:08:21,211 - WARNING - No public functions found in theory_evaluation\__init__.py. Skipping test generation.

