2025-04-15 15:14:02,409 - INFO - Loading environment variables...
2025-04-15 15:14:02,749 - INFO - Start Processing file: theory_evaluation\llm_handler.py
2025-04-15 15:14:13,525 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-15 15:14:23,842 - INFO - 

2025-04-15 15:14:23,842 - INFO - TEST CASE 1 Retry 0
2025-04-15 15:14:23,842 - INFO - ---------------
2025-04-15 15:14:23,843 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest


@pytest.mark.asyncio
async def test_openai_llm_initialization():
    with patch("theory_evaluation.llm_handler.AzureOpenAI") as mock_azure_openai, \
         patch("theory_evaluation.llm_handler.OpenAI") as mock_openai, \
         patch.dict(os.environ, {"AZURE_OPENAI_ENDPOINT_SWEDEN": "test_endpoint", "AZURE_OPENAI_API_VERSION": "v1", "OPENAI_API_KEY": "test_key"}):
        
        llm = OpenAI_llm(useAzureOpenAI=True)
        assert llm.azure_endpoint == "test_endpoint"
        assert llm.api_version == "v1"
        assert hasattr(llm, "client")
        assert mock_azure_openai.called

2025-04-15 15:14:23,844 - INFO - ---------------
2025-04-15 15:14:25,664 - INFO - Test Result 1- False
2025-04-15 15:14:25,665 - INFO - Test Error 1 - C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
_______________________ test_openai_llm_initialization ________________________
temp\temp.py:12: in test_openai_llm_initialization
    with patch("theory_evaluation.llm_handler.AzureOpenAI") as mock_azure_openai, \
E   NameError: name 'patch' is not defined
=========================== short test summary info ===========================
FAILED temp/temp.py::test_openai_llm_initialization - NameError: name 'patch'...
1 failed in 0.97s
2025-04-15 15:14:30,222 - INFO - TEST CASE 1 Retry 1
2025-04-15 15:14:30,222 - INFO - ---------------
2025-04-15 15:14:30,222 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest

from unittest.mock import patch
import os
import pytest

@pytest.mark.asyncio
async def test_openai_llm_initialization():
    with patch("theory_evaluation.llm_handler.AzureOpenAI") as mock_azure_openai, \
         patch("theory_evaluation.llm_handler.OpenAI") as mock_openai, \
         patch.dict(os.environ, {"AZURE_OPENAI_ENDPOINT_SWEDEN": "test_endpoint", "AZURE_OPENAI_API_VERSION": "v1", "OPENAI_API_KEY": "test_key"}):
        
        llm = OpenAI_llm(useAzureOpenAI=True)
        assert llm.azure_endpoint == "test_endpoint"
        assert llm.api_version == "v1"
        assert hasattr(llm, "client")
        assert mock_azure_openai.called

2025-04-15 15:14:30,223 - INFO - ---------------
2025-04-15 15:14:33,860 - INFO - Test Result 2- False
2025-04-15 15:14:33,860 - INFO - Test Error 2 - 
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
_______________________ test_openai_llm_initialization ________________________
temp\temp.py:19: in test_openai_llm_initialization
    llm = OpenAI_llm(useAzureOpenAI=True)
E   NameError: name 'OpenAI_llm' is not defined
=========================== short test summary info ===========================
FAILED temp/temp.py::test_openai_llm_initialization - NameError: name 'OpenAI...
1 failed in 2.25s
2025-04-15 15:14:36,057 - INFO - TEST CASE 1 Retry 2
2025-04-15 15:14:36,058 - INFO - ---------------
2025-04-15 15:14:36,058 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest

from unittest.mock import patch
import os
import pytest
from llm_handler import OpenAI_llm

@pytest.mark.asyncio
async def test_openai_llm_initialization():
    with patch("theory_evaluation.llm_handler.AzureOpenAI") as mock_azure_openai, \
         patch("theory_evaluation.llm_handler.OpenAI") as mock_openai, \
         patch.dict(os.environ, {"AZURE_OPENAI_ENDPOINT_SWEDEN": "test_endpoint", "AZURE_OPENAI_API_VERSION": "v1", "OPENAI_API_KEY": "test_key"}):
        
        llm = OpenAI_llm(useAzureOpenAI=True)
        assert llm.azure_endpoint == "test_endpoint"
        assert llm.api_version == "v1"
        assert hasattr(llm, "client")
        assert mock_azure_openai.called

2025-04-15 15:14:36,058 - INFO - ---------------
2025-04-15 15:14:37,953 - INFO - Test Result 3- False
2025-04-15 15:14:37,954 - INFO - Test Error 3 - 
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:12: in <module>
    from llm_handler import OpenAI_llm
E   ModuleNotFoundError: No module named 'llm_handler'
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 1.11s
2025-04-15 15:14:37,954 - INFO - Failed after all retries for test case 1
2025-04-15 15:14:37,954 - INFO - 

2025-04-15 15:14:37,954 - INFO - TEST CASE 2 Retry 0
2025-04-15 15:14:37,954 - INFO - ---------------
2025-04-15 15:14:37,954 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest


@pytest.mark.asyncio
async def test_openai_json_completion():
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client", new_callable=AsyncMock) as mock_client:
        mock_response = AsyncMock()
        mock_response.choices = [AsyncMock()]
        mock_response.choices[0].message.content = json.dumps({"answer": "42", "explanation": "The answer to life, the universe, and everything."})
        mock_client.chat.completions.create.return_value = mock_response

2025-04-15 15:14:37,955 - INFO - ---------------
2025-04-15 15:14:40,026 - INFO - Test Result 1- False
2025-04-15 15:14:40,027 - INFO - Test Error 1 - C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
_________________________ test_openai_json_completion _________________________
temp\temp.py:12: in test_openai_json_completion
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client", new_callable=AsyncMock) as mock_client:
E   NameError: name 'patch' is not defined
=========================== short test summary info ===========================
FAILED temp/temp.py::test_openai_json_completion - NameError: name 'patch' is...
1 failed in 1.06s
2025-04-15 15:14:42,790 - INFO - TEST CASE 2 Retry 1
2025-04-15 15:14:42,791 - INFO - ---------------
2025-04-15 15:14:42,791 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest

from unittest.mock import patch, AsyncMock

@pytest.mark.asyncio
async def test_openai_json_completion():
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client", new_callable=AsyncMock) as mock_client:
        mock_response = AsyncMock()
        mock_response.choices = [AsyncMock()]
        mock_response.choices[0].message.content = json.dumps({"answer": "42", "explanation": "The answer to life, the universe, and everything."})
        mock_client.chat.completions.create.return_value = mock_response

2025-04-15 15:14:42,791 - INFO - ---------------
2025-04-15 15:14:45,173 - INFO - Test Result 2- False
2025-04-15 15:14:45,173 - INFO - Test Error 2 - 
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
_________________________ test_openai_json_completion _________________________
temp\temp.py:13: in test_openai_json_completion
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client", new_callable=AsyncMock) as mock_client:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py:1495: in __enter__
    original, local = self.get_original()
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py:1465: in get_original
    raise AttributeError(
E   AttributeError: <class 'theory_evaluation.llm_handler.OpenAI_llm'> does not have the attribute 'client'
=========================== short test summary info ===========================
FAILED temp/temp.py::test_openai_json_completion - AttributeError: <class 'th...
1 failed in 1.26s
2025-04-15 15:14:48,153 - INFO - TEST CASE 2 Retry 2
2025-04-15 15:14:48,153 - INFO - ---------------
2025-04-15 15:14:48,154 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest

from unittest.mock import patch, AsyncMock
import pytest
import json
from theory_evaluation.llm_handler import OpenAI_llm

@pytest.mark.asyncio
async def test_openai_json_completion():
    with patch.object(OpenAI_llm, 'client', new_callable=AsyncMock) as mock_client:
        mock_response = AsyncMock()
        mock_response.choices = [AsyncMock()]
        mock_response.choices[0].message.content = json.dumps({"answer": "42", "explanation": "The answer to life, the universe, and everything."})
        mock_client.chat.completions.create.return_value = mock_response

        llm = OpenAI_llm()
        result = await llm._OpenAI_JSON_Completion()
        assert result == {"answer": "42", "explanation": "The answer to life, the universe, and everything."}

2025-04-15 15:14:48,154 - INFO - ---------------
2025-04-15 15:14:50,334 - INFO - Test Result 3- False
2025-04-15 15:14:50,334 - INFO - Test Error 3 - 
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
_________________________ test_openai_json_completion _________________________
temp\temp.py:16: in test_openai_json_completion
    with patch.object(OpenAI_llm, 'client', new_callable=AsyncMock) as mock_client:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py:1495: in __enter__
    original, local = self.get_original()
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py:1465: in get_original
    raise AttributeError(
E   AttributeError: <class 'theory_evaluation.llm_handler.OpenAI_llm'> does not have the attribute 'client'
=========================== short test summary info ===========================
FAILED temp/temp.py::test_openai_json_completion - AttributeError: <class 'th...
1 failed in 1.28s
2025-04-15 15:14:50,334 - INFO - Failed after all retries for test case 2
2025-04-15 15:14:50,334 - INFO - 

2025-04-15 15:14:50,334 - INFO - TEST CASE 3 Retry 0
2025-04-15 15:14:50,334 - INFO - ---------------
2025-04-15 15:14:50,335 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest


@pytest.mark.asyncio
async def test_openai_streaming():
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client", new_callable=AsyncMock) as mock_client:
        mock_stream = AsyncMock()
        mock_chunk = AsyncMock()
        mock_chunk.choices = [AsyncMock()]
        mock_chunk.choices[0].delta.content = "streaming content"
        mock_stream.__aiter__.return_value = [mock_chunk]
        mock_client.chat.completions.create.return_value = mock_stream

2025-04-15 15:14:50,335 - INFO - ---------------
2025-04-15 15:14:52,397 - INFO - Test Result 1- False
2025-04-15 15:14:52,397 - INFO - Test Error 1 - C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
____________________________ test_openai_streaming ____________________________
temp\temp.py:12: in test_openai_streaming
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client", new_callable=AsyncMock) as mock_client:
E   NameError: name 'patch' is not defined
=========================== short test summary info ===========================
FAILED temp/temp.py::test_openai_streaming - NameError: name 'patch' is not d...
1 failed in 1.29s
2025-04-15 15:14:54,187 - INFO - TEST CASE 3 Retry 1
2025-04-15 15:14:54,187 - INFO - ---------------
2025-04-15 15:14:54,188 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest

from unittest.mock import patch, AsyncMock

@pytest.mark.asyncio
async def test_openai_streaming():
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client", new_callable=AsyncMock) as mock_client:
        mock_stream = AsyncMock()
        mock_chunk = AsyncMock()
        mock_chunk.choices = [AsyncMock()]
        mock_chunk.choices[0].delta.content = "streaming content"
        mock_stream.__aiter__.return_value = [mock_chunk]
        mock_client.chat.completions.create.return_value = mock_stream

2025-04-15 15:14:54,188 - INFO - ---------------
2025-04-15 15:14:56,116 - INFO - Test Result 2- False
2025-04-15 15:14:56,116 - INFO - Test Error 2 - 
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
____________________________ test_openai_streaming ____________________________
temp\temp.py:13: in test_openai_streaming
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client", new_callable=AsyncMock) as mock_client:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py:1495: in __enter__
    original, local = self.get_original()
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py:1465: in get_original
    raise AttributeError(
E   AttributeError: <class 'theory_evaluation.llm_handler.OpenAI_llm'> does not have the attribute 'client'
=========================== short test summary info ===========================
FAILED temp/temp.py::test_openai_streaming - AttributeError: <class 'theory_e...
1 failed in 1.01s
2025-04-15 15:14:58,612 - INFO - TEST CASE 3 Retry 2
2025-04-15 15:14:58,612 - INFO - ---------------
2025-04-15 15:14:58,612 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest

import pytest
from unittest.mock import patch, AsyncMock

@pytest.mark.asyncio
async def test_openai_streaming():
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client.chat.completions.create", new_callable=AsyncMock) as mock_create:
        mock_stream = AsyncMock()
        mock_chunk = AsyncMock()
        mock_chunk.choices = [AsyncMock()]
        mock_chunk.choices[0].delta.content = "streaming content"
        mock_stream.__aiter__.return_value = [mock_chunk]
        mock_create.return_value = mock_stream

        llm = OpenAI_llm(message="Test message", output="stream")
        async for token in llm.execute():
            assert token == "streaming content"

2025-04-15 15:14:58,613 - INFO - ---------------
2025-04-15 15:15:00,826 - INFO - Test Result 3- False
2025-04-15 15:15:00,826 - INFO - Test Error 3 - 
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
____________________________ test_openai_streaming ____________________________
temp\temp.py:14: in test_openai_streaming
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client.chat.completions.create", new_callable=AsyncMock) as mock_create:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py:1479: in __enter__
    self.target = self.getter()
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\pkgutil.py:528: in resolve_name
    result = getattr(result, p)
E   AttributeError: type object 'OpenAI_llm' has no attribute 'client'
=========================== short test summary info ===========================
FAILED temp/temp.py::test_openai_streaming - AttributeError: type object 'Ope...
1 failed in 1.26s
2025-04-15 15:15:00,826 - INFO - Failed after all retries for test case 3
2025-04-15 15:15:00,826 - INFO - 

2025-04-15 15:15:00,826 - INFO - TEST CASE 4 Retry 0
2025-04-15 15:15:00,826 - INFO - ---------------
2025-04-15 15:15:00,827 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest


@pytest.mark.asyncio
async def test_openai_chat_completion():
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client", new_callable=AsyncMock) as mock_client:
        mock_response = AsyncMock()
        mock_response.choices = [AsyncMock()]
        mock_response.choices[0].message.content = "chat completion content"
        mock_client.chat.completions.create.return_value = mock_response

2025-04-15 15:15:00,827 - INFO - ---------------
2025-04-15 15:15:02,622 - INFO - Test Result 1- False
2025-04-15 15:15:02,622 - INFO - Test Error 1 - C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
_________________________ test_openai_chat_completion _________________________
temp\temp.py:12: in test_openai_chat_completion
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client", new_callable=AsyncMock) as mock_client:
E   NameError: name 'patch' is not defined
=========================== short test summary info ===========================
FAILED temp/temp.py::test_openai_chat_completion - NameError: name 'patch' is...
1 failed in 1.01s
2025-04-15 15:15:04,076 - INFO - TEST CASE 4 Retry 1
2025-04-15 15:15:04,077 - INFO - ---------------
2025-04-15 15:15:04,077 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest

from unittest.mock import patch, AsyncMock

@pytest.mark.asyncio
async def test_openai_chat_completion():
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client", new_callable=AsyncMock) as mock_client:
        mock_response = AsyncMock()
        mock_response.choices = [AsyncMock()]
        mock_response.choices[0].message.content = "chat completion content"
        mock_client.chat.completions.create.return_value = mock_response

2025-04-15 15:15:04,077 - INFO - ---------------
2025-04-15 15:15:06,046 - INFO - Test Result 2- False
2025-04-15 15:15:06,046 - INFO - Test Error 2 - 
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
_________________________ test_openai_chat_completion _________________________
temp\temp.py:13: in test_openai_chat_completion
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client", new_callable=AsyncMock) as mock_client:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py:1495: in __enter__
    original, local = self.get_original()
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py:1465: in get_original
    raise AttributeError(
E   AttributeError: <class 'theory_evaluation.llm_handler.OpenAI_llm'> does not have the attribute 'client'
=========================== short test summary info ===========================
FAILED temp/temp.py::test_openai_chat_completion - AttributeError: <class 'th...
1 failed in 1.03s
2025-04-15 15:15:07,975 - INFO - TEST CASE 4 Retry 2
2025-04-15 15:15:07,976 - INFO - ---------------
2025-04-15 15:15:07,976 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest

import pytest
from unittest.mock import patch, AsyncMock
from theory_evaluation.llm_handler import OpenAI_llm

@pytest.mark.asyncio
async def test_openai_chat_completion():
    with patch.object(OpenAI_llm, "client", new_callable=AsyncMock) as mock_client:
        mock_response = AsyncMock()
        mock_response.choices = [AsyncMock()]
        mock_response.choices[0].message.content = "chat completion content"
        mock_client.chat.completions.create.return_value = mock_response

        llm = OpenAI_llm()
        result = await llm._OpenAI_Chat_Completion()
        assert result == "chat completion content"

2025-04-15 15:15:07,976 - INFO - ---------------
2025-04-15 15:15:11,342 - INFO - Test Result 3- False
2025-04-15 15:15:11,343 - INFO - Test Error 3 - 
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
_________________________ test_openai_chat_completion _________________________
temp\temp.py:15: in test_openai_chat_completion
    with patch.object(OpenAI_llm, "client", new_callable=AsyncMock) as mock_client:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py:1495: in __enter__
    original, local = self.get_original()
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\unittest\mock.py:1465: in get_original
    raise AttributeError(
E   AttributeError: <class 'theory_evaluation.llm_handler.OpenAI_llm'> does not have the attribute 'client'
=========================== short test summary info ===========================
FAILED temp/temp.py::test_openai_chat_completion - AttributeError: <class 'th...
1 failed in 2.01s
2025-04-15 15:15:11,343 - INFO - Failed after all retries for test case 4
2025-04-15 15:15:11,343 - INFO - 

2025-04-15 15:15:11,343 - INFO - TEST CASE 5 Retry 0
2025-04-15 15:15:11,343 - INFO - ---------------
2025-04-15 15:15:11,343 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest


@pytest.mark.asyncio
async def test_execute_text_generation():
    with patch("theory_evaluation.llm_handler.OpenAI_llm._run", new_callable=AsyncMock) as mock_run:
        mock_run.return_value.__aiter__.return_value = ["response content"]

2025-04-15 15:15:11,343 - INFO - ---------------
2025-04-15 15:15:13,704 - INFO - Test Result 1- False
2025-04-15 15:15:13,704 - INFO - Test Error 1 - C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
________________________ test_execute_text_generation _________________________
temp\temp.py:12: in test_execute_text_generation
    with patch("theory_evaluation.llm_handler.OpenAI_llm._run", new_callable=AsyncMock) as mock_run:
E   NameError: name 'patch' is not defined
=========================== short test summary info ===========================
FAILED temp/temp.py::test_execute_text_generation - NameError: name 'patch' i...
1 failed in 1.34s
2025-04-15 15:15:15,990 - INFO - TEST CASE 5 Retry 1
2025-04-15 15:15:15,990 - INFO - ---------------
2025-04-15 15:15:15,990 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest

from unittest.mock import patch, AsyncMock

@pytest.mark.asyncio
async def test_execute_text_generation():
    with patch("theory_evaluation.llm_handler.OpenAI_llm._run", new_callable=AsyncMock) as mock_run:
        mock_run.return_value.__aiter__.return_value = ["response content"]
        llm = OpenAI_llm(message="Test message", useAzureOpenAI=False, output="stream")
        responses = [response async for response in llm.execute()]
        assert responses == ["response content"]

2025-04-15 15:15:15,990 - INFO - ---------------
2025-04-15 15:15:17,866 - INFO - Test Result 2- False
2025-04-15 15:15:17,866 - INFO - Test Error 2 - 
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
________________________ test_execute_text_generation _________________________
temp\temp.py:15: in test_execute_text_generation
    llm = OpenAI_llm(message="Test message", useAzureOpenAI=False, output="stream")
E   NameError: name 'OpenAI_llm' is not defined
=========================== short test summary info ===========================
FAILED temp/temp.py::test_execute_text_generation - NameError: name 'OpenAI_l...
1 failed in 1.00s
2025-04-15 15:15:19,614 - INFO - TEST CASE 5 Retry 2
2025-04-15 15:15:19,615 - INFO - ---------------
2025-04-15 15:15:19,615 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest

import pytest
from theory_evaluation.llm_handler import OpenAI_llm
from unittest.mock import patch, AsyncMock

@pytest.mark.asyncio
async def test_execute_text_generation():
    with patch("theory_evaluation.llm_handler.OpenAI_llm._run", new_callable=AsyncMock) as mock_run:
        mock_run.return_value.__aiter__.return_value = ["response content"]
        llm = OpenAI_llm(message="Test message", useAzureOpenAI=False, output="stream")
        responses = [response async for response in llm.execute()]
        assert responses == ["response content"]

2025-04-15 15:15:19,616 - INFO - ---------------
2025-04-15 15:15:22,107 - INFO - Test Result 3- False
2025-04-15 15:15:22,108 - INFO - Test Error 3 - 
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
________________________ test_execute_text_generation _________________________
temp\temp.py:19: in test_execute_text_generation
    assert responses == ["response content"]
E   assert ["Error: 'asy...ot coroutine"] == ['response content']
E     
E     At index 0 diff: "Error: 'async for' requires an object with __aiter__ method, got coroutine" != 'response content'
E     Use -v to get more diff
============================== warnings summary ===============================
temp/temp.py::test_execute_text_generation
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\llm_handler.py:164: RuntimeWarning: coroutine 'AsyncMockMixin._execute_mock_call' was never awaited
    async for response in self._run(
  Enable tracemalloc to get traceback where the object was allocated.
  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ===========================
FAILED temp/temp.py::test_execute_text_generation - assert ["Error: 'asy...ot...
1 failed, 1 warning in 1.48s
2025-04-15 15:15:22,108 - INFO - Failed after all retries for test case 5
2025-04-15 15:15:22,109 - INFO - 

2025-04-15 15:15:22,109 - INFO - TEST CASE 6 Retry 0
2025-04-15 15:15:22,109 - INFO - ---------------
2025-04-15 15:15:22,109 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest


@pytest.mark.asyncio
async def test_execute_vision():
    with patch("theory_evaluation.llm_handler.OpenAI_llm._run", new_callable=AsyncMock) as mock_run:
        mock_run.return_value.__aiter__.return_value = ["response content"]

2025-04-15 15:15:22,109 - INFO - ---------------
2025-04-15 15:15:24,656 - INFO - Test Result 1- False
2025-04-15 15:15:24,656 - INFO - Test Error 1 - C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
_____________________________ test_execute_vision _____________________________
temp\temp.py:12: in test_execute_vision
    with patch("theory_evaluation.llm_handler.OpenAI_llm._run", new_callable=AsyncMock) as mock_run:
E   NameError: name 'patch' is not defined
=========================== short test summary info ===========================
FAILED temp/temp.py::test_execute_vision - NameError: name 'patch' is not def...
1 failed in 1.59s
2025-04-15 15:15:26,542 - INFO - TEST CASE 6 Retry 1
2025-04-15 15:15:26,543 - INFO - ---------------
2025-04-15 15:15:26,543 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest

from unittest.mock import patch, AsyncMock

@pytest.mark.asyncio
async def test_execute_vision():
    with patch("theory_evaluation.llm_handler.OpenAI_llm._run", new_callable=AsyncMock) as mock_run:
        mock_run.return_value.__aiter__.return_value = ["response content"]

2025-04-15 15:15:26,543 - INFO - ---------------
2025-04-15 15:15:29,148 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-15 15:15:29,148 - INFO - New import Statements 2- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
from unittest.mock import patch, AsyncMock

import pytest
2025-04-15 15:15:29,148 - INFO - Test Result 2- True
2025-04-15 15:15:29,149 - INFO - Test Error 2 - 
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
.                                                                        [100%]
1 passed in 1.05s
2025-04-15 15:15:29,151 - INFO - End Processing file: theory_evaluation\llm_handler.py

2025-04-15 15:15:29,152 - INFO - Start Processing file: theory_evaluation\llm_utils.py
2025-04-15 15:15:37,134 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-15 15:15:42,125 - INFO - End Processing file: theory_evaluation\llm_utils.py

2025-04-15 15:15:42,126 - INFO - Start Processing file: theory_evaluation\__init__.py
2025-04-15 15:15:42,127 - WARNING - No public functions found in theory_evaluation\__init__.py. Skipping test generation.

