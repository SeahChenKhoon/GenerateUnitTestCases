2025-04-16 12:52:29,542 - INFO - Loading environment variables start
2025-04-16 12:52:29,554 - INFO - Loading environment variables completes
2025-04-16 12:52:29,554 - INFO - Initialising of LLM start
2025-04-16 12:52:29,970 - INFO - Initialising of LLM completes
2025-04-16 12:52:29,970 - INFO - Getting python file starts
2025-04-16 12:52:29,971 - INFO - Getting python file completes
2025-04-16 12:52:29,971 - INFO - 
Start Processing file: theory_evaluation\llm_handler.py
2025-04-16 12:52:29,972 - INFO - Extraction of function and class start
2025-04-16 12:52:29,972 - INFO - extraction of function and class complete
2025-04-16 12:52:29,972 - INFO - Generate Unit Test Case starts
2025-04-16 12:52:29,972 - INFO - Extract unique import start
2025-04-16 12:52:32,118 - INFO - Extract unique import complete
2025-04-16 12:52:32,118 - INFO - Update relative import start
2025-04-16 12:52:32,119 - INFO - Update relative import complete
2025-04-16 12:52:42,107 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-16 12:52:42,108 - INFO - Generate Unit Test Case complete
2025-04-16 12:52:42,112 - INFO - run_each_pytest_function_individually start
2025-04-16 12:52:55,202 - INFO - Number of test case to process - 6
2025-04-16 12:52:55,203 - INFO - 

2025-04-16 12:52:55,203 - INFO - TEST CASE 1 Retry 0
2025-04-16 12:52:55,203 - INFO - ---------------
2025-04-16 12:52:55,203 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest


@pytest.mark.asyncio
async def test_openai_llm_initialization():
    with patch("theory_evaluation.llm_handler.AzureOpenAI") as mock_azure_openai, \
         patch("theory_evaluation.llm_handler.OpenAI") as mock_openai, \
         patch("theory_evaluation.llm_handler.os.getenv", return_value="test_value"):

2025-04-16 12:52:55,203 - INFO - ---------------
2025-04-16 12:52:56,012 - INFO - TEST CASE 1 Retry 0 - Result - Failed
2025-04-16 12:52:56,012 - INFO - Test Error 1 - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
.venv\Lib\site-packages\_pytest\python.py:493: in importtestmodule
    mod = import_path(
.venv\Lib\site-packages\_pytest\pathlib.py:587: in import_path
    importlib.import_module(module_name)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1387: in _gcd_import
    ???
<frozen importlib._bootstrap>:1360: in _find_and_load
    ???
<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:935: in _load_unlocked
    ???
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:176: in exec_module
    source_stat, co = _rewrite_test(fn, self.config)
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:356: in _rewrite_test
    tree = ast.parse(source, filename=strfn)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\ast.py:54: in parse
    return compile(source, filename, mode, flags,
E     File "C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py", line 14
E       patch("theory_evaluation.llm_handler.os.getenv", return_value="test_value"):
E                                                                                   ^
E   IndentationError: expected an indented block after 'with' statement on line 12
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 0.27s
2025-04-16 12:52:59,370 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-16 12:52:59,371 - INFO - TEST CASE 1 Retry 1
2025-04-16 12:52:59,371 - INFO - ---------------
2025-04-16 12:52:59,372 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest


# New Test Case
@pytest.mark.asyncio
async def test_openai_llm_initialization():
    with patch("theory_evaluation.llm_handler.AzureOpenAI") as mock_azure_openai, \
         patch("theory_evaluation.llm_handler.OpenAI") as mock_openai, \
         patch("theory_evaluation.llm_handler.os.getenv", return_value="test_value"):
        # Add the indented block here
        llm = OpenAI_llm(
            useAzureOpenAI=True,
            azure_endpoint="test_endpoint",
            message="test_message",
            image_input="test_image_input",
            api_version="test_api_version",
            model_name="test_model_name",
            max_retries=3,
            output="json",
            mode="text_generation",
            config={"temperature": 0.5},
            verbose=True,
        )
        assert llm.azure_endpoint == "test_endpoint"
        assert llm.api_version == "test_api_version"
        assert llm.model_name == "test_model_name"
        assert llm.message == "test_message"
        assert llm.image_input == "test_image_input"
        assert llm.max_retries == 3
        assert llm.output == "json"
        assert llm.mode == "text_generation"
        assert llm.config["temperature"] == 0.5
        assert llm.verbose is True

2025-04-16 12:52:59,372 - INFO - ---------------
2025-04-16 12:53:01,667 - INFO - TEST CASE 1 Retry 1 - Result - Failed
2025-04-16 12:53:01,667 - INFO - Test Error 2 - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:6: in <module>
    from theory_evaluation.llm_handler import OpenAI_llm
theory_evaluation\__init__.py:1: in <module>
    from . import config
E   ImportError: cannot import name 'config' from partially initialized module 'theory_evaluation' (most likely due to a circular import) (C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\__init__.py)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 1.25s
2025-04-16 12:53:01,667 - INFO - Failed after all retries for test case 1
2025-04-16 12:53:05,408 - INFO - TEST CASE 1 Retry 2
2025-04-16 12:53:05,409 - INFO - ---------------
2025-04-16 12:53:05,409 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest


# New Test Case
from unittest.mock import patch
import pytest
from theory_evaluation.llm_handler import OpenAI_llm

@pytest.mark.asyncio
async def test_openai_llm_initialization():
    with patch("theory_evaluation.llm_handler.AzureOpenAI") as mock_azure_openai, \
         patch("theory_evaluation.llm_handler.OpenAI") as mock_openai, \
         patch("theory_evaluation.llm_handler.os.getenv", side_effect=lambda key: {
             "AZURE_OPENAI_ENDPOINT_SWEDEN": "test_endpoint",
             "AZURE_OPENAI_API_VERSION": "test_api_version",
             "AZURE_OPENAI_DEPLOYMENT_NAME": "test_model_name",
             "OPENAI_DEPLOYMENT_NAME": "test_model_name"
         }.get(key, "test_value")):
        llm = OpenAI_llm(
            useAzureOpenAI=True,
            azure_endpoint="test_endpoint",
            message="test_message",
            image_input="test_image_input",
            api_version="test_api_version",
            model_name="test_model_name",
            max_retries=3,
            output="json",
            mode="text_generation",
            config={"temperature": 0.5},
            verbose=True,
        )
        assert llm.azure_endpoint == "test_endpoint"
        assert llm.api_version == "test_api_version"
        assert llm.model_name == "test_model_name"
        assert llm.message == "test_message"
        assert llm.image_input == "test_image_input"
        assert llm.max_retries == 3
        assert llm.output == "json"
        assert llm.mode == "text_generation"
        assert llm.config["temperature"] == 0.5
        assert llm.verbose is True

2025-04-16 12:53:05,410 - INFO - ---------------
2025-04-16 12:53:08,028 - INFO - TEST CASE 1 Retry 2 - Result - Failed
2025-04-16 12:53:08,028 - INFO - Test Error 3 - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:6: in <module>
    from theory_evaluation.llm_handler import OpenAI_llm
theory_evaluation\__init__.py:1: in <module>
    from . import config
E   ImportError: cannot import name 'config' from partially initialized module 'theory_evaluation' (most likely due to a circular import) (C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\__init__.py)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 1.71s
2025-04-16 12:53:08,028 - INFO - Failed after all retries for test case 1
2025-04-16 12:53:13,093 - INFO - TEST CASE 1 Retry 3
2025-04-16 12:53:13,094 - INFO - ---------------
2025-04-16 12:53:13,094 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest


# New Test Case
from unittest.mock import patch
import pytest
from theory_evaluation.llm_handler import OpenAI_llm

@pytest.mark.asyncio
async def test_openai_llm_initialization():
    with patch("theory_evaluation.llm_handler.AzureOpenAI") as mock_azure_openai, \
         patch("theory_evaluation.llm_handler.OpenAI") as mock_openai, \
         patch("theory_evaluation.llm_handler.os.getenv", side_effect=lambda key: {
             "AZURE_OPENAI_ENDPOINT_SWEDEN": "test_endpoint",
             "AZURE_OPENAI_API_VERSION": "test_api_version",
             "AZURE_OPENAI_DEPLOYMENT_NAME": "test_model_name",
             "OPENAI_DEPLOYMENT_NAME": "test_model_name"
         }.get(key, "test_value")):
        llm = OpenAI_llm(
            useAzureOpenAI=True,
            azure_endpoint="test_endpoint",
            message="test_message",
            image_input="test_image_input",
            api_version="test_api_version",
            model_name="test_model_name",
            max_retries=3,
            output="json",
            mode="text_generation",
            config={"temperature": 0.5},
            verbose=True,
        )
        assert llm.azure_endpoint == "test_endpoint"
        assert llm.api_version == "test_api_version"
        assert llm.model_name == "test_model_name"
        assert llm.message == "test_message"
        assert llm.image_input == "test_image_input"
        assert llm.max_retries == 3
        assert llm.output == "json"
        assert llm.mode == "text_generation"
        assert llm.config["temperature"] == 0.5
        assert llm.verbose is True

2025-04-16 12:53:13,094 - INFO - ---------------
2025-04-16 12:53:15,172 - INFO - TEST CASE 1 Retry 3 - Result - Failed
2025-04-16 12:53:15,173 - INFO - Test Error 4 - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:6: in <module>
    from theory_evaluation.llm_handler import OpenAI_llm
theory_evaluation\__init__.py:1: in <module>
    from . import config
E   ImportError: cannot import name 'config' from partially initialized module 'theory_evaluation' (most likely due to a circular import) (C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\__init__.py)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 1.13s
2025-04-16 12:53:15,173 - INFO - Failed after all retries for test case 1
2025-04-16 12:53:15,174 - INFO - 

2025-04-16 12:53:15,174 - INFO - TEST CASE 2 Retry 0
2025-04-16 12:53:15,174 - INFO - ---------------
2025-04-16 12:53:15,174 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest


@pytest.mark.asyncio
async def test_openai_llm_openai_json_completion():
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client") as mock_client:
        mock_response = MagicMock()
        mock_response.choices[0].message.content = json.dumps({"answer": "42", "explanation": "The answer to life"})
        mock_client.chat.completions.create.return_value = mock_response

2025-04-16 12:53:15,175 - INFO - ---------------
2025-04-16 12:53:17,107 - INFO - TEST CASE 2 Retry 0 - Result - Failed
2025-04-16 12:53:17,108 - INFO - Test Error 1 - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:6: in <module>
    from theory_evaluation.llm_handler import OpenAI_llm
theory_evaluation\__init__.py:1: in <module>
    from . import config
E   ImportError: cannot import name 'config' from partially initialized module 'theory_evaluation' (most likely due to a circular import) (C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\__init__.py)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 1.12s
2025-04-16 12:53:19,695 - INFO - TEST CASE 2 Retry 1
2025-04-16 12:53:19,695 - INFO - ---------------
2025-04-16 12:53:19,696 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest


# New Test Case
from unittest.mock import patch, MagicMock
import pytest
import json
from theory_evaluation.llm_handler import OpenAI_llm

@pytest.mark.asyncio
async def test_openai_llm_openai_json_completion():
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client") as mock_client:
        mock_response = MagicMock()
        mock_response.choices = [MagicMock()]
        mock_response.choices[0].message.content = json.dumps({"answer": "42", "explanation": "The answer to life"})
        mock_client.chat.completions.create.return_value = mock_response

        llm = OpenAI_llm(output="json")
        result = await llm._OpenAI_JSON_Completion()
        assert result == {"answer": "42", "explanation": "The answer to life"}

2025-04-16 12:53:19,696 - INFO - ---------------
2025-04-16 12:53:21,709 - INFO - TEST CASE 2 Retry 1 - Result - Failed
2025-04-16 12:53:21,709 - INFO - Test Error 2 - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:6: in <module>
    from theory_evaluation.llm_handler import OpenAI_llm
theory_evaluation\__init__.py:1: in <module>
    from . import config
E   ImportError: cannot import name 'config' from partially initialized module 'theory_evaluation' (most likely due to a circular import) (C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\__init__.py)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 1.14s
2025-04-16 12:53:21,709 - INFO - Failed after all retries for test case 2
2025-04-16 12:53:23,892 - INFO - TEST CASE 2 Retry 2
2025-04-16 12:53:23,892 - INFO - ---------------
2025-04-16 12:53:23,893 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest


# New Test Case
from unittest.mock import patch, MagicMock
import pytest
import json
from theory_evaluation.llm_handler import OpenAI_llm

@pytest.mark.asyncio
async def test_openai_llm_openai_json_completion():
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client") as mock_client:
        mock_response = MagicMock()
        mock_response.choices = [MagicMock()]
        mock_response.choices[0].message.content = json.dumps({"answer": "42", "explanation": "The answer to life"})
        mock_client.chat.completions.create.return_value = mock_response

        llm = OpenAI_llm(output="json", message="Test message")
        result = await llm._OpenAI_JSON_Completion()
        assert result == {"answer": "42", "explanation": "The answer to life"}

2025-04-16 12:53:23,893 - INFO - ---------------
2025-04-16 12:53:27,039 - INFO - TEST CASE 2 Retry 2 - Result - Failed
2025-04-16 12:53:27,039 - INFO - Test Error 3 - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:6: in <module>
    from theory_evaluation.llm_handler import OpenAI_llm
theory_evaluation\__init__.py:1: in <module>
    from . import config
E   ImportError: cannot import name 'config' from partially initialized module 'theory_evaluation' (most likely due to a circular import) (C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\__init__.py)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 2.00s
2025-04-16 12:53:27,039 - INFO - Failed after all retries for test case 2
2025-04-16 12:53:29,682 - INFO - TEST CASE 2 Retry 3
2025-04-16 12:53:29,683 - INFO - ---------------
2025-04-16 12:53:29,683 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest


# New Test Case
from unittest.mock import patch, MagicMock
import pytest
import json
from theory_evaluation.llm_handler import OpenAI_llm

@pytest.mark.asyncio
async def test_openai_llm_openai_json_completion():
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client") as mock_client:
        mock_response = MagicMock()
        mock_response.choices = [MagicMock()]
        mock_response.choices[0].message.content = json.dumps({"answer": "42", "explanation": "The answer to life"})
        mock_client.chat.completions.create.return_value = mock_response

        llm = OpenAI_llm(output="json", message="Test message")
        result = await llm._OpenAI_JSON_Completion(messages=[{"role": "system", "content": "Test message"}], model=None, temperature=0, max_tokens=1000, top_p=1.0, frequency_penalty=0.0, presence_penalty=0.0)
        assert result == {"answer": "42", "explanation": "The answer to life"}

2025-04-16 12:53:29,683 - INFO - ---------------
2025-04-16 12:53:31,799 - INFO - TEST CASE 2 Retry 3 - Result - Failed
2025-04-16 12:53:31,800 - INFO - Test Error 4 - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:6: in <module>
    from theory_evaluation.llm_handler import OpenAI_llm
theory_evaluation\__init__.py:1: in <module>
    from . import config
E   ImportError: cannot import name 'config' from partially initialized module 'theory_evaluation' (most likely due to a circular import) (C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\__init__.py)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 1.16s
2025-04-16 12:53:31,800 - INFO - Failed after all retries for test case 2
2025-04-16 12:53:31,800 - INFO - 

2025-04-16 12:53:31,800 - INFO - TEST CASE 3 Retry 0
2025-04-16 12:53:31,800 - INFO - ---------------
2025-04-16 12:53:31,800 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest


@pytest.mark.asyncio
async def test_openai_llm_openai_streaming():
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client") as mock_client:
        mock_stream = [MagicMock(choices=[MagicMock(delta=MagicMock(content="chunk1"))]),
                       MagicMock(choices=[MagicMock(delta=MagicMock(content="chunk2"))])]
        mock_client.chat.completions.create.return_value = mock_stream

2025-04-16 12:53:31,800 - INFO - ---------------
2025-04-16 12:53:34,108 - INFO - TEST CASE 3 Retry 0 - Result - Failed
2025-04-16 12:53:34,109 - INFO - Test Error 1 - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:6: in <module>
    from theory_evaluation.llm_handler import OpenAI_llm
theory_evaluation\__init__.py:1: in <module>
    from . import config
E   ImportError: cannot import name 'config' from partially initialized module 'theory_evaluation' (most likely due to a circular import) (C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\__init__.py)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 1.42s
2025-04-16 12:53:36,958 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-16 12:53:36,959 - INFO - TEST CASE 3 Retry 1
2025-04-16 12:53:36,959 - INFO - ---------------
2025-04-16 12:53:36,959 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest


# New Test Case
import pytest
from unittest.mock import patch, MagicMock
from theory_evaluation.llm_handler import OpenAI_llm

@pytest.mark.asyncio
async def test_openai_llm_openai_streaming():
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client") as mock_client:
        mock_stream = [MagicMock(choices=[MagicMock(delta=MagicMock(content="chunk1"))]),
                       MagicMock(choices=[MagicMock(delta=MagicMock(content="chunk2"))])]
        mock_client.chat.completions.create.return_value = mock_stream

        llm = OpenAI_llm(output="stream")
        result = []
        async for chunk in llm.execute():
            result.append(chunk)

        assert result == ["chunk1", "chunk2"]

2025-04-16 12:53:36,959 - INFO - ---------------
2025-04-16 12:53:39,094 - INFO - TEST CASE 3 Retry 1 - Result - Failed
2025-04-16 12:53:39,094 - INFO - Test Error 2 - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:6: in <module>
    from theory_evaluation.llm_handler import OpenAI_llm
theory_evaluation\__init__.py:1: in <module>
    from . import config
E   ImportError: cannot import name 'config' from partially initialized module 'theory_evaluation' (most likely due to a circular import) (C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\__init__.py)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 1.23s
2025-04-16 12:53:39,095 - INFO - Failed after all retries for test case 3
2025-04-16 12:53:41,193 - INFO - TEST CASE 3 Retry 2
2025-04-16 12:53:41,194 - INFO - ---------------
2025-04-16 12:53:41,194 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest


# New Test Case
import pytest
from unittest.mock import patch, MagicMock
from theory_evaluation.llm_handler import OpenAI_llm

@pytest.mark.asyncio
async def test_openai_llm_openai_streaming():
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client") as mock_client:
        mock_stream = [MagicMock(choices=[MagicMock(delta=MagicMock(content="chunk1"))]),
                       MagicMock(choices=[MagicMock(delta=MagicMock(content="chunk2"))])]
        mock_client.chat.completions.create.return_value = mock_stream

        llm = OpenAI_llm(output="stream")
        result = []
        async for chunk in llm.execute():
            result.append(chunk)

        assert result == ["chunk1", "chunk2"]

2025-04-16 12:53:41,194 - INFO - ---------------
2025-04-16 12:53:43,305 - INFO - TEST CASE 3 Retry 2 - Result - Failed
2025-04-16 12:53:43,306 - INFO - Test Error 3 - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:6: in <module>
    from theory_evaluation.llm_handler import OpenAI_llm
theory_evaluation\__init__.py:1: in <module>
    from . import config
E   ImportError: cannot import name 'config' from partially initialized module 'theory_evaluation' (most likely due to a circular import) (C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\__init__.py)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 1.15s
2025-04-16 12:53:43,306 - INFO - Failed after all retries for test case 3
2025-04-16 12:53:45,555 - INFO - TEST CASE 3 Retry 3
2025-04-16 12:53:45,555 - INFO - ---------------
2025-04-16 12:53:45,556 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest


# New Test Case
import pytest
from unittest.mock import patch, MagicMock
from theory_evaluation.llm_handler import OpenAI_llm

@pytest.mark.asyncio
async def test_openai_llm_openai_streaming():
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client") as mock_client:
        mock_stream = [MagicMock(choices=[MagicMock(delta=MagicMock(content="chunk1"))]),
                       MagicMock(choices=[MagicMock(delta=MagicMock(content="chunk2"))])]
        mock_client.chat.completions.create.return_value = mock_stream

        llm = OpenAI_llm(output="stream", model_name="test_model")
        result = []
        async for chunk in llm.execute():
            result.append(chunk)

        assert result == ["chunk1", "chunk2"]

2025-04-16 12:53:45,556 - INFO - ---------------
2025-04-16 12:53:48,062 - INFO - TEST CASE 3 Retry 3 - Result - Failed
2025-04-16 12:53:48,062 - INFO - Test Error 4 - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:6: in <module>
    from theory_evaluation.llm_handler import OpenAI_llm
theory_evaluation\__init__.py:1: in <module>
    from . import config
E   ImportError: cannot import name 'config' from partially initialized module 'theory_evaluation' (most likely due to a circular import) (C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\__init__.py)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 1.16s
2025-04-16 12:53:48,062 - INFO - Failed after all retries for test case 3
2025-04-16 12:53:48,062 - INFO - 

2025-04-16 12:53:48,062 - INFO - TEST CASE 4 Retry 0
2025-04-16 12:53:48,062 - INFO - ---------------
2025-04-16 12:53:48,062 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest


@pytest.mark.asyncio
async def test_openai_llm_openai_chat_completion():
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client") as mock_client:
        mock_response = MagicMock()
        mock_response.choices[0].message.content = "Chat completion content"
        mock_client.chat.completions.create.return_value = mock_response

2025-04-16 12:53:48,063 - INFO - ---------------
2025-04-16 12:53:50,361 - INFO - TEST CASE 4 Retry 0 - Result - Failed
2025-04-16 12:53:50,361 - INFO - Test Error 1 - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:6: in <module>
    from theory_evaluation.llm_handler import OpenAI_llm
theory_evaluation\__init__.py:1: in <module>
    from . import config
E   ImportError: cannot import name 'config' from partially initialized module 'theory_evaluation' (most likely due to a circular import) (C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\__init__.py)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 1.58s
2025-04-16 12:53:52,663 - INFO - TEST CASE 4 Retry 1
2025-04-16 12:53:52,664 - INFO - ---------------
2025-04-16 12:53:52,664 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest


# New Test Case
from unittest.mock import patch, MagicMock
import pytest
from theory_evaluation.llm_handler import OpenAI_llm

@pytest.mark.asyncio
async def test_openai_llm_openai_chat_completion():
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client") as mock_client:
        mock_response = MagicMock()
        mock_response.choices = [MagicMock()]
        mock_response.choices[0].message.content = "Chat completion content"
        mock_client.chat.completions.create.return_value = mock_response

        llm = OpenAI_llm(message="Test message", useAzureOpenAI=False)
        response = await llm._OpenAI_Chat_Completion(messages=[{"role": "system", "content": llm.message}], model=llm.model_name, **llm.config)

        assert response == "Chat completion content"

2025-04-16 12:53:52,664 - INFO - ---------------
2025-04-16 12:53:54,789 - INFO - TEST CASE 4 Retry 1 - Result - Failed
2025-04-16 12:53:54,789 - INFO - Test Error 2 - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:6: in <module>
    from theory_evaluation.llm_handler import OpenAI_llm
theory_evaluation\__init__.py:1: in <module>
    from . import config
E   ImportError: cannot import name 'config' from partially initialized module 'theory_evaluation' (most likely due to a circular import) (C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\__init__.py)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 1.23s
2025-04-16 12:53:54,789 - INFO - Failed after all retries for test case 4
2025-04-16 12:53:58,253 - INFO - TEST CASE 4 Retry 2
2025-04-16 12:53:58,253 - INFO - ---------------
2025-04-16 12:53:58,253 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest


# New Test Case
from unittest.mock import patch, MagicMock
import pytest
from theory_evaluation.llm_handler import OpenAI_llm

@pytest.mark.asyncio
async def test_openai_llm_openai_chat_completion():
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client") as mock_client:
        mock_response = MagicMock()
        mock_response.choices = [MagicMock()]
        mock_response.choices[0].message.content = "Chat completion content"
        mock_client.chat.completions.create.return_value = mock_response

        llm = OpenAI_llm(message="Test message", useAzureOpenAI=False)
        response = await llm._OpenAI_Chat_Completion(messages=[{"role": "system", "content": llm.message}], model=llm.model_name, **llm.config)

        assert response == "Chat completion content"

2025-04-16 12:53:58,254 - INFO - ---------------
2025-04-16 12:54:00,463 - INFO - TEST CASE 4 Retry 2 - Result - Failed
2025-04-16 12:54:00,463 - INFO - Test Error 3 - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:6: in <module>
    from theory_evaluation.llm_handler import OpenAI_llm
theory_evaluation\__init__.py:1: in <module>
    from . import config
E   ImportError: cannot import name 'config' from partially initialized module 'theory_evaluation' (most likely due to a circular import) (C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\__init__.py)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 1.32s
2025-04-16 12:54:00,463 - INFO - Failed after all retries for test case 4
2025-04-16 12:54:02,794 - INFO - TEST CASE 4 Retry 3
2025-04-16 12:54:02,795 - INFO - ---------------
2025-04-16 12:54:02,795 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest


# New Test Case
from unittest.mock import patch, MagicMock
import pytest
from theory_evaluation.llm_handler import OpenAI_llm

@pytest.mark.asyncio
async def test_openai_llm_openai_chat_completion():
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client") as mock_client:
        mock_response = MagicMock()
        mock_response.choices = [MagicMock()]
        mock_response.choices[0].message.content = "Chat completion content"
        mock_client.chat.completions.create.return_value = mock_response

        llm = OpenAI_llm(message="Test message", useAzureOpenAI=False)
        response = await llm._OpenAI_Chat_Completion(messages=[{"role": "system", "content": llm.message}], model=llm.model_name, **llm.config)

        assert response == "Chat completion content"

2025-04-16 12:54:02,795 - INFO - ---------------
2025-04-16 12:54:05,649 - INFO - TEST CASE 4 Retry 3 - Result - Failed
2025-04-16 12:54:05,649 - INFO - Test Error 4 - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:6: in <module>
    from theory_evaluation.llm_handler import OpenAI_llm
theory_evaluation\__init__.py:1: in <module>
    from . import config
E   ImportError: cannot import name 'config' from partially initialized module 'theory_evaluation' (most likely due to a circular import) (C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\__init__.py)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 1.82s
2025-04-16 12:54:05,650 - INFO - Failed after all retries for test case 4
2025-04-16 12:54:05,650 - INFO - 

2025-04-16 12:54:05,650 - INFO - TEST CASE 5 Retry 0
2025-04-16 12:54:05,650 - INFO - ---------------
2025-04-16 12:54:05,651 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest


@pytest.mark.asyncio
async def test_openai_llm_execute_text_generation():
    with patch("theory_evaluation.llm_handler.OpenAI_llm._run", new_callable=AsyncMock) as mock_run:
        mock_run.return_value = AsyncMock()
        mock_run.return_value.__aiter__.return_value = ["response1", "response2"]

2025-04-16 12:54:05,651 - INFO - ---------------
2025-04-16 12:54:07,845 - INFO - TEST CASE 5 Retry 0 - Result - Failed
2025-04-16 12:54:07,846 - INFO - Test Error 1 - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:6: in <module>
    from theory_evaluation.llm_handler import OpenAI_llm
theory_evaluation\__init__.py:1: in <module>
    from . import config
E   ImportError: cannot import name 'config' from partially initialized module 'theory_evaluation' (most likely due to a circular import) (C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\__init__.py)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 1.28s
2025-04-16 12:54:11,319 - INFO - TEST CASE 5 Retry 1
2025-04-16 12:54:11,319 - INFO - ---------------
2025-04-16 12:54:11,319 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest


# New Test Case
from unittest.mock import patch, AsyncMock
import pytest
from theory_evaluation.llm_handler import OpenAI_llm

@pytest.mark.asyncio
async def test_openai_llm_execute_text_generation():
    with patch("theory_evaluation.llm_handler.OpenAI_llm._run", new_callable=AsyncMock) as mock_run:
        mock_run.return_value.__aiter__.return_value = ["response1", "response2"]
        
        llm = OpenAI_llm(message="Test message", output="stream")
        
        responses = []
        async for response in llm.execute():
            responses.append(response)
        
        assert responses == ["response1", "response2"]

2025-04-16 12:54:11,320 - INFO - ---------------
2025-04-16 12:54:13,346 - INFO - TEST CASE 5 Retry 1 - Result - Failed
2025-04-16 12:54:13,347 - INFO - Test Error 2 - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:6: in <module>
    from theory_evaluation.llm_handler import OpenAI_llm
theory_evaluation\__init__.py:1: in <module>
    from . import config
E   ImportError: cannot import name 'config' from partially initialized module 'theory_evaluation' (most likely due to a circular import) (C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\__init__.py)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 1.19s
2025-04-16 12:54:13,348 - INFO - Failed after all retries for test case 5
2025-04-16 12:54:15,099 - INFO - TEST CASE 5 Retry 2
2025-04-16 12:54:15,099 - INFO - ---------------
2025-04-16 12:54:15,100 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest


# New Test Case
from unittest.mock import patch, AsyncMock
import pytest
from theory_evaluation.llm_handler import OpenAI_llm

@pytest.mark.asyncio
async def test_openai_llm_execute_text_generation():
    with patch("theory_evaluation.llm_handler.OpenAI_llm._run", new_callable=AsyncMock) as mock_run:
        mock_run.return_value.__aiter__.return_value = ["response1", "response2"]
        
        llm = OpenAI_llm(message="Test message", output="stream")
        
        responses = []
        async for response in llm.execute():
            responses.append(response)
        
        assert responses == ["response1", "response2"]

2025-04-16 12:54:15,100 - INFO - ---------------
2025-04-16 12:54:17,022 - INFO - TEST CASE 5 Retry 2 - Result - Failed
2025-04-16 12:54:17,023 - INFO - Test Error 3 - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:6: in <module>
    from theory_evaluation.llm_handler import OpenAI_llm
theory_evaluation\__init__.py:1: in <module>
    from . import config
E   ImportError: cannot import name 'config' from partially initialized module 'theory_evaluation' (most likely due to a circular import) (C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\__init__.py)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 1.05s
2025-04-16 12:54:17,023 - INFO - Failed after all retries for test case 5
2025-04-16 12:54:19,464 - INFO - TEST CASE 5 Retry 3
2025-04-16 12:54:19,465 - INFO - ---------------
2025-04-16 12:54:19,465 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest


# New Test Case
from unittest.mock import patch, AsyncMock
import pytest
from theory_evaluation.llm_handler import OpenAI_llm

@pytest.mark.asyncio
async def test_openai_llm_execute_text_generation():
    with patch("theory_evaluation.llm_handler.OpenAI_llm._run", new_callable=AsyncMock) as mock_run:
        mock_run.return_value.__aiter__.return_value = ["response1", "response2"]
        
        llm = OpenAI_llm(message="Test message", output="stream", model_name="test_model")
        
        responses = []
        async for response in llm.execute():
            responses.append(response)
        
        assert responses == ["response1", "response2"]

2025-04-16 12:54:19,465 - INFO - ---------------
2025-04-16 12:54:21,402 - INFO - TEST CASE 5 Retry 3 - Result - Failed
2025-04-16 12:54:21,402 - INFO - Test Error 4 - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:6: in <module>
    from theory_evaluation.llm_handler import OpenAI_llm
theory_evaluation\__init__.py:1: in <module>
    from . import config
E   ImportError: cannot import name 'config' from partially initialized module 'theory_evaluation' (most likely due to a circular import) (C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\__init__.py)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 1.13s
2025-04-16 12:54:21,403 - INFO - Failed after all retries for test case 5
2025-04-16 12:54:21,403 - INFO - 

2025-04-16 12:54:21,403 - INFO - TEST CASE 6 Retry 0
2025-04-16 12:54:21,403 - INFO - ---------------
2025-04-16 12:54:21,403 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest


@pytest.mark.asyncio
async def test_openai_llm_execute_vision():
    with patch("theory_evaluation.llm_handler.OpenAI_llm._run", new_callable=AsyncMock) as mock_run:
        mock_run.return_value = AsyncMock()
        mock_run.return_value.__aiter__.return_value = ["response1", "response2"]

2025-04-16 12:54:21,403 - INFO - ---------------
2025-04-16 12:54:23,415 - INFO - TEST CASE 6 Retry 0 - Result - Failed
2025-04-16 12:54:23,416 - INFO - Test Error 1 - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:6: in <module>
    from theory_evaluation.llm_handler import OpenAI_llm
theory_evaluation\__init__.py:1: in <module>
    from . import config
E   ImportError: cannot import name 'config' from partially initialized module 'theory_evaluation' (most likely due to a circular import) (C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\__init__.py)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 1.19s
2025-04-16 12:54:25,506 - INFO - TEST CASE 6 Retry 1
2025-04-16 12:54:25,507 - INFO - ---------------
2025-04-16 12:54:25,507 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest


# New Test Case
from unittest.mock import patch, AsyncMock
import pytest
from theory_evaluation.llm_handler import OpenAI_llm

@pytest.mark.asyncio
async def test_openai_llm_execute_vision():
    with patch("theory_evaluation.llm_handler.OpenAI_llm._run", new_callable=AsyncMock) as mock_run:
        mock_run.return_value.__aiter__.return_value = ["response1", "response2"]
        
        llm = OpenAI_llm(
            message="Test message",
            mode="vision",
            image_input="test_image_data",
            output="stream"
        )
        
        responses = []
        async for response in llm.execute():
            responses.append(response)
        
        assert responses == ["response1", "response2"]

2025-04-16 12:54:25,507 - INFO - ---------------
2025-04-16 12:54:28,515 - INFO - TEST CASE 6 Retry 1 - Result - Failed
2025-04-16 12:54:28,515 - INFO - Test Error 2 - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:6: in <module>
    from theory_evaluation.llm_handler import OpenAI_llm
theory_evaluation\__init__.py:1: in <module>
    from . import config
E   ImportError: cannot import name 'config' from partially initialized module 'theory_evaluation' (most likely due to a circular import) (C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\__init__.py)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 1.74s
2025-04-16 12:54:28,515 - INFO - Failed after all retries for test case 6
2025-04-16 12:54:31,165 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-16 12:54:31,166 - INFO - TEST CASE 6 Retry 2
2025-04-16 12:54:31,166 - INFO - ---------------
2025-04-16 12:54:31,166 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest


# New Test Case
from unittest.mock import patch, AsyncMock
import pytest
from theory_evaluation.llm_handler import OpenAI_llm

@pytest.mark.asyncio
async def test_openai_llm_execute_vision():
    with patch("theory_evaluation.llm_handler.OpenAI_llm._run", new_callable=AsyncMock) as mock_run:
        mock_run.return_value.__aiter__.return_value = ["response1", "response2"]
        
        llm = OpenAI_llm(
            message="Test message",
            mode="vision",
            image_input="test_image_data",
            output="stream"
        )
        
        responses = []
        async for response in llm.execute():
            responses.append(response)
        
        assert responses == ["response1", "response2"]

2025-04-16 12:54:31,166 - INFO - ---------------
2025-04-16 12:54:32,940 - INFO - TEST CASE 6 Retry 2 - Result - Failed
2025-04-16 12:54:32,941 - INFO - Test Error 3 - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:6: in <module>
    from theory_evaluation.llm_handler import OpenAI_llm
theory_evaluation\__init__.py:1: in <module>
    from . import config
E   ImportError: cannot import name 'config' from partially initialized module 'theory_evaluation' (most likely due to a circular import) (C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\__init__.py)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 1.00s
2025-04-16 12:54:32,942 - INFO - Failed after all retries for test case 6
2025-04-16 12:54:35,726 - INFO - TEST CASE 6 Retry 3
2025-04-16 12:54:35,727 - INFO - ---------------
2025-04-16 12:54:35,728 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest


# New Test Case
from unittest.mock import patch, AsyncMock
import pytest
from theory_evaluation.llm_handler import OpenAI_llm

@pytest.mark.asyncio
async def test_openai_llm_execute_vision():
    with patch("theory_evaluation.llm_handler.OpenAI_llm._run", new_callable=AsyncMock) as mock_run:
        mock_run.return_value.__aiter__.return_value = ["response1", "response2"]
        
        llm = OpenAI_llm(
            message="Test message",
            mode="vision",
            image_input="test_image_data",
            output="stream"
        )
        
        responses = []
        async for response in llm.execute():
            responses.append(response)
        
        assert responses == ["response1", "response2"]

2025-04-16 12:54:35,728 - INFO - ---------------
2025-04-16 12:54:37,628 - INFO - TEST CASE 6 Retry 3 - Result - Failed
2025-04-16 12:54:37,629 - INFO - Test Error 4 - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:6: in <module>
    from theory_evaluation.llm_handler import OpenAI_llm
theory_evaluation\__init__.py:1: in <module>
    from . import config
E   ImportError: cannot import name 'config' from partially initialized module 'theory_evaluation' (most likely due to a circular import) (C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\__init__.py)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 1.05s
2025-04-16 12:54:37,629 - INFO - Failed after all retries for test case 6
2025-04-16 12:54:37,629 - INFO - run_each_pytest_function_individually complete
2025-04-16 12:54:37,630 - INFO - End Processing file: theory_evaluation\llm_handler.py

2025-04-16 12:54:37,630 - INFO - 
Start Processing file: theory_evaluation\__init__.py
2025-04-16 12:54:37,630 - INFO - Extraction of function and class start
2025-04-16 12:54:37,630 - INFO - extraction of function and class complete
2025-04-16 12:54:37,631 - WARNING - No public functions found in theory_evaluation\__init__.py. Skipping test generation.

