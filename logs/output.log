2025-04-15 14:24:40,196 - INFO - Loading environment variables...
2025-04-15 14:24:40,516 - INFO - [1mStart Processing file: theory_evaluation\llm_handler.py[0m
2025-04-15 14:25:01,558 - INFO - 

2025-04-15 14:25:01,559 - INFO - TEST CASE 1 Retry 0
2025-04-15 14:25:01,559 - INFO - ---------------
2025-04-15 14:25:01,559 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI



@pytest.mark.asyncio
async def test_openai_llm_initialization():
    with patch("theory_evaluation.llm_handler.AzureOpenAI") as mock_azure_openai, \
         patch("theory_evaluation.llm_handler.OpenAI") as mock_openai, \
         patch("theory_evaluation.llm_handler.os.getenv", return_value="test_value"):
        
        llm = OpenAI_llm(useAzureOpenAI=True, message="Test message")
        assert llm.message == "Test message"
        assert llm.azure_endpoint == "test_value"
        assert llm.api_version == "test_value"
        assert llm.model_name == "test_value"
        assert hasattr(llm, "client")
        assert mock_azure_openai.called

2025-04-15 14:25:01,562 - INFO - ---------------
2025-04-15 14:25:04,440 - INFO - Test Result 1- False
2025-04-15 14:25:04,440 - INFO - Test Error 1 - =================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
temp\temp.py:9: in <module>
    @pytest.mark.asyncio
E   NameError: name 'pytest' is not defined
=========================== short test summary info ===========================
ERROR temp/temp.py - NameError: name 'pytest' is not defined
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 1.97s
2025-04-15 14:25:08,037 - INFO - TEST CASE 1 Retry 1
2025-04-15 14:25:08,038 - INFO - ---------------
2025-04-15 14:25:08,038 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI


import pytest
from unittest.mock import patch

@pytest.mark.asyncio
async def test_openai_llm_initialization():
    with patch("theory_evaluation.llm_handler.AzureOpenAI") as mock_azure_openai, \
         patch("theory_evaluation.llm_handler.OpenAI") as mock_openai, \
         patch("theory_evaluation.llm_handler.os.getenv", return_value="test_value"):
        
        llm = OpenAI_llm(useAzureOpenAI=True, message="Test message")
        assert llm.message == "Test message"
        assert llm.azure_endpoint == "test_value"
        assert llm.api_version == "test_value"
        assert llm.model_name == "test_value"
        assert hasattr(llm, "client")
        assert mock_azure_openai.called

2025-04-15 14:25:08,038 - INFO - ---------------
2025-04-15 14:25:10,783 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-15 14:25:10,784 - INFO - New import Statements 2- import pytest
from unittest.mock import patch
2025-04-15 14:25:10,784 - INFO - Test Result 2- True
2025-04-15 14:25:10,785 - INFO - Test Error 2 - 
s                                                                        [100%]
============================== warnings summary ===============================
temp\temp.py:11
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py:11: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

temp/temp.py::test_openai_llm_initialization
  C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\python.py:148: PytestUnhandledCoroutineWarning: async def functions are not natively supported and have been skipped.
  You need to install a suitable plugin for your async framework, for example:
    - anyio
    - pytest-asyncio
    - pytest-tornasync
    - pytest-trio
    - pytest-twisted
    warnings.warn(PytestUnhandledCoroutineWarning(msg.format(nodeid)))

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
1 skipped, 2 warnings in 1.03s
2025-04-15 14:25:10,785 - INFO - 

2025-04-15 14:25:10,786 - INFO - TEST CASE 2 Retry 0
2025-04-15 14:25:10,786 - INFO - ---------------
2025-04-15 14:25:10,786 - INFO - 
import pytest
from unittest.mock import patch


@pytest.mark.asyncio
async def test_openai_json_completion():
    mock_response = MagicMock()
    mock_response.choices[0].message.content = json.dumps({"answer": "42", "explanation": "The answer to life"})
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client.chat.completions.create", return_value=mock_response):
        llm = OpenAI_llm(message="Test message")
        result = await llm._OpenAI_JSON_Completion()
        assert result == {"answer": "42", "explanation": "The answer to life"}

2025-04-15 14:25:10,786 - INFO - ---------------
2025-04-15 14:25:11,469 - INFO - Test Result 1- True
2025-04-15 14:25:11,469 - INFO - Test Error 1 - s                                                                        [100%]
============================== warnings summary ===============================
temp\temp.py:5
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py:5: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

temp/temp.py::test_openai_json_completion
  C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\python.py:148: PytestUnhandledCoroutineWarning: async def functions are not natively supported and have been skipped.
  You need to install a suitable plugin for your async framework, for example:
    - anyio
    - pytest-asyncio
    - pytest-tornasync
    - pytest-trio
    - pytest-twisted
    warnings.warn(PytestUnhandledCoroutineWarning(msg.format(nodeid)))

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
1 skipped, 2 warnings in 0.06s
2025-04-15 14:25:11,469 - INFO - 

2025-04-15 14:25:11,469 - INFO - TEST CASE 3 Retry 0
2025-04-15 14:25:11,469 - INFO - ---------------
2025-04-15 14:25:11,470 - INFO - 
import pytest
from unittest.mock import patch


@pytest.mark.asyncio
async def test_openai_streaming():
    mock_chunk = MagicMock()
    mock_chunk.choices[0].delta.content = "streaming content"
    mock_stream = AsyncMock(return_value=[mock_chunk])
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client.chat.completions.create", return_value=mock_stream):
        llm = OpenAI_llm(message="Test message", output="stream")
        async for data in llm._OpenAI_Streaming():
            assert data == "streaming content"

2025-04-15 14:25:11,470 - INFO - ---------------
2025-04-15 14:25:12,113 - INFO - Test Result 1- True
2025-04-15 14:25:12,113 - INFO - Test Error 1 - s                                                                        [100%]
============================== warnings summary ===============================
temp\temp.py:5
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py:5: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

temp/temp.py::test_openai_streaming
  C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\python.py:148: PytestUnhandledCoroutineWarning: async def functions are not natively supported and have been skipped.
  You need to install a suitable plugin for your async framework, for example:
    - anyio
    - pytest-asyncio
    - pytest-tornasync
    - pytest-trio
    - pytest-twisted
    warnings.warn(PytestUnhandledCoroutineWarning(msg.format(nodeid)))

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
1 skipped, 2 warnings in 0.06s
2025-04-15 14:25:12,113 - INFO - 

2025-04-15 14:25:12,113 - INFO - TEST CASE 4 Retry 0
2025-04-15 14:25:12,113 - INFO - ---------------
2025-04-15 14:25:12,113 - INFO - 
import pytest
from unittest.mock import patch


@pytest.mark.asyncio
async def test_openai_chat_completion():
    mock_response = MagicMock()
    mock_response.choices[0].message.content = "chat completion content"
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client.chat.completions.create", return_value=mock_response):
        llm = OpenAI_llm(message="Test message")
        result = await llm._OpenAI_Chat_Completion()
        assert result == "chat completion content"

2025-04-15 14:25:12,113 - INFO - ---------------
2025-04-15 14:25:12,704 - INFO - Test Result 1- True
2025-04-15 14:25:12,704 - INFO - Test Error 1 - s                                                                        [100%]
============================== warnings summary ===============================
temp\temp.py:5
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py:5: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

temp/temp.py::test_openai_chat_completion
  C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\python.py:148: PytestUnhandledCoroutineWarning: async def functions are not natively supported and have been skipped.
  You need to install a suitable plugin for your async framework, for example:
    - anyio
    - pytest-asyncio
    - pytest-tornasync
    - pytest-trio
    - pytest-twisted
    warnings.warn(PytestUnhandledCoroutineWarning(msg.format(nodeid)))

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
1 skipped, 2 warnings in 0.07s
2025-04-15 14:25:12,704 - INFO - 

2025-04-15 14:25:12,704 - INFO - TEST CASE 5 Retry 0
2025-04-15 14:25:12,704 - INFO - ---------------
2025-04-15 14:25:12,704 - INFO - 
import pytest
from unittest.mock import patch


@pytest.mark.asyncio
async def test_execute_text_generation():
    mock_response = MagicMock()
    mock_response.choices[0].message.content = "execution content"
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client.chat.completions.create", return_value=mock_response):
        llm = OpenAI_llm(message="Test message", output=None)
        async for response in llm.execute():
            assert response == "execution content"

2025-04-15 14:25:12,704 - INFO - ---------------
2025-04-15 14:25:13,212 - INFO - Test Result 1- True
2025-04-15 14:25:13,213 - INFO - Test Error 1 - s                                                                        [100%]
============================== warnings summary ===============================
temp\temp.py:5
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py:5: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

temp/temp.py::test_openai_chat_completion
  C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\python.py:148: PytestUnhandledCoroutineWarning: async def functions are not natively supported and have been skipped.
  You need to install a suitable plugin for your async framework, for example:
    - anyio
    - pytest-asyncio
    - pytest-tornasync
    - pytest-trio
    - pytest-twisted
    warnings.warn(PytestUnhandledCoroutineWarning(msg.format(nodeid)))

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
1 skipped, 2 warnings in 0.06s
2025-04-15 14:25:13,213 - INFO - 

2025-04-15 14:25:13,213 - INFO - TEST CASE 6 Retry 0
2025-04-15 14:25:13,213 - INFO - ---------------
2025-04-15 14:25:13,213 - INFO - 
import pytest
from unittest.mock import patch


@pytest.mark.asyncio
async def test_execute_vision():
    mock_response = MagicMock()
    mock_response.choices[0].message.content = "vision content"
    with patch("theory_evaluation.llm_handler.OpenAI_llm.client.chat.completions.create", return_value=mock_response):
        llm = OpenAI_llm(message="Test message", mode="vision", image_input="image_data")
        async for response in llm.execute():
            assert response == "vision content"

2025-04-15 14:25:13,213 - INFO - ---------------
2025-04-15 14:25:13,744 - INFO - Test Result 1- True
2025-04-15 14:25:13,745 - INFO - Test Error 1 - s                                                                        [100%]
============================== warnings summary ===============================
temp\temp.py:5
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py:5: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

temp/temp.py::test_execute_vision
  C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\python.py:148: PytestUnhandledCoroutineWarning: async def functions are not natively supported and have been skipped.
  You need to install a suitable plugin for your async framework, for example:
    - anyio
    - pytest-asyncio
    - pytest-tornasync
    - pytest-trio
    - pytest-twisted
    warnings.warn(PytestUnhandledCoroutineWarning(msg.format(nodeid)))

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
1 skipped, 2 warnings in 0.07s
2025-04-15 14:25:13,745 - INFO - [1mEnd Processing file: theory_evaluation\llm_handler.py[0m

2025-04-15 14:25:13,746 - INFO - [1mStart Processing file: theory_evaluation\llm_utils.py[0m
2025-04-15 14:25:21,027 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-15 14:25:25,179 - INFO - [1mEnd Processing file: theory_evaluation\llm_utils.py[0m

2025-04-15 14:25:25,179 - INFO - [1mStart Processing file: theory_evaluation\__init__.py[0m
2025-04-15 14:25:25,180 - WARNING - No public functions found in theory_evaluation\__init__.py. Skipping test generation.

