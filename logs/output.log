2025-04-17 12:42:40,798 - INFO - Loading environment variables start
2025-04-17 12:42:40,809 - INFO - Loading environment variables completes
2025-04-17 12:42:40,809 - INFO - Initialising of LLM start
2025-04-17 12:42:41,356 - INFO - Initialising of LLM completes
2025-04-17 12:42:41,356 - INFO - Getting python file starts
2025-04-17 12:42:41,357 - INFO - Getting python file completes
2025-04-17 12:42:41,358 - INFO - 
Start Processing file: theory_evaluation\circle_utils.py
2025-04-17 12:42:41,358 - INFO - Extraction of function and class start
2025-04-17 12:42:41,359 - INFO - extraction of function and class complete
2025-04-17 12:42:41,359 - INFO - Generate Unit Test Case starts
2025-04-17 12:42:41,359 - INFO - Extract unique import start
2025-04-17 12:42:42,962 - INFO - Extract unique import complete
2025-04-17 12:42:42,962 - INFO - Update relative import start
2025-04-17 12:42:42,964 - INFO - Update relative import complete
2025-04-17 12:42:47,684 - INFO - Generate Unit Test Case complete
2025-04-17 12:42:47,691 - INFO - run_each_pytest_function_individually start
2025-04-17 12:42:55,551 - INFO - Number of test case to process - 10
2025-04-17 12:42:55,552 - INFO - 
TEST CASE 1 Retry 0
---------------
import math
from theory_evaluation.circle_utils import circle_area, circle_circumference
import pytest



def test_circle_area_returns_correct_value_for_positive_radius():
    # Arrange
    radius = 5.0
    expected_area = math.pi * radius ** 2

---------------
2025-04-17 12:42:56,917 - INFO - TEST CASE 1 Retry 0 - Result - Passed
2025-04-17 12:42:56,917 - INFO - 
TEST CASE 2 Retry 0
---------------
import math
from theory_evaluation.circle_utils import circle_area, circle_circumference
import pytest



def test_circle_area_raises_value_error_for_negative_radius():
    # Arrange
    radius = -5.0

---------------
2025-04-17 12:42:58,026 - INFO - TEST CASE 2 Retry 0 - Result - Passed
2025-04-17 12:42:58,026 - INFO - 
TEST CASE 3 Retry 0
---------------
import math
from theory_evaluation.circle_utils import circle_area, circle_circumference
import pytest



def test_circle_area_returns_zero_for_zero_radius():
    # Arrange
    radius = 0.0
    expected_area = 0.0

---------------
2025-04-17 12:42:59,032 - INFO - TEST CASE 3 Retry 0 - Result - Passed
2025-04-17 12:42:59,033 - INFO - 
TEST CASE 4 Retry 0
---------------
import math
from theory_evaluation.circle_utils import circle_area, circle_circumference
import pytest



def test_circle_circumference_returns_correct_value_for_positive_radius():
    # Arrange
    radius = 5.0
    expected_circumference = 2 * math.pi * radius

---------------
2025-04-17 12:42:59,975 - INFO - TEST CASE 4 Retry 0 - Result - Passed
2025-04-17 12:42:59,975 - INFO - 
TEST CASE 5 Retry 0
---------------
import math
from theory_evaluation.circle_utils import circle_area, circle_circumference
import pytest



def test_circle_circumference_raises_value_error_for_negative_radius():
    # Arrange
    radius = -5.0

---------------
2025-04-17 12:43:00,957 - INFO - TEST CASE 5 Retry 0 - Result - Passed
2025-04-17 12:43:00,957 - INFO - 
TEST CASE 6 Retry 0
---------------
import math
from theory_evaluation.circle_utils import circle_area, circle_circumference
import pytest



def test_circle_circumference_returns_zero_for_zero_radius():
    # Arrange
    radius = 0.0
    expected_circumference = 0.0

---------------
2025-04-17 12:43:01,999 - INFO - TEST CASE 6 Retry 0 - Result - Passed
2025-04-17 12:43:01,999 - INFO - 
TEST CASE 7 Retry 0
---------------
import math
from theory_evaluation.circle_utils import circle_area, circle_circumference
import pytest



def test_circle_area_handles_large_radius():
    # Arrange
    radius = 1e6
    expected_area = math.pi * radius ** 2

---------------
2025-04-17 12:43:03,451 - INFO - TEST CASE 7 Retry 0 - Result - Passed
2025-04-17 12:43:03,451 - INFO - 
TEST CASE 8 Retry 0
---------------
import math
from theory_evaluation.circle_utils import circle_area, circle_circumference
import pytest



def test_circle_circumference_handles_large_radius():
    # Arrange
    radius = 1e6
    expected_circumference = 2 * math.pi * radius

---------------
2025-04-17 12:43:04,737 - INFO - TEST CASE 8 Retry 0 - Result - Passed
2025-04-17 12:43:04,738 - INFO - 
TEST CASE 9 Retry 0
---------------
import math
from theory_evaluation.circle_utils import circle_area, circle_circumference
import pytest



def test_circle_area_handles_float_radius():
    # Arrange
    radius = 3.14159
    expected_area = math.pi * radius ** 2

---------------
2025-04-17 12:43:05,962 - INFO - TEST CASE 9 Retry 0 - Result - Passed
2025-04-17 12:43:05,963 - INFO - 
TEST CASE 10 Retry 0
---------------
import math
from theory_evaluation.circle_utils import circle_area, circle_circumference
import pytest



def test_circle_circumference_handles_float_radius():
    # Arrange
    radius = 3.14159
    expected_circumference = 2 * math.pi * radius

---------------
2025-04-17 12:43:07,316 - INFO - TEST CASE 10 Retry 0 - Result - Passed
2025-04-17 12:43:07,317 - INFO - Before Improvement
import math
from theory_evaluation.circle_utils import circle_area, circle_circumference
import pytest


import math
from theory_evaluation.circle_utils import circle_area, circle_circumference
import pytest


def test_circle_area_returns_correct_value_for_positive_radius():
    # Arrange
    radius = 5.0
    expected_area = math.pi * radius ** 2

def test_circle_area_raises_value_error_for_negative_radius():
    # Arrange
    radius = -5.0

def test_circle_area_returns_zero_for_zero_radius():
    # Arrange
    radius = 0.0
    expected_area = 0.0

def test_circle_circumference_returns_correct_value_for_positive_radius():
    # Arrange
    radius = 5.0
    expected_circumference = 2 * math.pi * radius

def test_circle_circumference_raises_value_error_for_negative_radius():
    # Arrange
    radius = -5.0

def test_circle_circumference_returns_zero_for_zero_radius():
    # Arrange
    radius = 0.0
    expected_circumference = 0.0

def test_circle_area_handles_large_radius():
    # Arrange
    radius = 1e6
    expected_area = math.pi * radius ** 2

def test_circle_circumference_handles_large_radius():
    # Arrange
    radius = 1e6
    expected_circumference = 2 * math.pi * radius

def test_circle_area_handles_float_radius():
    # Arrange
    radius = 3.14159
    expected_area = math.pi * radius ** 2

def test_circle_circumference_handles_float_radius():
    # Arrange
    radius = 3.14159
    expected_circumference = 2 * math.pi * radius

2025-04-17 12:43:12,158 - INFO - After Improvement
import math
from theory_evaluation.circle_utils import circle_area, circle_circumference
import pytest


def test_circle_area_returns_correct_value_for_positive_radius():
    # Arrange
    radius = 5.0
    expected_area = math.pi * radius ** 2

def test_circle_area_raises_value_error_for_negative_radius():
    # Arrange
    radius = -5.0

def test_circle_area_returns_zero_for_zero_radius():
    # Arrange
    radius = 0.0
    expected_area = 0.0

def test_circle_circumference_returns_correct_value_for_positive_radius():
    # Arrange
    radius = 5.0
    expected_circumference = 2 * math.pi * radius

def test_circle_circumference_raises_value_error_for_negative_radius():
    # Arrange
    radius = -5.0

def test_circle_circumference_returns_zero_for_zero_radius():
    # Arrange
    radius = 0.0
    expected_circumference = 0.0

def test_circle_area_handles_large_radius():
    # Arrange
    radius = 1e6
    expected_area = math.pi * radius ** 2

def test_circle_circumference_handles_large_radius():
    # Arrange
    radius = 1e6
    expected_circumference = 2 * math.pi * radius

def test_circle_area_handles_float_radius():
    # Arrange
    radius = 3.14159
    expected_area = math.pi * radius ** 2

def test_circle_circumference_handles_float_radius():
    # Arrange
    radius = 3.14159
    expected_circumference = 2 * math.pi * radius
2025-04-17 12:43:13,371 - INFO - Improvement of test cases processed successfully
2025-04-17 12:43:13,371 - INFO - run_each_pytest_function_individually complete
2025-04-17 12:43:13,371 - INFO - End Processing file: theory_evaluation\circle_utils.py

2025-04-17 12:43:13,372 - INFO - 
Start Processing file: theory_evaluation\llm_handler.py
2025-04-17 12:43:13,372 - INFO - Extraction of function and class start
2025-04-17 12:43:13,373 - INFO - extraction of function and class complete
2025-04-17 12:43:13,373 - INFO - Generate Unit Test Case starts
2025-04-17 12:43:13,373 - INFO - Extract unique import start
2025-04-17 12:43:14,250 - INFO - Extract unique import complete
2025-04-17 12:43:14,250 - INFO - Update relative import start
2025-04-17 12:43:14,251 - INFO - Update relative import complete
2025-04-17 12:43:22,814 - INFO - Generate Unit Test Case complete
2025-04-17 12:43:22,818 - INFO - run_each_pytest_function_individually start
2025-04-17 12:43:32,598 - INFO - Number of test case to process - 7
2025-04-17 12:43:32,598 - INFO - 
TEST CASE 1 Retry 0
---------------
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest

There are no `@pytest.fixture` functions in the provided unit test file.

@pytest.mark.asyncio
async def test_OpenAI_llm_initialization_with_defaults():
    message = "Test message"
    llm = OpenAI_llm(message=message)
    assert llm.message == message
    assert llm.image_input is None
    assert llm.azure_endpoint is None
    assert llm.api_version is None
    assert llm.model_name is None
    assert llm.max_retries == 3
    assert llm.output is None
    assert llm.mode == "text_generation"
    assert llm.config == DEFAULT_CONFIG
    assert llm.verbose is False

---------------
2025-04-17 12:43:33,942 - INFO - TEST CASE 1 Retry 0 - Result - Failed
2025-04-17 12:43:33,942 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
.venv\Lib\site-packages\_pytest\python.py:493: in importtestmodule
    mod = import_path(
.venv\Lib\site-packages\_pytest\pathlib.py:587: in import_path
    importlib.import_module(module_name)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1387: in _gcd_import
    ???
<frozen importlib._bootstrap>:1360: in _find_and_load
    ???
<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:935: in _load_unlocked
    ???
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:176: in exec_module
    source_stat, co = _rewrite_test(fn, self.config)
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:356: in _rewrite_test
    tree = ast.parse(source, filename=strfn)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\ast.py:54: in parse
    return compile(source, filename, mode, flags,
E     File "C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py", line 9
E       There are no `@pytest.fixture` functions in the provided unit test file.
E             ^^^
E   SyntaxError: invalid syntax
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 0.33s
2025-04-17 12:43:36,310 - INFO - 
TEST CASE 1 Retry 1
---------------
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest

There are no `@pytest.fixture` functions in the provided unit test file.

from llm_handler import OpenAI_llm, DEFAULT_CONFIG
import pytest

@pytest.mark.asyncio
async def test_OpenAI_llm_initialization_with_defaults():
    message = "Test message"
    llm = OpenAI_llm(message=message)
    assert llm.message == message
    assert llm.image_input is None
    assert llm.azure_endpoint is None
    assert llm.api_version is None
    assert llm.model_name is None
    assert llm.max_retries == 3
    assert llm.output is None
    assert llm.mode == "text_generation"
    assert llm.config == DEFAULT_CONFIG
    assert llm.verbose is False

---------------
2025-04-17 12:43:37,721 - INFO - TEST CASE 1 Retry 1 - Result - Failed
2025-04-17 12:43:37,722 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
.venv\Lib\site-packages\_pytest\python.py:493: in importtestmodule
    mod = import_path(
.venv\Lib\site-packages\_pytest\pathlib.py:587: in import_path
    importlib.import_module(module_name)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1387: in _gcd_import
    ???
<frozen importlib._bootstrap>:1360: in _find_and_load
    ???
<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:935: in _load_unlocked
    ???
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:176: in exec_module
    source_stat, co = _rewrite_test(fn, self.config)
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:356: in _rewrite_test
    tree = ast.parse(source, filename=strfn)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\ast.py:54: in parse
    return compile(source, filename, mode, flags,
E     File "C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py", line 9
E       There are no `@pytest.fixture` functions in the provided unit test file.
E             ^^^
E   SyntaxError: invalid syntax
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 0.30s
2025-04-17 12:43:39,409 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-17 12:43:39,409 - INFO - 
TEST CASE 1 Retry 2
---------------
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest

There are no `@pytest.fixture` functions in the provided unit test file.

from llm_handler import OpenAI_llm, DEFAULT_CONFIG
import pytest

@pytest.mark.asyncio
async def test_OpenAI_llm_initialization_with_defaults():
    message = "Test message"
    llm = OpenAI_llm(message=message)
    assert llm.message == message
    assert llm.image_input is None
    assert llm.azure_endpoint is None
    assert llm.api_version is None
    assert llm.model_name is None
    assert llm.max_retries == 3
    assert llm.output is None
    assert llm.mode == "text_generation"
    assert llm.config == DEFAULT_CONFIG
    assert llm.verbose is False

---------------
2025-04-17 12:43:40,935 - INFO - TEST CASE 1 Retry 2 - Result - Failed
2025-04-17 12:43:40,935 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
.venv\Lib\site-packages\_pytest\python.py:493: in importtestmodule
    mod = import_path(
.venv\Lib\site-packages\_pytest\pathlib.py:587: in import_path
    importlib.import_module(module_name)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1387: in _gcd_import
    ???
<frozen importlib._bootstrap>:1360: in _find_and_load
    ???
<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:935: in _load_unlocked
    ???
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:176: in exec_module
    source_stat, co = _rewrite_test(fn, self.config)
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:356: in _rewrite_test
    tree = ast.parse(source, filename=strfn)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\ast.py:54: in parse
    return compile(source, filename, mode, flags,
E     File "C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py", line 9
E       There are no `@pytest.fixture` functions in the provided unit test file.
E             ^^^
E   SyntaxError: invalid syntax
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 0.26s
2025-04-17 12:43:42,967 - INFO - Failed after all retries for test case 1
2025-04-17 12:43:42,968 - INFO - 
TEST CASE 2 Retry 0
---------------
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest

There are no `@pytest.fixture` functions in the provided unit test file.

@pytest.mark.asyncio
async def test_OpenAI_llm_initialization_with_invalid_message():
    with pytest.raises(AssertionError, match="Prompt message must be inserted."):
        OpenAI_llm(message="")

---------------
2025-04-17 12:43:44,386 - INFO - TEST CASE 2 Retry 0 - Result - Failed
2025-04-17 12:43:44,386 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
.venv\Lib\site-packages\_pytest\python.py:493: in importtestmodule
    mod = import_path(
.venv\Lib\site-packages\_pytest\pathlib.py:587: in import_path
    importlib.import_module(module_name)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1387: in _gcd_import
    ???
<frozen importlib._bootstrap>:1360: in _find_and_load
    ???
<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:935: in _load_unlocked
    ???
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:176: in exec_module
    source_stat, co = _rewrite_test(fn, self.config)
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:356: in _rewrite_test
    tree = ast.parse(source, filename=strfn)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\ast.py:54: in parse
    return compile(source, filename, mode, flags,
E     File "C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py", line 9
E       There are no `@pytest.fixture` functions in the provided unit test file.
E             ^^^
E   SyntaxError: invalid syntax
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 0.29s
2025-04-17 12:43:45,524 - INFO - 
TEST CASE 2 Retry 1
---------------
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest

There are no `@pytest.fixture` functions in the provided unit test file.

import pytest
from llm_handler import OpenAI_llm

@pytest.mark.asyncio
async def test_OpenAI_llm_initialization_with_invalid_message():
    with pytest.raises(AssertionError, match="Prompt message must be inserted."):
        OpenAI_llm(message="")

---------------
2025-04-17 12:43:47,076 - INFO - TEST CASE 2 Retry 1 - Result - Failed
2025-04-17 12:43:47,076 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
.venv\Lib\site-packages\_pytest\python.py:493: in importtestmodule
    mod = import_path(
.venv\Lib\site-packages\_pytest\pathlib.py:587: in import_path
    importlib.import_module(module_name)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1387: in _gcd_import
    ???
<frozen importlib._bootstrap>:1360: in _find_and_load
    ???
<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:935: in _load_unlocked
    ???
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:176: in exec_module
    source_stat, co = _rewrite_test(fn, self.config)
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:356: in _rewrite_test
    tree = ast.parse(source, filename=strfn)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\ast.py:54: in parse
    return compile(source, filename, mode, flags,
E     File "C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py", line 9
E       There are no `@pytest.fixture` functions in the provided unit test file.
E             ^^^
E   SyntaxError: invalid syntax
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 0.29s
2025-04-17 12:43:48,287 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-17 12:43:48,288 - INFO - 
TEST CASE 2 Retry 2
---------------
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest

There are no `@pytest.fixture` functions in the provided unit test file.

import pytest
from llm_handler import OpenAI_llm

@pytest.mark.asyncio
async def test_OpenAI_llm_initialization_with_invalid_message():
    with pytest.raises(AssertionError, match="Prompt message must be inserted."):
        OpenAI_llm(message=None)

---------------
2025-04-17 12:43:49,768 - INFO - TEST CASE 2 Retry 2 - Result - Failed
2025-04-17 12:43:49,769 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
.venv\Lib\site-packages\_pytest\python.py:493: in importtestmodule
    mod = import_path(
.venv\Lib\site-packages\_pytest\pathlib.py:587: in import_path
    importlib.import_module(module_name)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1387: in _gcd_import
    ???
<frozen importlib._bootstrap>:1360: in _find_and_load
    ???
<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:935: in _load_unlocked
    ???
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:176: in exec_module
    source_stat, co = _rewrite_test(fn, self.config)
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:356: in _rewrite_test
    tree = ast.parse(source, filename=strfn)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\ast.py:54: in parse
    return compile(source, filename, mode, flags,
E     File "C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py", line 9
E       There are no `@pytest.fixture` functions in the provided unit test file.
E             ^^^
E   SyntaxError: invalid syntax
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 0.34s
2025-04-17 12:43:50,709 - INFO - Failed after all retries for test case 2
2025-04-17 12:43:50,710 - INFO - 
TEST CASE 3 Retry 0
---------------
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest

There are no `@pytest.fixture` functions in the provided unit test file.

@pytest.mark.asyncio
async def test_OpenAI_llm_initialization_with_invalid_output():
    with pytest.raises(AssertionError, match="Output must be either 'json', 'stream', or None"):
        OpenAI_llm(message="Test message", output="invalid_output")

---------------
2025-04-17 12:43:52,080 - INFO - TEST CASE 3 Retry 0 - Result - Failed
2025-04-17 12:43:52,080 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
.venv\Lib\site-packages\_pytest\python.py:493: in importtestmodule
    mod = import_path(
.venv\Lib\site-packages\_pytest\pathlib.py:587: in import_path
    importlib.import_module(module_name)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1387: in _gcd_import
    ???
<frozen importlib._bootstrap>:1360: in _find_and_load
    ???
<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:935: in _load_unlocked
    ???
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:176: in exec_module
    source_stat, co = _rewrite_test(fn, self.config)
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:356: in _rewrite_test
    tree = ast.parse(source, filename=strfn)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\ast.py:54: in parse
    return compile(source, filename, mode, flags,
E     File "C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py", line 9
E       There are no `@pytest.fixture` functions in the provided unit test file.
E             ^^^
E   SyntaxError: invalid syntax
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 0.24s
2025-04-17 12:43:53,626 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-17 12:43:53,627 - INFO - 
TEST CASE 3 Retry 1
---------------
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest

There are no `@pytest.fixture` functions in the provided unit test file.

import pytest
from llm_handler import OpenAI_llm

@pytest.mark.asyncio
async def test_OpenAI_llm_initialization_with_invalid_output():
    with pytest.raises(AssertionError, match="Output must be either 'json', 'stream', or None"):
        OpenAI_llm(message="Test message", output="invalid_output")

---------------
2025-04-17 12:43:54,930 - INFO - TEST CASE 3 Retry 1 - Result - Failed
2025-04-17 12:43:54,930 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
.venv\Lib\site-packages\_pytest\python.py:493: in importtestmodule
    mod = import_path(
.venv\Lib\site-packages\_pytest\pathlib.py:587: in import_path
    importlib.import_module(module_name)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1387: in _gcd_import
    ???
<frozen importlib._bootstrap>:1360: in _find_and_load
    ???
<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:935: in _load_unlocked
    ???
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:176: in exec_module
    source_stat, co = _rewrite_test(fn, self.config)
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:356: in _rewrite_test
    tree = ast.parse(source, filename=strfn)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\ast.py:54: in parse
    return compile(source, filename, mode, flags,
E     File "C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py", line 9
E       There are no `@pytest.fixture` functions in the provided unit test file.
E             ^^^
E   SyntaxError: invalid syntax
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 0.25s
2025-04-17 12:43:55,848 - INFO - 
TEST CASE 3 Retry 2
---------------
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest

There are no `@pytest.fixture` functions in the provided unit test file.

import pytest
from llm_handler import OpenAI_llm

@pytest.mark.asyncio
async def test_OpenAI_llm_initialization_with_invalid_output():
    with pytest.raises(AssertionError, match="Output must be either 'json', 'stream', or None"):
        OpenAI_llm(message="Test message", output="invalid_output")

---------------
2025-04-17 12:43:57,292 - INFO - TEST CASE 3 Retry 2 - Result - Failed
2025-04-17 12:43:57,292 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
.venv\Lib\site-packages\_pytest\python.py:493: in importtestmodule
    mod = import_path(
.venv\Lib\site-packages\_pytest\pathlib.py:587: in import_path
    importlib.import_module(module_name)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1387: in _gcd_import
    ???
<frozen importlib._bootstrap>:1360: in _find_and_load
    ???
<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:935: in _load_unlocked
    ???
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:176: in exec_module
    source_stat, co = _rewrite_test(fn, self.config)
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:356: in _rewrite_test
    tree = ast.parse(source, filename=strfn)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\ast.py:54: in parse
    return compile(source, filename, mode, flags,
E     File "C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py", line 9
E       There are no `@pytest.fixture` functions in the provided unit test file.
E             ^^^
E   SyntaxError: invalid syntax
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 0.32s
2025-04-17 12:43:59,509 - INFO - Failed after all retries for test case 3
2025-04-17 12:43:59,510 - INFO - 
TEST CASE 4 Retry 0
---------------
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest

There are no `@pytest.fixture` functions in the provided unit test file.

@pytest.mark.asyncio
async def test_OpenAI_llm_initialization_with_invalid_mode():
    with pytest.raises(AssertionError, match="mode must be either 'text_generation' or 'vision'"):
        OpenAI_llm(message="Test message", mode="invalid_mode")

---------------
2025-04-17 12:44:01,189 - INFO - TEST CASE 4 Retry 0 - Result - Failed
2025-04-17 12:44:01,189 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
.venv\Lib\site-packages\_pytest\python.py:493: in importtestmodule
    mod = import_path(
.venv\Lib\site-packages\_pytest\pathlib.py:587: in import_path
    importlib.import_module(module_name)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1387: in _gcd_import
    ???
<frozen importlib._bootstrap>:1360: in _find_and_load
    ???
<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:935: in _load_unlocked
    ???
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:176: in exec_module
    source_stat, co = _rewrite_test(fn, self.config)
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:356: in _rewrite_test
    tree = ast.parse(source, filename=strfn)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\ast.py:54: in parse
    return compile(source, filename, mode, flags,
E     File "C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py", line 9
E       There are no `@pytest.fixture` functions in the provided unit test file.
E             ^^^
E   SyntaxError: invalid syntax
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 0.34s
2025-04-17 12:44:02,388 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-17 12:44:02,389 - INFO - 
TEST CASE 4 Retry 1
---------------
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest

There are no `@pytest.fixture` functions in the provided unit test file.

import pytest
from llm_handler import OpenAI_llm

@pytest.mark.asyncio
async def test_OpenAI_llm_initialization_with_invalid_mode():
    with pytest.raises(AssertionError, match="mode must be either 'text_generation' or 'vision'"):
        OpenAI_llm(message="Test message", mode="invalid_mode")

---------------
2025-04-17 12:44:03,692 - INFO - TEST CASE 4 Retry 1 - Result - Failed
2025-04-17 12:44:03,692 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
.venv\Lib\site-packages\_pytest\python.py:493: in importtestmodule
    mod = import_path(
.venv\Lib\site-packages\_pytest\pathlib.py:587: in import_path
    importlib.import_module(module_name)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1387: in _gcd_import
    ???
<frozen importlib._bootstrap>:1360: in _find_and_load
    ???
<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:935: in _load_unlocked
    ???
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:176: in exec_module
    source_stat, co = _rewrite_test(fn, self.config)
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:356: in _rewrite_test
    tree = ast.parse(source, filename=strfn)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\ast.py:54: in parse
    return compile(source, filename, mode, flags,
E     File "C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py", line 9
E       There are no `@pytest.fixture` functions in the provided unit test file.
E             ^^^
E   SyntaxError: invalid syntax
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 0.34s
2025-04-17 12:44:05,177 - INFO - 
TEST CASE 4 Retry 2
---------------
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest

There are no `@pytest.fixture` functions in the provided unit test file.

import pytest
from llm_handler import OpenAI_llm

@pytest.mark.asyncio
async def test_OpenAI_llm_initialization_with_invalid_mode():
    with pytest.raises(AssertionError, match="mode must be either 'text_generation' or 'vision'"):
        OpenAI_llm(message="Test message", mode="invalid_mode")

---------------
2025-04-17 12:44:06,446 - INFO - TEST CASE 4 Retry 2 - Result - Failed
2025-04-17 12:44:06,447 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
.venv\Lib\site-packages\_pytest\python.py:493: in importtestmodule
    mod = import_path(
.venv\Lib\site-packages\_pytest\pathlib.py:587: in import_path
    importlib.import_module(module_name)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1387: in _gcd_import
    ???
<frozen importlib._bootstrap>:1360: in _find_and_load
    ???
<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:935: in _load_unlocked
    ???
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:176: in exec_module
    source_stat, co = _rewrite_test(fn, self.config)
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:356: in _rewrite_test
    tree = ast.parse(source, filename=strfn)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\ast.py:54: in parse
    return compile(source, filename, mode, flags,
E     File "C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py", line 9
E       There are no `@pytest.fixture` functions in the provided unit test file.
E             ^^^
E   SyntaxError: invalid syntax
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 0.24s
2025-04-17 12:44:07,682 - INFO - Failed after all retries for test case 4
2025-04-17 12:44:07,682 - INFO - 
TEST CASE 5 Retry 0
---------------
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest

There are no `@pytest.fixture` functions in the provided unit test file.

@pytest.mark.asyncio
async def test_execute_text_generation_mode():
    message = "Test message"
    llm = OpenAI_llm(message=message, mode="text_generation")
    with patch.object(llm, '_run', new_callable=AsyncMock) as mock_run:
        mock_run.return_value = AsyncMock()
        mock_run.return_value.__aiter__.return_value = ["response"]
        responses = []
        async for response in llm.execute():
            responses.append(response)
        assert responses == ["response"]
        mock_run.assert_called_once_with(messages=[{"role": "system", "content": message}], model=None, **DEFAULT_CONFIG)

---------------
2025-04-17 12:44:09,001 - INFO - TEST CASE 5 Retry 0 - Result - Failed
2025-04-17 12:44:09,002 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
.venv\Lib\site-packages\_pytest\python.py:493: in importtestmodule
    mod = import_path(
.venv\Lib\site-packages\_pytest\pathlib.py:587: in import_path
    importlib.import_module(module_name)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1387: in _gcd_import
    ???
<frozen importlib._bootstrap>:1360: in _find_and_load
    ???
<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:935: in _load_unlocked
    ???
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:176: in exec_module
    source_stat, co = _rewrite_test(fn, self.config)
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:356: in _rewrite_test
    tree = ast.parse(source, filename=strfn)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\ast.py:54: in parse
    return compile(source, filename, mode, flags,
E     File "C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py", line 9
E       There are no `@pytest.fixture` functions in the provided unit test file.
E             ^^^
E   SyntaxError: invalid syntax
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 0.28s
2025-04-17 12:44:10,942 - INFO - 
TEST CASE 5 Retry 1
---------------
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest

There are no `@pytest.fixture` functions in the provided unit test file.

from unittest.mock import patch, AsyncMock
import pytest
from llm_handler import OpenAI_llm, DEFAULT_CONFIG

@pytest.mark.asyncio
async def test_execute_text_generation_mode():
    message = "Test message"
    llm = OpenAI_llm(message=message, mode="text_generation")
    with patch.object(llm, '_run', new_callable=AsyncMock) as mock_run:
        mock_run.return_value.__aiter__.return_value = ["response"]
        responses = []
        async for response in llm.execute():
            responses.append(response)
        assert responses == ["response"]
        mock_run.assert_called_once_with(messages=[{"role": "system", "content": message}], model=None, **DEFAULT_CONFIG)

---------------
2025-04-17 12:44:12,452 - INFO - TEST CASE 5 Retry 1 - Result - Failed
2025-04-17 12:44:12,452 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
.venv\Lib\site-packages\_pytest\python.py:493: in importtestmodule
    mod = import_path(
.venv\Lib\site-packages\_pytest\pathlib.py:587: in import_path
    importlib.import_module(module_name)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1387: in _gcd_import
    ???
<frozen importlib._bootstrap>:1360: in _find_and_load
    ???
<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:935: in _load_unlocked
    ???
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:176: in exec_module
    source_stat, co = _rewrite_test(fn, self.config)
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:356: in _rewrite_test
    tree = ast.parse(source, filename=strfn)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\ast.py:54: in parse
    return compile(source, filename, mode, flags,
E     File "C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py", line 9
E       There are no `@pytest.fixture` functions in the provided unit test file.
E             ^^^
E   SyntaxError: invalid syntax
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 0.30s
2025-04-17 12:44:14,554 - INFO - 
TEST CASE 5 Retry 2
---------------
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest

There are no `@pytest.fixture` functions in the provided unit test file.

from unittest.mock import patch, AsyncMock
import pytest
from llm_handler import OpenAI_llm, DEFAULT_CONFIG

@pytest.mark.asyncio
async def test_execute_text_generation_mode():
    message = "Test message"
    llm = OpenAI_llm(message=message, mode="text_generation")
    with patch.object(llm, '_run', new_callable=AsyncMock) as mock_run:
        mock_run.return_value.__aiter__.return_value = ["response"]
        responses = []
        async for response in llm.execute():
            responses.append(response)
        assert responses == ["response"]
        mock_run.assert_called_once_with(messages=[{"role": "system", "content": message}], model=llm.model_name, **DEFAULT_CONFIG)

---------------
2025-04-17 12:44:15,838 - INFO - TEST CASE 5 Retry 2 - Result - Failed
2025-04-17 12:44:15,838 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
.venv\Lib\site-packages\_pytest\python.py:493: in importtestmodule
    mod = import_path(
.venv\Lib\site-packages\_pytest\pathlib.py:587: in import_path
    importlib.import_module(module_name)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1387: in _gcd_import
    ???
<frozen importlib._bootstrap>:1360: in _find_and_load
    ???
<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:935: in _load_unlocked
    ???
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:176: in exec_module
    source_stat, co = _rewrite_test(fn, self.config)
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:356: in _rewrite_test
    tree = ast.parse(source, filename=strfn)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\ast.py:54: in parse
    return compile(source, filename, mode, flags,
E     File "C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py", line 9
E       There are no `@pytest.fixture` functions in the provided unit test file.
E             ^^^
E   SyntaxError: invalid syntax
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 0.24s
2025-04-17 12:44:17,852 - INFO - Failed after all retries for test case 5
2025-04-17 12:44:17,853 - INFO - 
TEST CASE 6 Retry 0
---------------
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest

There are no `@pytest.fixture` functions in the provided unit test file.

@pytest.mark.asyncio
async def test_execute_vision_mode():
    message = "Test message"
    image_input = "base64image"
    llm = OpenAI_llm(message=message, mode="vision", image_input=image_input)
    with patch.object(llm, '_run', new_callable=AsyncMock) as mock_run:
        mock_run.return_value = AsyncMock()
        mock_run.return_value.__aiter__.return_value = ["response"]
        responses = []
        async for response in llm.execute():
            responses.append(response)
        assert responses == ["response"]
        expected_messages = [
            {"role": "system", "content": message},
            {"role": "user", "content": "Help me with the task regarding the image given."},
            {"role": "user", "content": [{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_input}", "detail": "high"}}]}
        ]
        mock_run.assert_called_once_with(messages=expected_messages, model=None, **DEFAULT_CONFIG)

---------------
2025-04-17 12:44:19,106 - INFO - TEST CASE 6 Retry 0 - Result - Failed
2025-04-17 12:44:19,106 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
.venv\Lib\site-packages\_pytest\python.py:493: in importtestmodule
    mod = import_path(
.venv\Lib\site-packages\_pytest\pathlib.py:587: in import_path
    importlib.import_module(module_name)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1387: in _gcd_import
    ???
<frozen importlib._bootstrap>:1360: in _find_and_load
    ???
<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:935: in _load_unlocked
    ???
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:176: in exec_module
    source_stat, co = _rewrite_test(fn, self.config)
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:356: in _rewrite_test
    tree = ast.parse(source, filename=strfn)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\ast.py:54: in parse
    return compile(source, filename, mode, flags,
E     File "C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py", line 9
E       There are no `@pytest.fixture` functions in the provided unit test file.
E             ^^^
E   SyntaxError: invalid syntax
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 0.28s
2025-04-17 12:44:22,221 - INFO - 
TEST CASE 6 Retry 1
---------------
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest

There are no `@pytest.fixture` functions in the provided unit test file.

from unittest.mock import patch, AsyncMock
import pytest
from llm_handler import OpenAI_llm, DEFAULT_CONFIG

@pytest.mark.asyncio
async def test_execute_vision_mode():
    message = "Test message"
    image_input = "base64image"
    llm = OpenAI_llm(message=message, mode="vision", image_input=image_input)
    with patch.object(llm, '_run', new_callable=AsyncMock) as mock_run:
        mock_run.return_value = AsyncMock()
        mock_run.return_value.__aiter__.return_value = ["response"]
        responses = []
        async for response in llm.execute():
            responses.append(response)
        assert responses == ["response"]
        expected_messages = [
            {"role": "system", "content": message},
            {"role": "user", "content": "Help me with the task regarding the image given."},
            {"role": "user", "content": [{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_input}", "detail": "high"}}]}
        ]
        mock_run.assert_called_once_with(messages=expected_messages, model=None, **DEFAULT_CONFIG)

---------------
2025-04-17 12:44:23,523 - INFO - TEST CASE 6 Retry 1 - Result - Failed
2025-04-17 12:44:23,524 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
.venv\Lib\site-packages\_pytest\python.py:493: in importtestmodule
    mod = import_path(
.venv\Lib\site-packages\_pytest\pathlib.py:587: in import_path
    importlib.import_module(module_name)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1387: in _gcd_import
    ???
<frozen importlib._bootstrap>:1360: in _find_and_load
    ???
<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:935: in _load_unlocked
    ???
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:176: in exec_module
    source_stat, co = _rewrite_test(fn, self.config)
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:356: in _rewrite_test
    tree = ast.parse(source, filename=strfn)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\ast.py:54: in parse
    return compile(source, filename, mode, flags,
E     File "C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py", line 9
E       There are no `@pytest.fixture` functions in the provided unit test file.
E             ^^^
E   SyntaxError: invalid syntax
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 0.25s
2025-04-17 12:44:27,297 - INFO - 
TEST CASE 6 Retry 2
---------------
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest

There are no `@pytest.fixture` functions in the provided unit test file.

from unittest.mock import patch, AsyncMock
import pytest
from llm_handler import OpenAI_llm, DEFAULT_CONFIG

@pytest.mark.asyncio
async def test_execute_vision_mode():
    message = "Test message"
    image_input = "base64image"
    llm = OpenAI_llm(message=message, mode="vision", image_input=image_input)
    with patch.object(llm, '_run', new_callable=AsyncMock) as mock_run:
        mock_run.return_value.__aiter__.return_value = ["response"]
        responses = []
        async for response in llm.execute():
            responses.append(response)
        assert responses == ["response"]
        expected_messages = [
            {"role": "system", "content": message},
            {"role": "user", "content": "Help me with the task regarding the image given."},
            {"role": "user", "content": [{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_input}", "detail": "high"}}]}
        ]
        mock_run.assert_called_once_with(messages=expected_messages, model=None, **DEFAULT_CONFIG)

---------------
2025-04-17 12:44:29,316 - INFO - TEST CASE 6 Retry 2 - Result - Failed
2025-04-17 12:44:29,316 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
.venv\Lib\site-packages\_pytest\python.py:493: in importtestmodule
    mod = import_path(
.venv\Lib\site-packages\_pytest\pathlib.py:587: in import_path
    importlib.import_module(module_name)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1387: in _gcd_import
    ???
<frozen importlib._bootstrap>:1360: in _find_and_load
    ???
<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:935: in _load_unlocked
    ???
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:176: in exec_module
    source_stat, co = _rewrite_test(fn, self.config)
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:356: in _rewrite_test
    tree = ast.parse(source, filename=strfn)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\ast.py:54: in parse
    return compile(source, filename, mode, flags,
E     File "C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py", line 9
E       There are no `@pytest.fixture` functions in the provided unit test file.
E             ^^^
E   SyntaxError: invalid syntax
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 0.34s
2025-04-17 12:44:32,078 - INFO - Failed after all retries for test case 6
2025-04-17 12:44:32,079 - INFO - 
TEST CASE 7 Retry 0
---------------
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest

There are no `@pytest.fixture` functions in the provided unit test file.

@pytest.mark.asyncio
async def test_execute_with_exception():
    message = "Test message"
    llm = OpenAI_llm(message=message)
    with patch.object(llm, '_run', new_callable=AsyncMock) as mock_run:
        mock_run.side_effect = Exception("Test exception")
        responses = []
        async for response in llm.execute():
            responses.append(response)
        assert responses == ["Error: Test exception"]

---------------
2025-04-17 12:44:33,296 - INFO - TEST CASE 7 Retry 0 - Result - Failed
2025-04-17 12:44:33,297 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
.venv\Lib\site-packages\_pytest\python.py:493: in importtestmodule
    mod = import_path(
.venv\Lib\site-packages\_pytest\pathlib.py:587: in import_path
    importlib.import_module(module_name)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1387: in _gcd_import
    ???
<frozen importlib._bootstrap>:1360: in _find_and_load
    ???
<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:935: in _load_unlocked
    ???
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:176: in exec_module
    source_stat, co = _rewrite_test(fn, self.config)
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:356: in _rewrite_test
    tree = ast.parse(source, filename=strfn)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\ast.py:54: in parse
    return compile(source, filename, mode, flags,
E     File "C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py", line 9
E       There are no `@pytest.fixture` functions in the provided unit test file.
E             ^^^
E   SyntaxError: invalid syntax
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 0.26s
2025-04-17 12:44:34,662 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-17 12:44:34,663 - INFO - 
TEST CASE 7 Retry 1
---------------
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest

There are no `@pytest.fixture` functions in the provided unit test file.

import pytest
from unittest.mock import patch, AsyncMock
from llm_handler import OpenAI_llm

@pytest.mark.asyncio
async def test_execute_with_exception():
    message = "Test message"
    llm = OpenAI_llm(message=message)
    with patch.object(llm, '_run', new_callable=AsyncMock) as mock_run:
        mock_run.side_effect = Exception("Test exception")
        responses = []
        async for response in llm.execute():
            responses.append(response)
        assert responses == ["Error: Test exception"]

---------------
2025-04-17 12:44:35,956 - INFO - TEST CASE 7 Retry 1 - Result - Failed
2025-04-17 12:44:35,957 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
.venv\Lib\site-packages\_pytest\python.py:493: in importtestmodule
    mod = import_path(
.venv\Lib\site-packages\_pytest\pathlib.py:587: in import_path
    importlib.import_module(module_name)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1387: in _gcd_import
    ???
<frozen importlib._bootstrap>:1360: in _find_and_load
    ???
<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:935: in _load_unlocked
    ???
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:176: in exec_module
    source_stat, co = _rewrite_test(fn, self.config)
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:356: in _rewrite_test
    tree = ast.parse(source, filename=strfn)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\ast.py:54: in parse
    return compile(source, filename, mode, flags,
E     File "C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py", line 9
E       There are no `@pytest.fixture` functions in the provided unit test file.
E             ^^^
E   SyntaxError: invalid syntax
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 0.34s
2025-04-17 12:44:37,740 - INFO - 
TEST CASE 7 Retry 2
---------------
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest

There are no `@pytest.fixture` functions in the provided unit test file.

import pytest
from unittest.mock import patch, AsyncMock
from llm_handler import OpenAI_llm

@pytest.mark.asyncio
async def test_execute_with_exception():
    message = "Test message"
    llm = OpenAI_llm(message=message)
    with patch.object(llm, '_run', new_callable=AsyncMock) as mock_run:
        mock_run.side_effect = Exception("Test exception")
        responses = []
        async for response in llm.execute():
            responses.append(response)
        assert responses == ["Error: Test exception"]

---------------
2025-04-17 12:44:38,948 - INFO - TEST CASE 7 Retry 2 - Result - Failed
2025-04-17 12:44:38,948 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
.venv\Lib\site-packages\_pytest\python.py:493: in importtestmodule
    mod = import_path(
.venv\Lib\site-packages\_pytest\pathlib.py:587: in import_path
    importlib.import_module(module_name)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1387: in _gcd_import
    ???
<frozen importlib._bootstrap>:1360: in _find_and_load
    ???
<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:935: in _load_unlocked
    ???
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:176: in exec_module
    source_stat, co = _rewrite_test(fn, self.config)
.venv\Lib\site-packages\_pytest\assertion\rewrite.py:356: in _rewrite_test
    tree = ast.parse(source, filename=strfn)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\ast.py:54: in parse
    return compile(source, filename, mode, flags,
E     File "C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py", line 9
E       There are no `@pytest.fixture` functions in the provided unit test file.
E             ^^^
E   SyntaxError: invalid syntax
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 0.27s
2025-04-17 12:44:40,668 - INFO - Failed after all retries for test case 7
2025-04-17 12:44:40,668 - INFO - Before Improvement
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest

There are no `@pytest.fixture` functions in the provided unit test file.
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest

There are no `@pytest.fixture` functions in the provided unit test file.
2025-04-17 12:44:41,579 - INFO - After Improvement
import asyncio
import json
import os
from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest
2025-04-17 12:44:44,714 - INFO - Error in generating improved test cases
Test case:
import asyncio
import json
import os
from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import OpenAI_llm
import pytest
Test error:
c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

no tests ran in 1.81s
2025-04-17 12:44:44,715 - INFO - run_each_pytest_function_individually complete
2025-04-17 12:44:44,715 - ERROR - Failed processing theory_evaluation\llm_handler.py: 'str' object has no attribute 'relative_to'
2025-04-17 12:44:44,716 - INFO - End Processing file: theory_evaluation\llm_handler.py

2025-04-17 12:44:44,716 - INFO - 
Start Processing file: theory_evaluation\llm_utils.py
2025-04-17 12:44:44,717 - INFO - Extraction of function and class start
2025-04-17 12:44:44,718 - INFO - extraction of function and class complete
2025-04-17 12:44:44,718 - INFO - Generate Unit Test Case starts
2025-04-17 12:44:44,718 - INFO - Extract unique import start
2025-04-17 12:44:45,373 - INFO - Extract unique import complete
2025-04-17 12:44:45,374 - INFO - Update relative import start
2025-04-17 12:44:45,374 - INFO - Update relative import complete
2025-04-17 12:44:52,691 - INFO - Generate Unit Test Case complete
2025-04-17 12:44:52,696 - INFO - run_each_pytest_function_individually start
2025-04-17 12:45:00,117 - INFO - Number of test case to process - 5
2025-04-17 12:45:00,118 - INFO - 
TEST CASE 1 Retry 0
---------------
import os
import re
import yaml
from theory_evaluation.llm_utils import initialise_prompt, initialise_settings
import pytest



def test_initialise_prompt_returns_correct_prompt_structure():
    agent = "test_agent"
    config_path = "./theory_evaluation/evaluator/prompts"
    config_yaml_content = "key1: value1\nkey2: value2"
    prompt_txt_content = "This is a prompt with {$key1} and {$key2}."
    expected_prompt = "This is a prompt with value1 and value2."

---------------
2025-04-17 12:45:02,327 - INFO - TEST CASE 1 Retry 0 - Result - Passed
2025-04-17 12:45:02,327 - INFO - 
TEST CASE 2 Retry 0
---------------
import os
import re
import yaml
from theory_evaluation.llm_utils import initialise_prompt, initialise_settings
import pytest



def test_initialise_prompt_raises_exception_for_missing_config():
    agent = "missing_agent"
    config_path = "./theory_evaluation/evaluator/prompts"

---------------
2025-04-17 12:45:03,736 - INFO - TEST CASE 2 Retry 0 - Result - Passed
2025-04-17 12:45:03,736 - INFO - 
TEST CASE 3 Retry 0
---------------
import os
import re
import yaml
from theory_evaluation.llm_utils import initialise_prompt, initialise_settings
import pytest



def test_initialise_prompt_handles_missing_placeholder():
    agent = "test_agent"
    config_path = "./theory_evaluation/evaluator/prompts"
    config_yaml_content = "key1: value1"
    prompt_txt_content = "This is a prompt with {$key1} and {$key2}."
    expected_prompt = "This is a prompt with value1 and {$key2}."

---------------
2025-04-17 12:45:05,513 - INFO - TEST CASE 3 Retry 0 - Result - Passed
2025-04-17 12:45:05,513 - INFO - 
TEST CASE 4 Retry 0
---------------
import os
import re
import yaml
from theory_evaluation.llm_utils import initialise_prompt, initialise_settings
import pytest



def test_initialise_settings_returns_correct_settings():
    agent = "test_agent"
    config_path = "./theory_evaluation/evaluator/prompts"
    settings_yaml_content = "setting1: value1\nsetting2: value2"
    expected_settings = yaml.safe_load(settings_yaml_content)

---------------
2025-04-17 12:45:06,961 - INFO - TEST CASE 4 Retry 0 - Result - Passed
2025-04-17 12:45:06,961 - INFO - 
TEST CASE 5 Retry 0
---------------
import os
import re
import yaml
from theory_evaluation.llm_utils import initialise_prompt, initialise_settings
import pytest



def test_initialise_settings_raises_exception_for_missing_settings():
    agent = "missing_agent"
    config_path = "./theory_evaluation/evaluator/prompts"

---------------
2025-04-17 12:45:09,277 - INFO - TEST CASE 5 Retry 0 - Result - Passed
2025-04-17 12:45:09,278 - INFO - Before Improvement
import os
import re
import yaml
from theory_evaluation.llm_utils import initialise_prompt, initialise_settings
import pytest


import os
import re
import yaml
from theory_evaluation.llm_utils import initialise_prompt, initialise_settings
import pytest


def test_initialise_prompt_returns_correct_prompt_structure():
    agent = "test_agent"
    config_path = "./theory_evaluation/evaluator/prompts"
    config_yaml_content = "key1: value1\nkey2: value2"
    prompt_txt_content = "This is a prompt with {$key1} and {$key2}."
    expected_prompt = "This is a prompt with value1 and value2."

def test_initialise_prompt_raises_exception_for_missing_config():
    agent = "missing_agent"
    config_path = "./theory_evaluation/evaluator/prompts"

def test_initialise_prompt_handles_missing_placeholder():
    agent = "test_agent"
    config_path = "./theory_evaluation/evaluator/prompts"
    config_yaml_content = "key1: value1"
    prompt_txt_content = "This is a prompt with {$key1} and {$key2}."
    expected_prompt = "This is a prompt with value1 and {$key2}."

def test_initialise_settings_returns_correct_settings():
    agent = "test_agent"
    config_path = "./theory_evaluation/evaluator/prompts"
    settings_yaml_content = "setting1: value1\nsetting2: value2"
    expected_settings = yaml.safe_load(settings_yaml_content)

def test_initialise_settings_raises_exception_for_missing_settings():
    agent = "missing_agent"
    config_path = "./theory_evaluation/evaluator/prompts"

2025-04-17 12:45:13,563 - INFO - After Improvement
import yaml
from theory_evaluation.llm_utils import initialise_prompt, initialise_settings
import pytest


def test_initialise_prompt_returns_correct_prompt_structure():
    agent = "test_agent"
    config_path = "./theory_evaluation/evaluator/prompts"
    config_yaml_content = "key1: value1\nkey2: value2"
    prompt_txt_content = "This is a prompt with {$key1} and {$key2}."
    expected_prompt = "This is a prompt with value1 and value2."

def test_initialise_prompt_raises_exception_for_missing_config():
    agent = "missing_agent"
    config_path = "./theory_evaluation/evaluator/prompts"

def test_initialise_prompt_handles_missing_placeholder():
    agent = "test_agent"
    config_path = "./theory_evaluation/evaluator/prompts"
    config_yaml_content = "key1: value1"
    prompt_txt_content = "This is a prompt with {$key1} and {$key2}."
    expected_prompt = "This is a prompt with value1 and {$key2}."

def test_initialise_settings_returns_correct_settings():
    agent = "test_agent"
    config_path = "./theory_evaluation/evaluator/prompts"
    settings_yaml_content = "setting1: value1\nsetting2: value2"
    expected_settings = yaml.safe_load(settings_yaml_content)

def test_initialise_settings_raises_exception_for_missing_settings():
    agent = "missing_agent"
    config_path = "./theory_evaluation/evaluator/prompts"
2025-04-17 12:45:14,772 - INFO - Improvement of test cases processed successfully
2025-04-17 12:45:14,773 - INFO - run_each_pytest_function_individually complete
2025-04-17 12:45:14,773 - INFO - End Processing file: theory_evaluation\llm_utils.py

2025-04-17 12:45:14,773 - INFO - 
Start Processing file: theory_evaluation\models.py
2025-04-17 12:45:14,774 - INFO - Extraction of function and class start
2025-04-17 12:45:14,774 - INFO - extraction of function and class complete
2025-04-17 12:45:14,774 - INFO - Generate Unit Test Case starts
2025-04-17 12:45:14,774 - INFO - Extract unique import start
2025-04-17 12:45:15,882 - INFO - Extract unique import complete
2025-04-17 12:45:15,882 - INFO - Update relative import start
2025-04-17 12:45:15,884 - INFO - Update relative import complete
2025-04-17 12:45:26,913 - INFO - Generate Unit Test Case complete
2025-04-17 12:45:26,918 - INFO - run_each_pytest_function_individually start
2025-04-17 12:45:40,394 - INFO - Number of test case to process - 8
2025-04-17 12:45:40,395 - INFO - 
TEST CASE 1 Retry 0
---------------
from sqlalchemy.dialects.postgresql import JSONB, UUID
from sqlalchemy import (
    Column,
    Integer,
    String,
    TIMESTAMP,
    create_engine,
    Float,
    ForeignKey,
    Text,
    UniqueConstraint,
)
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.sql import func
import uuid
from theory_evaluation.models import ConsultantChat, CurrentUserTable, Curriculum, MentorChat, Projects, SprintIssues, TheoryEvalUserPerformance, UserInfo, UserRepo, UserScoreLog
import pytest

@pytest.fixture(scope='module')
def test_engine():
    engine = create_engine('sqlite:///:memory:', echo=True)
    Base.metadata.create_all(engine)
    return engine

@pytest.fixture(scope='function')
def session(test_engine):
    Session = sessionmaker(bind=test_engine)
    session = Session()
    yield session
    session.close()

def test_user_info_creation(session):
    user_info = UserInfo(
        first_name="John",
        last_name="Doe",
        email="john.doe@example.com",
        github_username="johndoe",
        payment_date=None,
        current_duration=0,
        course_duration=0,
        end_date=None,
        status=1
    )
    session.add(user_info)
    session.commit()
    retrieved_user = session.query(UserInfo).filter_by(email="john.doe@example.com").first()
    assert retrieved_user is not None
    assert retrieved_user.first_name == "John"
    assert retrieved_user.last_name == "Doe"

---------------
2025-04-17 12:45:42,445 - INFO - TEST CASE 1 Retry 0 - Result - Failed
2025-04-17 12:45:42,446 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
E                                                                        [100%]
=================================== ERRORS ====================================
__________________ ERROR at setup of test_user_info_creation __________________
temp\temp.py:22: in test_engine
    Base.metadata.create_all(engine)
E   NameError: name 'Base' is not defined
============================== warnings summary ===============================
theory_evaluation\models.py:17
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\models.py:17: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)
    Base = declarative_base()

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ===========================
ERROR temp/temp.py::test_user_info_creation - NameError: name 'Base' is not d...
1 warning, 1 error in 0.93s
2025-04-17 12:45:45,797 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-17 12:45:45,797 - INFO - 
TEST CASE 1 Retry 1
---------------
from sqlalchemy.dialects.postgresql import JSONB, UUID
from sqlalchemy import (
    Column,
    Integer,
    String,
    TIMESTAMP,
    create_engine,
    Float,
    ForeignKey,
    Text,
    UniqueConstraint,
)
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.sql import func
import uuid
from theory_evaluation.models import ConsultantChat, CurrentUserTable, Curriculum, MentorChat, Projects, SprintIssues, TheoryEvalUserPerformance, UserInfo, UserRepo, UserScoreLog
import pytest

@pytest.fixture(scope='module')
def test_engine():
    engine = create_engine('sqlite:///:memory:', echo=True)
    Base.metadata.create_all(engine)
    return engine

@pytest.fixture(scope='function')
def session(test_engine):
    Session = sessionmaker(bind=test_engine)
    session = Session()
    yield session
    session.close()

import pytest
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from your_module import Base, UserInfo  # Replace 'your_module' with the actual module name

@pytest.fixture(scope="function")
def session():
    engine = create_engine('sqlite:///:memory:', echo=True)
    Base.metadata.create_all(engine)
    Session = sessionmaker(bind=engine)
    session = Session()
    yield session
    session.close()

def test_user_info_creation(session):
    user_info = UserInfo(
        first_name="John",
        last_name="Doe",
        email="john.doe@example.com",
        github_username="johndoe",
        payment_date=None,
        current_duration=0,
        course_duration=0,
        end_date=None,
        status=1
    )
    session.add(user_info)
    session.commit()
    retrieved_user = session.query(UserInfo).filter_by(email="john.doe@example.com").first()
    assert retrieved_user is not None
    assert retrieved_user.first_name == "John"
    assert retrieved_user.last_name == "Doe"

---------------
2025-04-17 12:45:47,894 - INFO - TEST CASE 1 Retry 1 - Result - Failed
2025-04-17 12:45:47,894 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:35: in <module>
    from your_module import Base, UserInfo  # Replace 'your_module' with the actual module name
E   ModuleNotFoundError: No module named 'your_module'
============================== warnings summary ===============================
theory_evaluation\models.py:17
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\models.py:17: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)
    Base = declarative_base()

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 warning, 1 error in 0.89s
2025-04-17 12:45:51,137 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-17 12:45:51,137 - INFO - 
TEST CASE 1 Retry 2
---------------
from sqlalchemy.dialects.postgresql import JSONB, UUID
from sqlalchemy import (
    Column,
    Integer,
    String,
    TIMESTAMP,
    create_engine,
    Float,
    ForeignKey,
    Text,
    UniqueConstraint,
)
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.sql import func
import uuid
from theory_evaluation.models import ConsultantChat, CurrentUserTable, Curriculum, MentorChat, Projects, SprintIssues, TheoryEvalUserPerformance, UserInfo, UserRepo, UserScoreLog
import pytest

@pytest.fixture(scope='module')
def test_engine():
    engine = create_engine('sqlite:///:memory:', echo=True)
    Base.metadata.create_all(engine)
    return engine

@pytest.fixture(scope='function')
def session(test_engine):
    Session = sessionmaker(bind=test_engine)
    session = Session()
    yield session
    session.close()

import pytest
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from your_actual_module_name import Base, UserInfo  # Replace 'your_actual_module_name' with the actual module name

@pytest.fixture(scope="function")
def session():
    engine = create_engine('sqlite:///:memory:', echo=True)
    Base.metadata.create_all(engine)
    Session = sessionmaker(bind=engine)
    session = Session()
    yield session
    session.close()

def test_user_info_creation(session):
    user_info = UserInfo(
        first_name="John",
        last_name="Doe",
        email="john.doe@example.com",
        github_username="johndoe",
        payment_date=None,
        current_duration=0,
        course_duration=0,
        end_date=None,
        status=1
    )
    session.add(user_info)
    session.commit()
    retrieved_user = session.query(UserInfo).filter_by(email="john.doe@example.com").first()
    assert retrieved_user is not None
    assert retrieved_user.first_name == "John"
    assert retrieved_user.last_name == "Doe"

---------------
2025-04-17 12:45:53,289 - INFO - TEST CASE 1 Retry 2 - Result - Failed
2025-04-17 12:45:53,290 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:35: in <module>
    from your_actual_module_name import Base, UserInfo  # Replace 'your_actual_module_name' with the actual module name
E   ModuleNotFoundError: No module named 'your_actual_module_name'
============================== warnings summary ===============================
theory_evaluation\models.py:17
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\models.py:17: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)
    Base = declarative_base()

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 warning, 1 error in 0.94s
2025-04-17 12:45:55,924 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-17 12:45:55,925 - INFO - Failed after all retries for test case 1
2025-04-17 12:45:55,925 - INFO - 
TEST CASE 2 Retry 0
---------------
from sqlalchemy.dialects.postgresql import JSONB, UUID
from sqlalchemy import (
    Column,
    Integer,
    String,
    TIMESTAMP,
    create_engine,
    Float,
    ForeignKey,
    Text,
    UniqueConstraint,
)
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.sql import func
import uuid
from theory_evaluation.models import ConsultantChat, CurrentUserTable, Curriculum, MentorChat, Projects, SprintIssues, TheoryEvalUserPerformance, UserInfo, UserRepo, UserScoreLog
import pytest

@pytest.fixture(scope='module')
def test_engine():
    engine = create_engine('sqlite:///:memory:', echo=True)
    Base.metadata.create_all(engine)
    return engine

@pytest.fixture(scope='function')
def session(test_engine):
    Session = sessionmaker(bind=test_engine)
    session = Session()
    yield session
    session.close()

def test_user_info_unique_email_constraint(session):
    user_info1 = UserInfo(
        first_name="Jane",
        last_name="Doe",
        email="jane.doe@example.com",
        github_username="janedoe",
        status=1
    )
    user_info2 = UserInfo(
        first_name="Jane",
        last_name="Smith",
        email="jane.doe@example.com",
        github_username="janesmith",
        status=1
    )
    session.add(user_info1)
    session.commit()
    session.add(user_info2)
    with pytest.raises(IntegrityError):
        session.commit()

---------------
2025-04-17 12:45:58,240 - INFO - TEST CASE 2 Retry 0 - Result - Failed
2025-04-17 12:45:58,241 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
E                                                                        [100%]
=================================== ERRORS ====================================
__________ ERROR at setup of test_user_info_unique_email_constraint ___________
temp\temp.py:22: in test_engine
    Base.metadata.create_all(engine)
E   NameError: name 'Base' is not defined
============================== warnings summary ===============================
theory_evaluation\models.py:17
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\models.py:17: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)
    Base = declarative_base()

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ===========================
ERROR temp/temp.py::test_user_info_unique_email_constraint - NameError: name ...
1 warning, 1 error in 0.94s
2025-04-17 12:46:00,781 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-17 12:46:00,782 - INFO - 
TEST CASE 2 Retry 1
---------------
from sqlalchemy.dialects.postgresql import JSONB, UUID
from sqlalchemy import (
    Column,
    Integer,
    String,
    TIMESTAMP,
    create_engine,
    Float,
    ForeignKey,
    Text,
    UniqueConstraint,
)
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.sql import func
import uuid
from theory_evaluation.models import ConsultantChat, CurrentUserTable, Curriculum, MentorChat, Projects, SprintIssues, TheoryEvalUserPerformance, UserInfo, UserRepo, UserScoreLog
import pytest

@pytest.fixture(scope='module')
def test_engine():
    engine = create_engine('sqlite:///:memory:', echo=True)
    Base.metadata.create_all(engine)
    return engine

@pytest.fixture(scope='function')
def session(test_engine):
    Session = sessionmaker(bind=test_engine)
    session = Session()
    yield session
    session.close()

import pytest
from sqlalchemy.exc import IntegrityError
from sqlalchemy.orm import sessionmaker
from sqlalchemy import create_engine

# Assuming you have a database URL
DATABASE_URL = "sqlite:///:memory:"  # or your actual database URL

# Create an engine and a session
engine = create_engine(DATABASE_URL)
Session = sessionmaker(bind=engine)
Base.metadata.create_all(engine)

@pytest.fixture
def session():
    session = Session()
    yield session
    session.close()

def test_user_info_unique_email_constraint(session):
    user_info1 = UserInfo(
        first_name="Jane",
        last_name="Doe",
        email="jane.doe@example.com",
        github_username="janedoe",
        status=1
    )
    user_info2 = UserInfo(
        first_name="Jane",
        last_name="Smith",
        email="jane.doe@example.com",
        github_username="janesmith",
        status=1
    )
    session.add(user_info1)
    session.commit()
    session.add(user_info2)
    with pytest.raises(IntegrityError):
        session.commit()

---------------
2025-04-17 12:46:03,112 - INFO - TEST CASE 2 Retry 1 - Result - Failed
2025-04-17 12:46:03,113 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
temp\temp.py:43: in <module>
    Base.metadata.create_all(engine)
E   NameError: name 'Base' is not defined
============================== warnings summary ===============================
theory_evaluation\models.py:17
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\models.py:17: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)
    Base = declarative_base()

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ===========================
ERROR temp/temp.py - NameError: name 'Base' is not defined
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 warning, 1 error in 1.01s
2025-04-17 12:46:06,390 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-17 12:46:06,390 - INFO - 
TEST CASE 2 Retry 2
---------------
from sqlalchemy.dialects.postgresql import JSONB, UUID
from sqlalchemy import (
    Column,
    Integer,
    String,
    TIMESTAMP,
    create_engine,
    Float,
    ForeignKey,
    Text,
    UniqueConstraint,
)
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.sql import func
import uuid
from theory_evaluation.models import ConsultantChat, CurrentUserTable, Curriculum, MentorChat, Projects, SprintIssues, TheoryEvalUserPerformance, UserInfo, UserRepo, UserScoreLog
import pytest

@pytest.fixture(scope='module')
def test_engine():
    engine = create_engine('sqlite:///:memory:', echo=True)
    Base.metadata.create_all(engine)
    return engine

@pytest.fixture(scope='function')
def session(test_engine):
    Session = sessionmaker(bind=test_engine)
    session = Session()
    yield session
    session.close()

import pytest
from sqlalchemy.exc import IntegrityError
from sqlalchemy.orm import sessionmaker
from sqlalchemy import create_engine
from your_module import Base, UserInfo  # Import Base and UserInfo from your module

# Assuming you have a database URL
DATABASE_URL = "sqlite:///:memory:"  # or your actual database URL

# Create an engine and a session
engine = create_engine(DATABASE_URL)
Session = sessionmaker(bind=engine)
Base.metadata.create_all(engine)

@pytest.fixture
def session():
    session = Session()
    yield session
    session.close()

def test_user_info_unique_email_constraint(session):
    user_info1 = UserInfo(
        first_name="Jane",
        last_name="Doe",
        email="jane.doe@example.com",
        github_username="janedoe",
        status=1
    )
    user_info2 = UserInfo(
        first_name="Jane",
        last_name="Smith",
        email="jane.doe@example.com",
        github_username="janesmith",
        status=1
    )
    session.add(user_info1)
    session.commit()
    session.add(user_info2)
    with pytest.raises(IntegrityError):
        session.commit()

---------------
2025-04-17 12:46:08,187 - INFO - TEST CASE 2 Retry 2 - Result - Failed
2025-04-17 12:46:08,187 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:36: in <module>
    from your_module import Base, UserInfo  # Import Base and UserInfo from your module
E   ModuleNotFoundError: No module named 'your_module'
============================== warnings summary ===============================
theory_evaluation\models.py:17
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\models.py:17: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)
    Base = declarative_base()

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 warning, 1 error in 0.78s
2025-04-17 12:46:11,183 - INFO - Failed after all retries for test case 2
2025-04-17 12:46:11,184 - INFO - 
TEST CASE 3 Retry 0
---------------
from sqlalchemy.dialects.postgresql import JSONB, UUID
from sqlalchemy import (
    Column,
    Integer,
    String,
    TIMESTAMP,
    create_engine,
    Float,
    ForeignKey,
    Text,
    UniqueConstraint,
)
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.sql import func
import uuid
from theory_evaluation.models import ConsultantChat, CurrentUserTable, Curriculum, MentorChat, Projects, SprintIssues, TheoryEvalUserPerformance, UserInfo, UserRepo, UserScoreLog
import pytest

@pytest.fixture(scope='module')
def test_engine():
    engine = create_engine('sqlite:///:memory:', echo=True)
    Base.metadata.create_all(engine)
    return engine

@pytest.fixture(scope='function')
def session(test_engine):
    Session = sessionmaker(bind=test_engine)
    session = Session()
    yield session
    session.close()

def test_projects_creation(session):
    project = Projects(
        repo_name="test_repo",
        problem_statement={"key": "value"},
        bloblink="http://example.com/blob",
        mini_project_flag=1
    )
    session.add(project)
    session.commit()
    retrieved_project = session.query(Projects).filter_by(repo_name="test_repo").first()
    assert retrieved_project is not None
    assert retrieved_project.problem_statement == {"key": "value"}

---------------
2025-04-17 12:46:13,088 - INFO - TEST CASE 3 Retry 0 - Result - Failed
2025-04-17 12:46:13,088 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
E                                                                        [100%]
=================================== ERRORS ====================================
__________________ ERROR at setup of test_projects_creation ___________________
temp\temp.py:22: in test_engine
    Base.metadata.create_all(engine)
E   NameError: name 'Base' is not defined
============================== warnings summary ===============================
theory_evaluation\models.py:17
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\models.py:17: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)
    Base = declarative_base()

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ===========================
ERROR temp/temp.py::test_projects_creation - NameError: name 'Base' is not de...
1 warning, 1 error in 0.81s
2025-04-17 12:46:15,439 - INFO - 
TEST CASE 3 Retry 1
---------------
from sqlalchemy.dialects.postgresql import JSONB, UUID
from sqlalchemy import (
    Column,
    Integer,
    String,
    TIMESTAMP,
    create_engine,
    Float,
    ForeignKey,
    Text,
    UniqueConstraint,
)
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.sql import func
import uuid
from theory_evaluation.models import ConsultantChat, CurrentUserTable, Curriculum, MentorChat, Projects, SprintIssues, TheoryEvalUserPerformance, UserInfo, UserRepo, UserScoreLog
import pytest

@pytest.fixture(scope='module')
def test_engine():
    engine = create_engine('sqlite:///:memory:', echo=True)
    Base.metadata.create_all(engine)
    return engine

@pytest.fixture(scope='function')
def session(test_engine):
    Session = sessionmaker(bind=test_engine)
    session = Session()
    yield session
    session.close()

def test_projects_creation(session):
    from sqlalchemy.orm import sessionmaker
    from sqlalchemy import create_engine

    # Assuming you have a database URL
    DATABASE_URL = "your_database_url_here"
    engine = create_engine(DATABASE_URL)
    Session = sessionmaker(bind=engine)
    session = Session()

    project = Projects(
        repo_name="test_repo",
        problem_statement={"key": "value"},
        bloblink="http://example.com/blob",
        mini_project_flag=1
    )
    session.add(project)
    session.commit()
    retrieved_project = session.query(Projects).filter_by(repo_name="test_repo").first()
    assert retrieved_project is not None
    assert retrieved_project.problem_statement == {"key": "value"}

    session.close()

---------------
2025-04-17 12:46:17,649 - INFO - TEST CASE 3 Retry 1 - Result - Failed
2025-04-17 12:46:17,650 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
E                                                                        [100%]
=================================== ERRORS ====================================
__________________ ERROR at setup of test_projects_creation ___________________
temp\temp.py:22: in test_engine
    Base.metadata.create_all(engine)
E   NameError: name 'Base' is not defined
============================== warnings summary ===============================
theory_evaluation\models.py:17
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\models.py:17: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)
    Base = declarative_base()

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ===========================
ERROR temp/temp.py::test_projects_creation - NameError: name 'Base' is not de...
1 warning, 1 error in 0.94s
2025-04-17 12:46:20,622 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-17 12:46:20,623 - INFO - 
TEST CASE 3 Retry 2
---------------
from sqlalchemy.dialects.postgresql import JSONB, UUID
from sqlalchemy import (
    Column,
    Integer,
    String,
    TIMESTAMP,
    create_engine,
    Float,
    ForeignKey,
    Text,
    UniqueConstraint,
)
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.sql import func
import uuid
from theory_evaluation.models import ConsultantChat, CurrentUserTable, Curriculum, MentorChat, Projects, SprintIssues, TheoryEvalUserPerformance, UserInfo, UserRepo, UserScoreLog
import pytest

@pytest.fixture(scope='module')
def test_engine():
    engine = create_engine('sqlite:///:memory:', echo=True)
    Base.metadata.create_all(engine)
    return engine

@pytest.fixture(scope='function')
def session(test_engine):
    Session = sessionmaker(bind=test_engine)
    session = Session()
    yield session
    session.close()

def test_projects_creation():
    from sqlalchemy.orm import sessionmaker
    from sqlalchemy import create_engine
    from your_module_name import Base, Projects  # Replace 'your_module_name' with the actual module name

    # Assuming you have a database URL
    DATABASE_URL = "your_database_url_here"
    engine = create_engine(DATABASE_URL)
    Base.metadata.create_all(engine)  # Ensure tables are created
    Session = sessionmaker(bind=engine)
    session = Session()

    project = Projects(
        repo_name="test_repo",
        problem_statement={"key": "value"},
        bloblink="http://example.com/blob",
        mini_project_flag=1
    )
    session.add(project)
    session.commit()
    retrieved_project = session.query(Projects).filter_by(repo_name="test_repo").first()
    assert retrieved_project is not None
    assert retrieved_project.problem_statement == {"key": "value"}

    session.close()

---------------
2025-04-17 12:46:22,641 - INFO - TEST CASE 3 Retry 2 - Result - Failed
2025-04-17 12:46:22,641 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
___________________________ test_projects_creation ____________________________
temp\temp.py:35: in test_projects_creation
    from your_module_name import Base, Projects  # Replace 'your_module_name' with the actual module name
E   ModuleNotFoundError: No module named 'your_module_name'
============================== warnings summary ===============================
theory_evaluation\models.py:17
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\models.py:17: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)
    Base = declarative_base()

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ===========================
FAILED temp/temp.py::test_projects_creation - ModuleNotFoundError: No module ...
1 failed, 1 warning in 0.90s
2025-04-17 12:46:25,463 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-17 12:46:25,464 - INFO - Failed after all retries for test case 3
2025-04-17 12:46:25,464 - INFO - 
TEST CASE 4 Retry 0
---------------
from sqlalchemy.dialects.postgresql import JSONB, UUID
from sqlalchemy import (
    Column,
    Integer,
    String,
    TIMESTAMP,
    create_engine,
    Float,
    ForeignKey,
    Text,
    UniqueConstraint,
)
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.sql import func
import uuid
from theory_evaluation.models import ConsultantChat, CurrentUserTable, Curriculum, MentorChat, Projects, SprintIssues, TheoryEvalUserPerformance, UserInfo, UserRepo, UserScoreLog
import pytest

@pytest.fixture(scope='module')
def test_engine():
    engine = create_engine('sqlite:///:memory:', echo=True)
    Base.metadata.create_all(engine)
    return engine

@pytest.fixture(scope='function')
def session(test_engine):
    Session = sessionmaker(bind=test_engine)
    session = Session()
    yield session
    session.close()

def test_user_repo_unique_constraint(session):
    user_repo1 = UserRepo(
        user_id=1,
        psid=1,
        github_username="uniqueuser",
        repo_name="uniquerepo",
        github_url="http://github.com/uniqueuser/uniquerepo"
    )
    user_repo2 = UserRepo(
        user_id=2,
        psid=2,
        github_username="uniqueuser",
        repo_name="uniquerepo",
        github_url="http://github.com/uniqueuser/uniquerepo"
    )
    session.add(user_repo1)
    session.commit()
    session.add(user_repo2)
    with pytest.raises(IntegrityError):
        session.commit()

---------------
2025-04-17 12:46:27,568 - INFO - TEST CASE 4 Retry 0 - Result - Failed
2025-04-17 12:46:27,568 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
E                                                                        [100%]
=================================== ERRORS ====================================
_____________ ERROR at setup of test_user_repo_unique_constraint ______________
temp\temp.py:22: in test_engine
    Base.metadata.create_all(engine)
E   NameError: name 'Base' is not defined
============================== warnings summary ===============================
theory_evaluation\models.py:17
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\models.py:17: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)
    Base = declarative_base()

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ===========================
ERROR temp/temp.py::test_user_repo_unique_constraint - NameError: name 'Base'...
1 warning, 1 error in 0.86s
2025-04-17 12:46:31,163 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-17 12:46:31,163 - INFO - 
TEST CASE 4 Retry 1
---------------
from sqlalchemy.dialects.postgresql import JSONB, UUID
from sqlalchemy import (
    Column,
    Integer,
    String,
    TIMESTAMP,
    create_engine,
    Float,
    ForeignKey,
    Text,
    UniqueConstraint,
)
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.sql import func
import uuid
from theory_evaluation.models import ConsultantChat, CurrentUserTable, Curriculum, MentorChat, Projects, SprintIssues, TheoryEvalUserPerformance, UserInfo, UserRepo, UserScoreLog
import pytest

@pytest.fixture(scope='module')
def test_engine():
    engine = create_engine('sqlite:///:memory:', echo=True)
    Base.metadata.create_all(engine)
    return engine

@pytest.fixture(scope='function')
def session(test_engine):
    Session = sessionmaker(bind=test_engine)
    session = Session()
    yield session
    session.close()

import pytest
from sqlalchemy.exc import IntegrityError
from sqlalchemy.orm import sessionmaker
from sqlalchemy import create_engine

# Assuming the database URL is defined somewhere
DATABASE_URL = "postgresql://user:password@localhost/testdb"

# Create an engine and a session
engine = create_engine(DATABASE_URL)
Session = sessionmaker(bind=engine)

@pytest.fixture(scope="function")
def session():
    # Create a new session
    session = Session()
    yield session
    # Rollback any changes made during the test
    session.rollback()
    session.close()

def test_user_repo_unique_constraint(session):
    Base.metadata.create_all(engine)
    user_repo1 = UserRepo(
        user_id=1,
        psid=1,
        github_username="uniqueuser",
        repo_name="uniquerepo",
        github_url="http://github.com/uniqueuser/uniquerepo"
    )
    user_repo2 = UserRepo(
        user_id=2,
        psid=2,
        github_username="uniqueuser",
        repo_name="uniquerepo",
        github_url="http://github.com/uniqueuser/uniquerepo"
    )
    session.add(user_repo1)
    session.commit()
    session.add(user_repo2)
    with pytest.raises(IntegrityError):
        session.commit()

---------------
2025-04-17 12:46:33,533 - INFO - TEST CASE 4 Retry 1 - Result - Failed
2025-04-17 12:46:33,533 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:41: in <module>
    engine = create_engine(DATABASE_URL)
.venv\Lib\site-packages\sqlalchemy\util\deprecations.py:281: in warned
    return fn(*args, **kwargs)  # type: ignore[no-any-return]
.venv\Lib\site-packages\sqlalchemy\engine\create.py:602: in create_engine
    dbapi = dbapi_meth(**dbapi_args)
.venv\Lib\site-packages\sqlalchemy\dialects\postgresql\psycopg2.py:696: in import_dbapi
    import psycopg2
E   ModuleNotFoundError: No module named 'psycopg2'
============================== warnings summary ===============================
theory_evaluation\models.py:17
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\models.py:17: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)
    Base = declarative_base()

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 warning, 1 error in 1.09s
2025-04-17 12:46:37,761 - INFO - 
TEST CASE 4 Retry 2
---------------
from sqlalchemy.dialects.postgresql import JSONB, UUID
from sqlalchemy import (
    Column,
    Integer,
    String,
    TIMESTAMP,
    create_engine,
    Float,
    ForeignKey,
    Text,
    UniqueConstraint,
)
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.sql import func
import uuid
from theory_evaluation.models import ConsultantChat, CurrentUserTable, Curriculum, MentorChat, Projects, SprintIssues, TheoryEvalUserPerformance, UserInfo, UserRepo, UserScoreLog
import pytest

@pytest.fixture(scope='module')
def test_engine():
    engine = create_engine('sqlite:///:memory:', echo=True)
    Base.metadata.create_all(engine)
    return engine

@pytest.fixture(scope='function')
def session(test_engine):
    Session = sessionmaker(bind=test_engine)
    session = Session()
    yield session
    session.close()

import pytest
from sqlalchemy.exc import IntegrityError
from sqlalchemy.orm import sessionmaker
from sqlalchemy import create_engine
from sqlalchemy_utils import database_exists, create_database
from source_code import Base, UserRepo  # Assuming the source code is in a file named source_code.py

# Assuming the database URL is defined somewhere
DATABASE_URL = "postgresql://user:password@localhost/testdb"

# Create an engine and a session
engine = create_engine(DATABASE_URL)

# Create the database if it does not exist
if not database_exists(engine.url):
    create_database(engine.url)

Session = sessionmaker(bind=engine)

@pytest.fixture(scope="function")
def session():
    # Create all tables
    Base.metadata.create_all(engine)
    # Create a new session
    session = Session()
    yield session
    # Rollback any changes made during the test
    session.rollback()
    session.close()
    # Drop all tables
    Base.metadata.drop_all(engine)

def test_user_repo_unique_constraint(session):
    user_repo1 = UserRepo(
        user_id=1,
        psid=1,
        github_username="uniqueuser",
        repo_name="uniquerepo",
        github_url="http://github.com/uniqueuser/uniquerepo"
    )
    user_repo2 = UserRepo(
        user_id=2,
        psid=2,
        github_username="uniqueuser",
        repo_name="uniquerepo",
        github_url="http://github.com/uniqueuser/uniquerepo"
    )
    session.add(user_repo1)
    session.commit()
    session.add(user_repo2)
    with pytest.raises(IntegrityError):
        session.commit()

---------------
2025-04-17 12:46:40,107 - INFO - TEST CASE 4 Retry 2 - Result - Failed
2025-04-17 12:46:40,107 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))

=================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:36: in <module>
    from sqlalchemy_utils import database_exists, create_database
E   ModuleNotFoundError: No module named 'sqlalchemy_utils'
============================== warnings summary ===============================
theory_evaluation\models.py:17
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\models.py:17: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)
    Base = declarative_base()

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 warning, 1 error in 0.99s
2025-04-17 12:46:43,364 - INFO - Failed after all retries for test case 4
2025-04-17 12:46:43,365 - INFO - 
TEST CASE 5 Retry 0
---------------
from sqlalchemy.dialects.postgresql import JSONB, UUID
from sqlalchemy import (
    Column,
    Integer,
    String,
    TIMESTAMP,
    create_engine,
    Float,
    ForeignKey,
    Text,
    UniqueConstraint,
)
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.sql import func
import uuid
from theory_evaluation.models import ConsultantChat, CurrentUserTable, Curriculum, MentorChat, Projects, SprintIssues, TheoryEvalUserPerformance, UserInfo, UserRepo, UserScoreLog
import pytest

@pytest.fixture(scope='module')
def test_engine():
    engine = create_engine('sqlite:///:memory:', echo=True)
    Base.metadata.create_all(engine)
    return engine

@pytest.fixture(scope='function')
def session(test_engine):
    Session = sessionmaker(bind=test_engine)
    session = Session()
    yield session
    session.close()

def test_curriculum_creation(session):
    curriculum = Curriculum(
        question="What is Python?",
        marking_scheme="Detailed explanation required.",
        model_answer="Python is a programming language."
    )
    session.add(curriculum)
    session.commit()
    retrieved_curriculum = session.query(Curriculum).filter_by(question="What is Python?").first()
    assert retrieved_curriculum is not None
    assert retrieved_curriculum.model_answer == "Python is a programming language."

---------------
2025-04-17 12:46:45,822 - INFO - TEST CASE 5 Retry 0 - Result - Failed
2025-04-17 12:46:45,823 - INFO - Test Error - c:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\.venv\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
E                                                                        [100%]
=================================== ERRORS ====================================
_________________ ERROR at setup of test_curriculum_creation __________________
temp\temp.py:22: in test_engine
    Base.metadata.create_all(engine)
E   NameError: name 'Base' is not defined
============================== warnings summary ===============================
theory_evaluation\models.py:17
  C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\models.py:17: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)
    Base = declarative_base()

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ===========================
ERROR temp/temp.py::test_curriculum_creation - NameError: name 'Base' is not ...
1 warning, 1 error in 1.06s
