2025-04-14 17:39:22,961 - INFO - Loading environment variables...
2025-04-14 17:39:23,341 - INFO - [1mStart Processing file: theory_evaluation\llm_handler.py[0m
2025-04-14 17:39:34,814 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-14 17:39:34,822 - INFO - 

2025-04-14 17:39:34,823 - INFO - TEST CASE 1 Retry 1
2025-04-14 17:39:34,823 - INFO - ---------------
2025-04-14 17:39:34,824 - INFO - def test_openai_llm_initialization_with_azure(mock_azure_openai, mock_os_environ):
    llm = OpenAI_llm(useAzureOpenAI=True)
    assert llm.client == mock_azure_openai.return_value
    assert llm.azure_endpoint == "test_endpoint"
    assert llm.api_version == "test_version"
    assert llm.model_name == "test_deployment"
2025-04-14 17:39:34,825 - INFO - ---------------
2025-04-14 17:39:37,623 - INFO - passed 1- False
2025-04-14 17:39:37,623 - INFO - test_case_error 1 - =================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:6: in <module>
    from theory_evaluation.llm_handler import execute, main
E   ImportError: cannot import name 'execute' from 'theory_evaluation.llm_handler' (C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\llm_handler.py)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 1.60s
2025-04-14 17:39:37,623 - INFO - TEST CASE 1 Retry 2
2025-04-14 17:39:37,623 - INFO - ---------------
2025-04-14 17:39:37,623 - INFO - def test_openai_llm_initialization_with_azure(mock_azure_openai, mock_os_environ):
    llm = OpenAI_llm(useAzureOpenAI=True)
    assert llm.client == mock_azure_openai.return_value
    assert llm.azure_endpoint == "test_endpoint"
    assert llm.api_version == "test_version"
    assert llm.model_name == "test_deployment"
2025-04-14 17:39:37,623 - INFO - ---------------
2025-04-14 17:39:38,190 - INFO - missing_import_statement 2- from theory_evaluation.llm_handler import execute
2025-04-14 17:39:38,190 - INFO - new import statement 2- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import execute, main
from theory_evaluation.llm_handler import execute

2025-04-14 17:39:41,425 - INFO - TEST CASE 1 Retry 3
2025-04-14 17:39:41,425 - INFO - ---------------
2025-04-14 17:39:41,425 - INFO - def test_openai_llm_initialization_with_azure(mock_azure_openai, mock_os_environ):
    llm = OpenAI_llm(useAzureOpenAI=True)
    assert llm.client == mock_azure_openai.return_value
    assert llm.azure_endpoint == "test_endpoint"
    assert llm.api_version == "test_version"
    assert llm.model_name == "test_deployment"
2025-04-14 17:39:41,425 - INFO - ---------------
2025-04-14 17:39:41,949 - INFO - missing_import_statement 3- from theory_evaluation.llm_handler import execute
2025-04-14 17:39:41,949 - INFO - new import statement 3- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import execute, main
from theory_evaluation.llm_handler import execute

from theory_evaluation.llm_handler import execute

2025-04-14 17:39:44,286 - INFO - Failed after all retries for test case 1
2025-04-14 17:39:44,286 - INFO - 

2025-04-14 17:39:44,286 - INFO - TEST CASE 2 Retry 1
2025-04-14 17:39:44,286 - INFO - ---------------
2025-04-14 17:39:44,286 - INFO - def test_openai_llm_initialization_without_azure(mock_openai, mock_os_environ):
    llm = OpenAI_llm(useAzureOpenAI=False)
    assert llm.client == mock_openai.return_value
    assert llm.model_name == "test_openai_deployment"
2025-04-14 17:39:44,286 - INFO - ---------------
2025-04-14 17:39:46,084 - INFO - passed 1- False
2025-04-14 17:39:46,085 - INFO - test_case_error 1 - =================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
ImportError while importing test module 'C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
temp\temp.py:6: in <module>
    from theory_evaluation.llm_handler import execute, main
E   ImportError: cannot import name 'execute' from 'theory_evaluation.llm_handler' (C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\theory_evaluation\llm_handler.py)
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 1.09s
2025-04-14 17:39:46,085 - INFO - TEST CASE 2 Retry 2
2025-04-14 17:39:46,086 - INFO - ---------------
2025-04-14 17:39:46,086 - INFO - def test_openai_llm_initialization_without_azure(mock_openai, mock_os_environ):
    llm = OpenAI_llm(useAzureOpenAI=False)
    assert llm.client == mock_openai.return_value
    assert llm.model_name == "test_openai_deployment"
2025-04-14 17:39:46,087 - INFO - ---------------
2025-04-14 17:39:46,613 - INFO - missing_import_statement 2- from theory_evaluation.llm_handler import main
2025-04-14 17:39:46,613 - INFO - new import statement 2- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import execute, main
from theory_evaluation.llm_handler import execute

from theory_evaluation.llm_handler import execute

from theory_evaluation.llm_handler import main

2025-04-14 17:39:48,668 - INFO - TEST CASE 2 Retry 3
2025-04-14 17:39:48,668 - INFO - ---------------
2025-04-14 17:39:48,668 - INFO - def test_openai_llm_initialization_without_azure(mock_openai, mock_os_environ):
    llm = OpenAI_llm(useAzureOpenAI=False)
    assert llm.client == mock_openai.return_value
    assert llm.model_name == "test_openai_deployment"
2025-04-14 17:39:48,669 - INFO - ---------------
2025-04-14 17:39:49,204 - INFO - missing_import_statement 3- from theory_evaluation.llm_handler import execute
2025-04-14 17:39:49,204 - INFO - new import statement 3- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import execute, main
from theory_evaluation.llm_handler import execute

from theory_evaluation.llm_handler import execute

from theory_evaluation.llm_handler import main

from theory_evaluation.llm_handler import execute

2025-04-14 17:39:51,311 - INFO - Failed after all retries for test case 2
2025-04-14 17:39:51,312 - INFO - 

2025-04-14 17:39:51,312 - INFO - TEST CASE 3 Retry 1
2025-04-14 17:39:51,312 - INFO - ---------------
2025-04-14 17:39:51,312 - INFO - def test_openai_json_completion(mock_openai):
    mock_client = MagicMock()
    mock_client.chat.completions.create = AsyncMock(return_value=MagicMock(choices=[MagicMock(message=MagicMock(content=json.dumps({"key": "value"})))]))
    llm = OpenAI_llm()
    llm.client = mock_client
    result = await llm._OpenAI_JSON_Completion()
    assert result == {"key": "value"}
2025-04-14 17:39:51,312 - INFO - ---------------
2025-04-14 17:39:52,155 - INFO - passed 1- False
2025-04-14 17:39:52,155 - INFO - test_case_error 1 - =================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\python.py:493: in importtestmodule
    mod = import_path(
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\pathlib.py:587: in import_path
    importlib.import_module(module_name)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1387: in _gcd_import
    ???
<frozen importlib._bootstrap>:1360: in _find_and_load
    ???
<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:935: in _load_unlocked
    ???
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\assertion\rewrite.py:176: in exec_module
    source_stat, co = _rewrite_test(fn, self.config)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\assertion\rewrite.py:358: in _rewrite_test
    co = compile(tree, strfn, "exec", dont_inherit=True)
E     File "C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py", line 21
E       result = await llm._OpenAI_JSON_Completion()
E                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   SyntaxError: 'await' outside async function
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 0.18s
2025-04-14 17:39:52,155 - INFO - TEST CASE 3 Retry 2
2025-04-14 17:39:52,156 - INFO - ---------------
2025-04-14 17:39:52,156 - INFO - def test_openai_json_completion(mock_openai):
    mock_client = MagicMock()
    mock_client.chat.completions.create = AsyncMock(return_value=MagicMock(choices=[MagicMock(message=MagicMock(content=json.dumps({"key": "value"})))]))
    llm = OpenAI_llm()
    llm.client = mock_client
    result = await llm._OpenAI_JSON_Completion()
    assert result == {"key": "value"}
2025-04-14 17:39:52,156 - INFO - ---------------
2025-04-14 17:39:52,595 - INFO - missing_import_statement 2- import pytest_asyncio
2025-04-14 17:39:52,596 - INFO - new import statement 2- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import execute, main
from theory_evaluation.llm_handler import execute

from theory_evaluation.llm_handler import execute

from theory_evaluation.llm_handler import main

from theory_evaluation.llm_handler import execute

import pytest_asyncio

2025-04-14 17:39:53,413 - INFO - TEST CASE 3 Retry 3
2025-04-14 17:39:53,414 - INFO - ---------------
2025-04-14 17:39:53,414 - INFO - def test_openai_json_completion(mock_openai):
    mock_client = MagicMock()
    mock_client.chat.completions.create = AsyncMock(return_value=MagicMock(choices=[MagicMock(message=MagicMock(content=json.dumps({"key": "value"})))]))
    llm = OpenAI_llm()
    llm.client = mock_client
    result = await llm._OpenAI_JSON_Completion()
    assert result == {"key": "value"}
2025-04-14 17:39:53,414 - INFO - ---------------
2025-04-14 17:39:54,412 - INFO - missing_import_statement 3- ''
2025-04-14 17:39:54,413 - INFO - new import statement 3- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import execute, main
from theory_evaluation.llm_handler import execute

from theory_evaluation.llm_handler import execute

from theory_evaluation.llm_handler import main

from theory_evaluation.llm_handler import execute

import pytest_asyncio

''

2025-04-14 17:39:55,229 - INFO - Failed after all retries for test case 3
2025-04-14 17:39:55,229 - INFO - 

2025-04-14 17:39:55,230 - INFO - TEST CASE 4 Retry 1
2025-04-14 17:39:55,230 - INFO - ---------------
2025-04-14 17:39:55,230 - INFO - def test_openai_streaming(mock_openai):
    mock_client = MagicMock()
    mock_client.chat.completions.create = AsyncMock(return_value=[MagicMock(choices=[MagicMock(delta=MagicMock(content="chunk"))])])
    llm = OpenAI_llm(output="stream")
    llm.client = mock_client
    result = [chunk async for chunk in llm._OpenAI_Streaming()]
    assert result == ["chunk"]
2025-04-14 17:39:55,230 - INFO - ---------------
2025-04-14 17:39:56,105 - INFO - passed 1- False
2025-04-14 17:39:56,105 - INFO - test_case_error 1 - =================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\python.py:493: in importtestmodule
    mod = import_path(
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\pathlib.py:587: in import_path
    importlib.import_module(module_name)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1387: in _gcd_import
    ???
<frozen importlib._bootstrap>:1360: in _find_and_load
    ???
<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:935: in _load_unlocked
    ???
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\assertion\rewrite.py:176: in exec_module
    source_stat, co = _rewrite_test(fn, self.config)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\assertion\rewrite.py:358: in _rewrite_test
    co = compile(tree, strfn, "exec", dont_inherit=True)
E     File "C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py", line 25
E       result = [chunk async for chunk in llm._OpenAI_Streaming()]
E                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   SyntaxError: asynchronous comprehension outside of an asynchronous function
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 0.18s
2025-04-14 17:39:56,105 - INFO - TEST CASE 4 Retry 2
2025-04-14 17:39:56,105 - INFO - ---------------
2025-04-14 17:39:56,105 - INFO - def test_openai_streaming(mock_openai):
    mock_client = MagicMock()
    mock_client.chat.completions.create = AsyncMock(return_value=[MagicMock(choices=[MagicMock(delta=MagicMock(content="chunk"))])])
    llm = OpenAI_llm(output="stream")
    llm.client = mock_client
    result = [chunk async for chunk in llm._OpenAI_Streaming()]
    assert result == ["chunk"]
2025-04-14 17:39:56,105 - INFO - ---------------
2025-04-14 17:39:56,588 - INFO - missing_import_statement 2- asyncio
2025-04-14 17:39:56,588 - INFO - new import statement 2- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import execute, main
from theory_evaluation.llm_handler import execute

from theory_evaluation.llm_handler import execute

from theory_evaluation.llm_handler import main

from theory_evaluation.llm_handler import execute

import pytest_asyncio

''

asyncio

2025-04-14 17:39:57,834 - INFO - TEST CASE 4 Retry 3
2025-04-14 17:39:57,834 - INFO - ---------------
2025-04-14 17:39:57,834 - INFO - def test_openai_streaming(mock_openai):
    mock_client = MagicMock()
    mock_client.chat.completions.create = AsyncMock(return_value=[MagicMock(choices=[MagicMock(delta=MagicMock(content="chunk"))])])
    llm = OpenAI_llm(output="stream")
    llm.client = mock_client
    result = [chunk async for chunk in llm._OpenAI_Streaming()]
    assert result == ["chunk"]
2025-04-14 17:39:57,835 - INFO - ---------------
2025-04-14 17:39:58,276 - INFO - missing_import_statement 3- import pytest
2025-04-14 17:39:58,276 - INFO - new import statement 3- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import execute, main
from theory_evaluation.llm_handler import execute

from theory_evaluation.llm_handler import execute

from theory_evaluation.llm_handler import main

from theory_evaluation.llm_handler import execute

import pytest_asyncio

''

asyncio

import pytest

2025-04-14 17:39:59,206 - INFO - Failed after all retries for test case 4
2025-04-14 17:39:59,206 - INFO - 

2025-04-14 17:39:59,207 - INFO - TEST CASE 5 Retry 1
2025-04-14 17:39:59,207 - INFO - ---------------
2025-04-14 17:39:59,207 - INFO - def test_openai_chat_completion(mock_openai):
    mock_client = MagicMock()
    mock_client.chat.completions.create = AsyncMock(return_value=MagicMock(choices=[MagicMock(message=MagicMock(content="response"))]))
    llm = OpenAI_llm()
    llm.client = mock_client
    result = await llm._OpenAI_Chat_Completion()
    assert result == "response"
2025-04-14 17:39:59,207 - INFO - ---------------
2025-04-14 17:40:00,139 - INFO - passed 1- False
2025-04-14 17:40:00,139 - INFO - test_case_error 1 - =================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\python.py:493: in importtestmodule
    mod = import_path(
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\pathlib.py:587: in import_path
    importlib.import_module(module_name)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1387: in _gcd_import
    ???
<frozen importlib._bootstrap>:1360: in _find_and_load
    ???
<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:935: in _load_unlocked
    ???
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\assertion\rewrite.py:176: in exec_module
    source_stat, co = _rewrite_test(fn, self.config)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\assertion\rewrite.py:358: in _rewrite_test
    co = compile(tree, strfn, "exec", dont_inherit=True)
E     File "C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py", line 29
E       result = await llm._OpenAI_Chat_Completion()
E                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   SyntaxError: 'await' outside async function
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 0.18s
2025-04-14 17:40:00,139 - INFO - TEST CASE 5 Retry 2
2025-04-14 17:40:00,139 - INFO - ---------------
2025-04-14 17:40:00,140 - INFO - def test_openai_chat_completion(mock_openai):
    mock_client = MagicMock()
    mock_client.chat.completions.create = AsyncMock(return_value=MagicMock(choices=[MagicMock(message=MagicMock(content="response"))]))
    llm = OpenAI_llm()
    llm.client = mock_client
    result = await llm._OpenAI_Chat_Completion()
    assert result == "response"
2025-04-14 17:40:00,140 - INFO - ---------------
2025-04-14 17:40:00,543 - INFO - missing_import_statement 2- import pytest
2025-04-14 17:40:00,544 - INFO - new import statement 2- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import execute, main
from theory_evaluation.llm_handler import execute

from theory_evaluation.llm_handler import execute

from theory_evaluation.llm_handler import main

from theory_evaluation.llm_handler import execute

import pytest_asyncio

''

asyncio

import pytest

import pytest

2025-04-14 17:40:01,548 - INFO - TEST CASE 5 Retry 3
2025-04-14 17:40:01,548 - INFO - ---------------
2025-04-14 17:40:01,548 - INFO - def test_openai_chat_completion(mock_openai):
    mock_client = MagicMock()
    mock_client.chat.completions.create = AsyncMock(return_value=MagicMock(choices=[MagicMock(message=MagicMock(content="response"))]))
    llm = OpenAI_llm()
    llm.client = mock_client
    result = await llm._OpenAI_Chat_Completion()
    assert result == "response"
2025-04-14 17:40:01,548 - INFO - ---------------
2025-04-14 17:40:02,073 - INFO - missing_import_statement 3- import pytest
2025-04-14 17:40:02,073 - INFO - new import statement 3- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import execute, main
from theory_evaluation.llm_handler import execute

from theory_evaluation.llm_handler import execute

from theory_evaluation.llm_handler import main

from theory_evaluation.llm_handler import execute

import pytest_asyncio

''

asyncio

import pytest

import pytest

import pytest

2025-04-14 17:40:02,759 - INFO - Failed after all retries for test case 5
2025-04-14 17:40:02,759 - INFO - 

2025-04-14 17:40:02,759 - INFO - TEST CASE 6 Retry 1
2025-04-14 17:40:02,759 - INFO - ---------------
2025-04-14 17:40:02,759 - INFO - def test_execute_text_generation(mock_openai):
    mock_client = MagicMock()
    mock_client.chat.completions.create = AsyncMock(return_value=MagicMock(choices=[MagicMock(message=MagicMock(content="response"))]))
    llm = OpenAI_llm(mode="text_generation")
    llm.client = mock_client
    result = [response async for response in llm.execute()]
    assert result == ["response"]
2025-04-14 17:40:02,759 - INFO - ---------------
2025-04-14 17:40:03,570 - INFO - passed 1- False
2025-04-14 17:40:03,571 - INFO - test_case_error 1 - =================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\python.py:493: in importtestmodule
    mod = import_path(
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\pathlib.py:587: in import_path
    importlib.import_module(module_name)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1387: in _gcd_import
    ???
<frozen importlib._bootstrap>:1360: in _find_and_load
    ???
<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:935: in _load_unlocked
    ???
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\assertion\rewrite.py:176: in exec_module
    source_stat, co = _rewrite_test(fn, self.config)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\assertion\rewrite.py:358: in _rewrite_test
    co = compile(tree, strfn, "exec", dont_inherit=True)
E     File "C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py", line 33
E       result = [response async for response in llm.execute()]
E                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   SyntaxError: asynchronous comprehension outside of an asynchronous function
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 0.17s
2025-04-14 17:40:03,571 - INFO - TEST CASE 6 Retry 2
2025-04-14 17:40:03,571 - INFO - ---------------
2025-04-14 17:40:03,571 - INFO - def test_execute_text_generation(mock_openai):
    mock_client = MagicMock()
    mock_client.chat.completions.create = AsyncMock(return_value=MagicMock(choices=[MagicMock(message=MagicMock(content="response"))]))
    llm = OpenAI_llm(mode="text_generation")
    llm.client = mock_client
    result = [response async for response in llm.execute()]
    assert result == ["response"]
2025-04-14 17:40:03,571 - INFO - ---------------
2025-04-14 17:40:03,998 - INFO - missing_import_statement 2- import pytest
2025-04-14 17:40:03,999 - INFO - new import statement 2- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import execute, main
from theory_evaluation.llm_handler import execute

from theory_evaluation.llm_handler import execute

from theory_evaluation.llm_handler import main

from theory_evaluation.llm_handler import execute

import pytest_asyncio

''

asyncio

import pytest

import pytest

import pytest

import pytest

2025-04-14 17:40:04,917 - INFO - TEST CASE 6 Retry 3
2025-04-14 17:40:04,917 - INFO - ---------------
2025-04-14 17:40:04,917 - INFO - def test_execute_text_generation(mock_openai):
    mock_client = MagicMock()
    mock_client.chat.completions.create = AsyncMock(return_value=MagicMock(choices=[MagicMock(message=MagicMock(content="response"))]))
    llm = OpenAI_llm(mode="text_generation")
    llm.client = mock_client
    result = [response async for response in llm.execute()]
    assert result == ["response"]
2025-04-14 17:40:04,917 - INFO - ---------------
2025-04-14 17:40:05,352 - INFO - missing_import_statement 3- import pytest
2025-04-14 17:40:05,353 - INFO - new import statement 3- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import execute, main
from theory_evaluation.llm_handler import execute

from theory_evaluation.llm_handler import execute

from theory_evaluation.llm_handler import main

from theory_evaluation.llm_handler import execute

import pytest_asyncio

''

asyncio

import pytest

import pytest

import pytest

import pytest

import pytest

2025-04-14 17:40:06,108 - INFO - Failed after all retries for test case 6
2025-04-14 17:40:06,109 - INFO - 

2025-04-14 17:40:06,109 - INFO - TEST CASE 7 Retry 1
2025-04-14 17:40:06,109 - INFO - ---------------
2025-04-14 17:40:06,109 - INFO - def test_execute_vision(mock_openai):
    mock_client = MagicMock()
    mock_client.chat.completions.create = AsyncMock(return_value=MagicMock(choices=[MagicMock(message=MagicMock(content="response"))]))
    llm = OpenAI_llm(mode="vision", image_input="test_image")
    llm.client = mock_client
    result = [response async for response in llm.execute()]
    assert result == ["response"]
2025-04-14 17:40:06,109 - INFO - ---------------
2025-04-14 17:40:06,803 - INFO - passed 1- False
2025-04-14 17:40:06,803 - INFO - test_case_error 1 - =================================== ERRORS ====================================
________________________ ERROR collecting temp/temp.py ________________________
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\python.py:493: in importtestmodule
    mod = import_path(
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\pathlib.py:587: in import_path
    importlib.import_module(module_name)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py:88: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1387: in _gcd_import
    ???
<frozen importlib._bootstrap>:1360: in _find_and_load
    ???
<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:935: in _load_unlocked
    ???
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\assertion\rewrite.py:176: in exec_module
    source_stat, co = _rewrite_test(fn, self.config)
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\_pytest\assertion\rewrite.py:358: in _rewrite_test
    co = compile(tree, strfn, "exec", dont_inherit=True)
E     File "C:\ChenKhoon\JupyterNotebook\GenerateUnitTestCases\temp\temp.py", line 37
E       result = [response async for response in llm.execute()]
E                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   SyntaxError: asynchronous comprehension outside of an asynchronous function
=========================== short test summary info ===========================
ERROR temp/temp.py
!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
1 error in 0.18s
2025-04-14 17:40:06,803 - INFO - TEST CASE 7 Retry 2
2025-04-14 17:40:06,803 - INFO - ---------------
2025-04-14 17:40:06,803 - INFO - def test_execute_vision(mock_openai):
    mock_client = MagicMock()
    mock_client.chat.completions.create = AsyncMock(return_value=MagicMock(choices=[MagicMock(message=MagicMock(content="response"))]))
    llm = OpenAI_llm(mode="vision", image_input="test_image")
    llm.client = mock_client
    result = [response async for response in llm.execute()]
    assert result == ["response"]
2025-04-14 17:40:06,803 - INFO - ---------------
2025-04-14 17:40:07,321 - INFO - missing_import_statement 2- async def test_execute_vision(mock_openai):
2025-04-14 17:40:07,322 - INFO - new import statement 2- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import execute, main
from theory_evaluation.llm_handler import execute

from theory_evaluation.llm_handler import execute

from theory_evaluation.llm_handler import main

from theory_evaluation.llm_handler import execute

import pytest_asyncio

''

asyncio

import pytest

import pytest

import pytest

import pytest

import pytest

async def test_execute_vision(mock_openai):

2025-04-14 17:40:08,133 - INFO - TEST CASE 7 Retry 3
2025-04-14 17:40:08,133 - INFO - ---------------
2025-04-14 17:40:08,134 - INFO - def test_execute_vision(mock_openai):
    mock_client = MagicMock()
    mock_client.chat.completions.create = AsyncMock(return_value=MagicMock(choices=[MagicMock(message=MagicMock(content="response"))]))
    llm = OpenAI_llm(mode="vision", image_input="test_image")
    llm.client = mock_client
    result = [response async for response in llm.execute()]
    assert result == ["response"]
2025-04-14 17:40:08,134 - INFO - ---------------
2025-04-14 17:40:08,668 - INFO - missing_import_statement 3- from unittest.mock import MagicMock, AsyncMock
2025-04-14 17:40:08,669 - INFO - new import statement 3- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI
from theory_evaluation.llm_handler import execute, main
from theory_evaluation.llm_handler import execute

from theory_evaluation.llm_handler import execute

from theory_evaluation.llm_handler import main

from theory_evaluation.llm_handler import execute

import pytest_asyncio

''

asyncio

import pytest

import pytest

import pytest

import pytest

import pytest

async def test_execute_vision(mock_openai):

from unittest.mock import MagicMock, AsyncMock

2025-04-14 17:40:09,628 - INFO - Failed after all retries for test case 7
2025-04-14 17:40:09,630 - INFO - [1mEnd Processing file: theory_evaluation\llm_handler.py[0m

2025-04-14 17:40:09,630 - INFO - [1mStart Processing file: theory_evaluation\llm_utils.py[0m
2025-04-14 17:40:15,034 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-14 17:40:15,040 - INFO - 

2025-04-14 17:40:15,040 - INFO - TEST CASE 1 Retry 1
2025-04-14 17:40:15,041 - INFO - ---------------
2025-04-14 17:40:15,041 - INFO - def test_initialise_prompt_success():
    agent = "test_agent"
    config_yaml = "key: value"
    prompt_txt = "This is a {$key} test."
    expected_prompt = "This is a value test."
2025-04-14 17:40:15,041 - INFO - ---------------
2025-04-14 17:40:15,782 - INFO - passed 1- True
2025-04-14 17:40:15,783 - INFO - test_case_error 1 - .                                                                        [100%]
1 passed in 0.06s
2025-04-14 17:40:15,783 - INFO - 

2025-04-14 17:40:15,783 - INFO - TEST CASE 2 Retry 1
2025-04-14 17:40:15,783 - INFO - ---------------
2025-04-14 17:40:15,783 - INFO - def test_initialise_prompt_no_config_path():
    with patch("theory_evaluation.llm_utils.open", side_effect=FileNotFoundError):
        result = initialise_prompt("non_existent_agent")
        assert result is None
2025-04-14 17:40:15,783 - INFO - ---------------
2025-04-14 17:40:16,787 - INFO - passed 1- False
2025-04-14 17:40:16,787 - INFO - test_case_error 1 - F                                                                        [100%]
================================== FAILURES ===================================
____________________ test_initialise_prompt_no_config_path ____________________
temp\temp.py:7: in test_initialise_prompt_no_config_path
    with patch("theory_evaluation.llm_utils.open", side_effect=FileNotFoundError):
E   NameError: name 'patch' is not defined
=========================== short test summary info ===========================
FAILED temp/temp.py::test_initialise_prompt_no_config_path - NameError: name ...
1 failed in 0.14s
2025-04-14 17:40:16,787 - INFO - TEST CASE 2 Retry 2
2025-04-14 17:40:16,787 - INFO - ---------------
2025-04-14 17:40:16,787 - INFO - def test_initialise_prompt_no_config_path():
    with patch("theory_evaluation.llm_utils.open", side_effect=FileNotFoundError):
        result = initialise_prompt("non_existent_agent")
        assert result is None
2025-04-14 17:40:16,787 - INFO - ---------------
2025-04-14 17:40:17,245 - INFO - missing_import_statement 2- from unittest.mock import patch
2025-04-14 17:40:17,246 - INFO - new import statement 2- import os
import re
import yaml
from theory_evaluation.llm_utils import initialise_prompt, initialise_settings
from unittest.mock import patch

2025-04-14 17:40:18,052 - INFO - passed 2- True
2025-04-14 17:40:18,052 - INFO - test_case_error 2 - .                                                                        [100%]
1 passed in 0.08s
2025-04-14 17:40:18,053 - INFO - 

2025-04-14 17:40:18,053 - INFO - TEST CASE 3 Retry 1
2025-04-14 17:40:18,053 - INFO - ---------------
2025-04-14 17:40:18,053 - INFO - def test_initialise_settings_success():
    agent = "test_agent"
    settings_yaml = "key: value"
    expected_settings = {'key': 'value'}
2025-04-14 17:40:18,053 - INFO - ---------------
2025-04-14 17:40:18,927 - INFO - passed 1- True
2025-04-14 17:40:18,927 - INFO - test_case_error 1 - .                                                                        [100%]
1 passed in 0.17s
2025-04-14 17:40:18,927 - INFO - 

2025-04-14 17:40:18,927 - INFO - TEST CASE 4 Retry 1
2025-04-14 17:40:18,927 - INFO - ---------------
2025-04-14 17:40:18,927 - INFO - def test_initialise_settings_no_config_path():
    with patch("theory_evaluation.llm_utils.open", side_effect=FileNotFoundError):
        result = initialise_settings("non_existent_agent")
        assert result is None
2025-04-14 17:40:18,927 - INFO - ---------------
2025-04-14 17:40:19,943 - INFO - passed 1- True
2025-04-14 17:40:19,943 - INFO - test_case_error 1 - .                                                                        [100%]
1 passed in 0.18s
2025-04-14 17:40:19,946 - INFO - [1mEnd Processing file: theory_evaluation\llm_utils.py[0m

2025-04-14 17:40:19,946 - INFO - [1mStart Processing file: theory_evaluation\__init__.py[0m
2025-04-14 17:40:19,946 - WARNING - No public functions found in theory_evaluation\__init__.py. Skipping test generation.

