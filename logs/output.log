2025-04-15 15:59:18,310 - INFO - Loading environment variables...
2025-04-15 15:59:18,637 - INFO - Start Processing file: theory_evaluation\llm_handler.py
2025-04-15 15:59:20,751 - INFO - function_names - ['OpenAI_llm']
2025-04-15 15:59:20,754 - INFO - 
2025-04-15 15:59:20,755 - INFO - function_names - ['OpenAI_llm']
2025-04-15 15:59:30,515 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-15 15:59:41,206 - INFO - 

2025-04-15 15:59:41,206 - INFO - TEST CASE 1 Retry 0
2025-04-15 15:59:41,206 - INFO - ---------------
2025-04-15 15:59:41,207 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
@pytest.fixture
def mock_openai_llm():
    with patch('theory_evaluation.llm_handler.OpenAI_llm') as mock_llm:
        yield mock_llm

@pytest.mark.asyncio
async def test_openai_llm_initialization():
    with patch('theory_evaluation.llm_handler.AzureOpenAI') as mock_azure_openai, \
         patch('theory_evaluation.llm_handler.OpenAI') as mock_openai, \
         patch('os.getenv', side_effect=lambda key: f"mock_{key}"):
        
        llm = OpenAI_llm(useAzureOpenAI=True)
        assert llm.client == mock_azure_openai.return_value
        assert llm.azure_endpoint == "mock_AZURE_OPENAI_ENDPOINT_SWEDEN"
        assert llm.api_version == "mock_AZURE_OPENAI_API_VERSION"
        
        llm = OpenAI_llm(useAzureOpenAI=False)
        assert llm.client == mock_openai.return_value

2025-04-15 15:59:41,210 - INFO - ---------------
2025-04-15 15:59:43,577 - INFO - Test Result 1- False
2025-04-15 15:59:43,577 - INFO - Test Error 1 - C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
_______________________ test_openai_llm_initialization ________________________
temp\temp.py:15: in test_openai_llm_initialization
    with patch('theory_evaluation.llm_handler.AzureOpenAI') as mock_azure_openai, \
E   NameError: name 'patch' is not defined
=========================== short test summary info ===========================
FAILED temp/temp.py::test_openai_llm_initialization - NameError: name 'patch'...
1 failed in 1.42s
2025-04-15 15:59:46,155 - INFO - TEST CASE 1 Retry 1
2025-04-15 15:59:46,155 - INFO - ---------------
2025-04-15 15:59:46,155 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
@pytest.fixture
def mock_openai_llm():
    with patch('theory_evaluation.llm_handler.OpenAI_llm') as mock_llm:
        yield mock_llm
from unittest.mock import patch

@pytest.mark.asyncio
async def test_openai_llm_initialization():
    with patch('theory_evaluation.llm_handler.AzureOpenAI') as mock_azure_openai, \
         patch('theory_evaluation.llm_handler.OpenAI') as mock_openai, \
         patch('os.getenv', side_effect=lambda key: f"mock_{key}"):
        
        llm = OpenAI_llm(useAzureOpenAI=True)
        assert llm.client == mock_azure_openai.return_value
        assert llm.azure_endpoint == "mock_AZURE_OPENAI_ENDPOINT_SWEDEN"
        assert llm.api_version == "mock_AZURE_OPENAI_API_VERSION"
        
        llm = OpenAI_llm(useAzureOpenAI=False)
        assert llm.client == mock_openai.return_value

2025-04-15 15:59:46,156 - INFO - ---------------
2025-04-15 15:59:48,467 - INFO - Test Result 2- False
2025-04-15 15:59:48,468 - INFO - Test Error 2 - 
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
_______________________ test_openai_llm_initialization ________________________
temp\temp.py:20: in test_openai_llm_initialization
    llm = OpenAI_llm(useAzureOpenAI=True)
E   NameError: name 'OpenAI_llm' is not defined
=========================== short test summary info ===========================
FAILED temp/temp.py::test_openai_llm_initialization - NameError: name 'OpenAI...
1 failed in 1.13s
2025-04-15 15:59:51,580 - INFO - TEST CASE 1 Retry 2
2025-04-15 15:59:51,581 - INFO - ---------------
2025-04-15 15:59:51,581 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
@pytest.fixture
def mock_openai_llm():
    with patch('theory_evaluation.llm_handler.OpenAI_llm') as mock_llm:
        yield mock_llm
from unittest.mock import patch
from theory_evaluation.llm_handler import OpenAI_llm

@pytest.mark.asyncio
async def test_openai_llm_initialization():
    with patch('theory_evaluation.llm_handler.AzureOpenAI') as mock_azure_openai, \
         patch('theory_evaluation.llm_handler.OpenAI') as mock_openai, \
         patch('os.getenv', side_effect=lambda key: f"mock_{key}"):
        
        llm = OpenAI_llm(useAzureOpenAI=True)
        assert llm.client == mock_azure_openai.return_value
        assert llm.azure_endpoint == "mock_AZURE_OPENAI_ENDPOINT_SWEDEN"
        assert llm.api_version == "mock_AZURE_OPENAI_API_VERSION"
        
        llm = OpenAI_llm(useAzureOpenAI=False)
        assert llm.client == mock_openai.return_value

2025-04-15 15:59:51,581 - INFO - ---------------
2025-04-15 15:59:56,147 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-15 15:59:56,148 - INFO - New import Statements 3- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
from unittest.mock import patch
from theory_evaluation.llm_handler import OpenAI_llm

import pytest
2025-04-15 15:59:56,149 - INFO - Test Result 3- True
2025-04-15 15:59:56,150 - INFO - Test Error 3 - 
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
.                                                                        [100%]
1 passed in 0.99s
2025-04-15 15:59:56,151 - INFO - 

2025-04-15 15:59:56,151 - INFO - TEST CASE 2 Retry 0
2025-04-15 15:59:56,152 - INFO - ---------------
2025-04-15 15:59:56,152 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
from unittest.mock import patch
from theory_evaluation.llm_handler import OpenAI_llm

import pytest
@pytest.fixture
def mock_openai_llm():
    with patch('theory_evaluation.llm_handler.OpenAI_llm') as mock_llm:
        yield mock_llm

@pytest.mark.asyncio
async def test_openai_json_completion():
    mock_response = AsyncMock()
    mock_response.choices[0].message.content = json.dumps({"answer": "42", "explanation": "The answer to life."})

2025-04-15 15:59:56,153 - INFO - ---------------
2025-04-15 15:59:59,678 - INFO - Test Result 1- False
2025-04-15 15:59:59,679 - INFO - Test Error 1 - C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
F                                                                        [100%]
================================== FAILURES ===================================
_________________________ test_openai_json_completion _________________________
temp\temp.py:19: in test_openai_json_completion
    mock_response = AsyncMock()
E   NameError: name 'AsyncMock' is not defined
=========================== short test summary info ===========================
FAILED temp/temp.py::test_openai_json_completion - NameError: name 'AsyncMock...
1 failed in 1.88s
2025-04-15 16:00:00,949 - INFO - TEST CASE 2 Retry 1
2025-04-15 16:00:00,949 - INFO - ---------------
2025-04-15 16:00:00,949 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
from unittest.mock import patch
from theory_evaluation.llm_handler import OpenAI_llm

import pytest
@pytest.fixture
def mock_openai_llm():
    with patch('theory_evaluation.llm_handler.OpenAI_llm') as mock_llm:
        yield mock_llm
from unittest.mock import AsyncMock
import json
import pytest

@pytest.mark.asyncio
async def test_openai_json_completion():
    mock_response = AsyncMock()
    mock_response.choices = [AsyncMock()]
    mock_response.choices[0].message.content = json.dumps({"answer": "42", "explanation": "The answer to life."})
    # Add your test logic here using mock_response

2025-04-15 16:00:00,950 - INFO - ---------------
2025-04-15 16:00:05,146 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-15 16:00:05,147 - INFO - New import Statements 2- import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
from unittest.mock import patch
from theory_evaluation.llm_handler import OpenAI_llm

import pytest
from unittest.mock import AsyncMock
2025-04-15 16:00:05,147 - INFO - Test Result 2- True
2025-04-15 16:00:05,148 - INFO - Test Error 2 - 
C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
.                                                                        [100%]
1 passed in 2.09s
2025-04-15 16:00:05,148 - INFO - 

2025-04-15 16:00:05,149 - INFO - TEST CASE 3 Retry 0
2025-04-15 16:00:05,149 - INFO - ---------------
2025-04-15 16:00:05,150 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
from unittest.mock import patch
from theory_evaluation.llm_handler import OpenAI_llm

import pytest
from unittest.mock import AsyncMock
@pytest.fixture
def mock_openai_llm():
    with patch('theory_evaluation.llm_handler.OpenAI_llm') as mock_llm:
        yield mock_llm

@pytest.mark.asyncio
async def test_openai_streaming():
    mock_chunk = AsyncMock()
    mock_chunk.choices[0].delta.content = "streaming content"

2025-04-15 16:00:05,150 - INFO - ---------------
2025-04-15 16:00:07,885 - INFO - Test Result 1- True
2025-04-15 16:00:07,885 - INFO - Test Error 1 - C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
.                                                                        [100%]
1 passed in 1.75s
2025-04-15 16:00:07,886 - INFO - 

2025-04-15 16:00:07,886 - INFO - TEST CASE 4 Retry 0
2025-04-15 16:00:07,886 - INFO - ---------------
2025-04-15 16:00:07,886 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
from unittest.mock import patch
from theory_evaluation.llm_handler import OpenAI_llm

import pytest
from unittest.mock import AsyncMock
@pytest.fixture
def mock_openai_llm():
    with patch('theory_evaluation.llm_handler.OpenAI_llm') as mock_llm:
        yield mock_llm

@pytest.mark.asyncio
async def test_openai_chat_completion():
    mock_response = AsyncMock()
    mock_response.choices[0].message.content = "Chat completion content"

2025-04-15 16:00:07,886 - INFO - ---------------
2025-04-15 16:00:10,000 - INFO - Test Result 1- True
2025-04-15 16:00:10,000 - INFO - Test Error 1 - C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
.                                                                        [100%]
1 passed in 1.03s
2025-04-15 16:00:10,000 - INFO - 

2025-04-15 16:00:10,000 - INFO - TEST CASE 5 Retry 0
2025-04-15 16:00:10,000 - INFO - ---------------
2025-04-15 16:00:10,000 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
from unittest.mock import patch
from theory_evaluation.llm_handler import OpenAI_llm

import pytest
from unittest.mock import AsyncMock
@pytest.fixture
def mock_openai_llm():
    with patch('theory_evaluation.llm_handler.OpenAI_llm') as mock_llm:
        yield mock_llm

@pytest.mark.asyncio
async def test_execute_text_generation():
    mock_response = AsyncMock()
    mock_response.choices[0].message.content = "Generated text"

2025-04-15 16:00:10,000 - INFO - ---------------
2025-04-15 16:00:12,041 - INFO - Test Result 1- True
2025-04-15 16:00:12,041 - INFO - Test Error 1 - C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
.                                                                        [100%]
1 passed in 1.01s
2025-04-15 16:00:12,041 - INFO - 

2025-04-15 16:00:12,041 - INFO - TEST CASE 6 Retry 0
2025-04-15 16:00:12,041 - INFO - ---------------
2025-04-15 16:00:12,041 - INFO - 
import asyncio
import json
import os

from openai import AzureOpenAI, OpenAI

import pytest
from unittest.mock import patch
from theory_evaluation.llm_handler import OpenAI_llm

import pytest
from unittest.mock import AsyncMock
@pytest.fixture
def mock_openai_llm():
    with patch('theory_evaluation.llm_handler.OpenAI_llm') as mock_llm:
        yield mock_llm

@pytest.mark.asyncio
async def test_execute_vision():
    mock_response = AsyncMock()
    mock_response.choices[0].message.content = "Vision response"

2025-04-15 16:00:12,042 - INFO - ---------------
2025-04-15 16:00:14,506 - INFO - Test Result 1- True
2025-04-15 16:00:14,506 - INFO - Test Error 1 - C:\Users\User\AppData\Local\Programs\Python\Python313\Lib\site-packages\pytest_asyncio\plugin.py:217: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))
.                                                                        [100%]
1 passed in 1.65s
2025-04-15 16:00:14,512 - INFO - End Processing file: theory_evaluation\llm_handler.py

2025-04-15 16:00:14,513 - INFO - Start Processing file: theory_evaluation\llm_utils.py
2025-04-15 16:00:15,876 - INFO - function_names - ['initialise_prompt', 'initialise_settings']
2025-04-15 16:00:15,879 - INFO - from theory_evaluation.llm_utils import initialise_prompt, initialise_settings
2025-04-15 16:00:15,880 - INFO - function_names - ['initialise_prompt', 'initialise_settings']
2025-04-15 16:00:20,737 - WARNING - Stripped Markdown-style triple backtick fences from LLM output.
2025-04-15 16:00:26,259 - INFO - End Processing file: theory_evaluation\llm_utils.py

2025-04-15 16:00:26,259 - INFO - Start Processing file: theory_evaluation\__init__.py
2025-04-15 16:00:26,261 - WARNING - No public functions found in theory_evaluation\__init__.py. Skipping test generation.

